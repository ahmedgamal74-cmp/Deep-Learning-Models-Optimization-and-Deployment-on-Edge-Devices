{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üåê Connect to google drive"
      ],
      "metadata": {
        "id": "tz1W1V8bK05D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUVzIURnK_AU",
        "outputId": "17c3a68b-2242-49df-ffc8-b4a2e965cedf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# H5 ‚û°Ô∏è ONNX"
      ],
      "metadata": {
        "id": "gh3uBh3PH9wn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lp6LNBZ1F_UM",
        "outputId": "250a4c92-beb0-479c-ab5e-db8db2571b64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: tf2onnx in /usr/local/lib/python3.11/dist-packages (1.16.1)\n",
            "Requirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from tf2onnx) (1.26.4)\n",
            "Requirement already satisfied: onnx>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from tf2onnx) (1.17.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from tf2onnx) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from tf2onnx) (1.17.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.11/dist-packages (from tf2onnx) (25.2.10)\n",
            "Requirement already satisfied: protobuf~=3.20 in /usr/local/lib/python3.11/dist-packages (from tf2onnx) (3.20.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->tf2onnx) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->tf2onnx) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->tf2onnx) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->tf2onnx) (2025.1.31)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.11/dist-packages (1.17.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from onnx) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx) (3.20.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow\n",
        "!pip install tf2onnx\n",
        "!pip install onnx"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select h5 model path\n",
        "h5_model_path = '/content/drive/MyDrive/saved_models/mobileNetAug-CIFAR10-95.h5'\n",
        "# Select where to save the onnx model\n",
        "onnx_model_save_path = '/content/drive/MyDrive/saved_models/test.onnx'"
      ],
      "metadata": {
        "id": "Z74t8l5UIPSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tf2onnx\n",
        "import onnx\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model(h5_model_path)\n",
        "# Create a concrete function from the model\n",
        "input_signature = [tf.TensorSpec(shape=[None] + list(model.input_shape[1:]), dtype=tf.float32, name=\"input\")]\n",
        "# Convert the model to ONNX Format\n",
        "onnx_model, _ = tf2onnx.convert.from_keras(model, input_signature=input_signature)\n",
        "onnx.save(onnx_model, onnx_model_save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atRPUj_-INN1",
        "outputId": "23183fd8-b517-4b01-eba3-c2c8350d85e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ONNX ‚û°Ô∏è Protobuff / tflite\n"
      ],
      "metadata": {
        "id": "CnHyWRgkIyP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx2tf\n",
        "!pip install onnx-graphsurgeon\n",
        "!pip install sng4onnx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBgc3KNtJlOc",
        "outputId": "070364a1-96f6-4c28-8d06-294b647a183b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx2tf\n",
            "  Downloading onnx2tf-1.26.8-py3-none-any.whl.metadata (147 kB)\n",
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/147.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m147.5/147.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx2tf-1.26.8-py3-none-any.whl (446 kB)\n",
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/446.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m446.2/446.2 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx2tf\n",
            "Successfully installed onnx2tf-1.26.8\n",
            "Collecting onnx-graphsurgeon\n",
            "  Downloading onnx_graphsurgeon-0.5.6-py2.py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from onnx-graphsurgeon) (1.26.4)\n",
            "Collecting onnx>=1.14.0 (from onnx-graphsurgeon)\n",
            "  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx>=1.14.0->onnx-graphsurgeon) (4.25.6)\n",
            "Downloading onnx_graphsurgeon-0.5.6-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx, onnx-graphsurgeon\n",
            "Successfully installed onnx-1.17.0 onnx-graphsurgeon-0.5.6\n",
            "Collecting sng4onnx\n",
            "  Downloading sng4onnx-1.0.4-py3-none-any.whl.metadata (4.6 kB)\n",
            "Downloading sng4onnx-1.0.4-py3-none-any.whl (5.9 kB)\n",
            "Installing collected packages: sng4onnx\n",
            "Successfully installed sng4onnx-1.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/saved_models/onnx_models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krCdoIp9Y2Y2",
        "outputId": "3c256d25-4a72-4976-f19c-cf4435346a79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/saved_models/onnx_models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!onnx2tf --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OajnqRJvpwgX",
        "outputId": "8f0ce50d-a0df-4fff-8bd3-f9197990f299"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1741376666.829790    3050 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1741376666.853809    3050 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "1.26.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!onnx2tf -h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtfoqCQIuVVc",
        "outputId": "f941cc53-7347-4595-a8f0-f22cf39292ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1740245668.109332   10310 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1740245668.131455   10310 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "usage: onnx2tf [-h] (-i INPUT_ONNX_FILE_PATH | -V) [-o OUTPUT_FOLDER_PATH] [-osd] [-oh5] [-okv3]\n",
            "               [-otfv1pb] [-ow] [-coion] [-odrqt] [-oiqt] [-qt {per-channel,per-tensor}]\n",
            "               [-cind CUSTOM_INPUT_OP_NAME_NP_DATA_PATH [CUSTOM_INPUT_OP_NAME_NP_DATA_PATH ...]]\n",
            "               [-iqd {int8,uint8,float32}] [-oqd {int8,uint8,float32}] [-nuo] [-nuonag]\n",
            "               [-b BATCH_SIZE] [-ois OVERWRITE_INPUT_SHAPE [OVERWRITE_INPUT_SHAPE ...]] [-nlt]\n",
            "               [-onwdt] [-snms {v4,v5}]\n",
            "               [-k KEEP_NCW_OR_NCHW_OR_NCDHW_INPUT_NAMES [KEEP_NCW_OR_NCHW_OR_NCDHW_INPUT_NAMES ...]]\n",
            "               [-kt KEEP_NWC_OR_NHWC_OR_NDHWC_INPUT_NAMES [KEEP_NWC_OR_NHWC_OR_NDHWC_INPUT_NAMES ...]]\n",
            "               [-kat KEEP_SHAPE_ABSOLUTELY_INPUT_NAMES [KEEP_SHAPE_ABSOLUTELY_INPUT_NAMES ...]]\n",
            "               [-inimc INPUT_NAMES_TO_INTERRUPT_MODEL_CONVERSION [INPUT_NAMES_TO_INTERRUPT_MODEL_CONVERSION ...]]\n",
            "               [-onimc OUTPUT_NAMES_TO_INTERRUPT_MODEL_CONVERSION [OUTPUT_NAMES_TO_INTERRUPT_MODEL_CONVERSION ...]]\n",
            "               [-dgc] [-eatfp16] [-ebu] [-eru] [-dsft]\n",
            "               [-nodaftc NUMBER_OF_DIMENSIONS_AFTER_FLEXTRANSPOSE_COMPRESSION] [-dsfs] [-dsm]\n",
            "               [-nodafsc NUMBER_OF_DIMENSIONS_AFTER_FLEXSTRIDEDSLICE_COMPRESSION] [-ofgd]\n",
            "               [-rari64 | -rarf32 | -rafi64 | -raff32] [-fasr FUSED_ARGMAX_SCALE_RATIO]\n",
            "               [-rtpo [REPLACE_TO_PSEUDO_OPERATORS ...]] [-me MVN_EPSILON]\n",
            "               [-prf PARAM_REPLACEMENT_FILE] [-cgdc] [-coto | -cotof] [-coton {norm,denorm}]\n",
            "               [-cotor CHECK_ONNX_TF_OUTPUTS_ELEMENTWISE_CLOSE_RTOL]\n",
            "               [-cotoa CHECK_ONNX_TF_OUTPUTS_ELEMENTWISE_CLOSE_ATOL] [-dms] [-n]\n",
            "               [-v {debug,info,warn,error}]\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  -i INPUT_ONNX_FILE_PATH, --input_onnx_file_path INPUT_ONNX_FILE_PATH\n",
            "                        Input onnx file path.\n",
            "  -V, --version         Show version and exit.\n",
            "  -o OUTPUT_FOLDER_PATH, --output_folder_path OUTPUT_FOLDER_PATH\n",
            "                        Output folder path. Default: \"saved_model\"\n",
            "  -osd, --output_signaturedefs\n",
            "                        Signature is added to the output for serving or for conversion to other\n",
            "                        model formats. However, this can significantly reduce the speed of model\n",
            "                        conversion and significant increase the size of the model.\n",
            "  -oh5, --output_h5     Output model in Keras (hdf5) format.\n",
            "  -okv3, --output_keras_v3\n",
            "                        Output model in Keras (keras_v3) format.\n",
            "  -otfv1pb, --output_tfv1_pb\n",
            "                        Output model in TF v1 (.pb) format.\n",
            "  -ow, --output_weights\n",
            "                        Output weights in hdf5 format.\n",
            "  -coion, --copy_onnx_input_output_names_to_tflite\n",
            "                        Copy the input/output OP name of ONNX to the input/output OP name of\n",
            "                        tflite. Due to Tensorflow internal operating specifications, the\n",
            "                        input/output order of ONNX does not necessarily match the input/output\n",
            "                        order of tflite. Be sure to check that the input/output OP names in the\n",
            "                        generated tflite file have been converted as expected. Also, this option\n",
            "                        generates a huge JSON file as a temporary file for processing. Therefore,\n",
            "                        it is strongly discouraged to use it on large models of hundreds of\n",
            "                        megabytes or more.\n",
            "  -odrqt, --output_dynamic_range_quantized_tflite\n",
            "                        Output of dynamic range quantized tflite.\n",
            "  -oiqt, --output_integer_quantized_tflite\n",
            "                        Output of integer quantized tflite.\n",
            "  -qt {per-channel,per-tensor}, --quant_type {per-channel,per-tensor}\n",
            "                        Selects whether \"per-channel\" or \"per-tensor\" quantization is used.\n",
            "                        Default: \"per-channel\"\n",
            "  -cind CUSTOM_INPUT_OP_NAME_NP_DATA_PATH [CUSTOM_INPUT_OP_NAME_NP_DATA_PATH ...], --custom_input_op_name_np_data_path CUSTOM_INPUT_OP_NAME_NP_DATA_PATH [CUSTOM_INPUT_OP_NAME_NP_DATA_PATH ...]\n",
            "                        Input name of OP and path of data file (Numpy) for custom input for -cotof\n",
            "                        or -oiqt, and mean (optional) and std (optional). <Usage in -cotof> When\n",
            "                        using -cotof, custom input defined by the user, instead of dummy data, is\n",
            "                        used. In this case, mean and std are omitted from the input. -cind\n",
            "                        {input_op_name} {numpy_file_path} ex) -cind onnx::Equal_0\n",
            "                        test_cind/x_1.npy -cind onnx::Add_1 test_cind/x_2.npy -cotof The\n",
            "                        input_op_name must be the same as in ONNX, and it may not work if the\n",
            "                        input format is different between ONNX and TF. <Usage in -oiqt> INPUT Name\n",
            "                        of OP and path of calibration data file (Numpy) for quantization and mean\n",
            "                        and std. The specification can be omitted only when the input OP is a\n",
            "                        single 4D tensor image data. If omitted, it is automatically calibrated\n",
            "                        using 20 normalized MS-COCO images. The type of the input OP must be\n",
            "                        Float32. Data for calibration must be pre-normalized to a range of 0 to 1.\n",
            "                        -cind {input_op_name} {numpy_file_path} {mean} {std} Numpy file paths must\n",
            "                        be specified the same number of times as the number of input OPs.\n",
            "                        Normalize the value of the input OP based on the tensor specified in mean\n",
            "                        and std. (input_value - mean) / std Tensors in Numpy file format must be\n",
            "                        in dimension order after conversion to TF. Note that this is intended for\n",
            "                        deployment on low-resource devices, so the batch size is limited to 1\n",
            "                        only. e.g. The example below shows a case where there are three input OPs.\n",
            "                        Assume input0 is 128x128 RGB image data. In addition, input0 should be a\n",
            "                        value that has been divided by 255 in the preprocessing and normalized to\n",
            "                        a range between 0 and 1. input1 and input2 assume the input of something\n",
            "                        that is not an image. Because input1 and input2 assume something that is\n",
            "                        not an image, the divisor is not 255 when normalizing from 0 to 1. \"n\" is\n",
            "                        the number of calibration data. ONNX INPUT shapes: input0: [n,3,128,128]\n",
            "                        mean: [1,3,1,1] -> [[[[0.485]],[[0.456]],[[0.406]]]] std: [1,3,1,1] ->\n",
            "                        [[[[0.229]],[[0.224]],[[0.225]]]] input1: [n,64,64] mean: [1,64] -> [0.1,\n",
            "                        ..., 0.64] std: [1,64] -> [0.05, ..., 0.08] input2: [n,5] mean: [1] ->\n",
            "                        [0.3] std: [1] -> [0.07] TensorFlow INPUT shapes (Numpy file ndarray\n",
            "                        shapes): input0: [n,128,128,3] mean: [1,1,1,3] -> [[[[0.485, 0.456,\n",
            "                        0.406]]]] std: [1,1,1,3] -> [[[[0.229, 0.224, 0.225]]]] input1: [n,64,64]\n",
            "                        mean: [1,64] -> [0.1, ..., 0.64] std: [1,64] -> [0.05, ..., 0.08] input2:\n",
            "                        [n,5] mean: [1] -> [0.3] std: [1] -> [0.07] -cind \"input0\" \"../input0.npy\"\n",
            "                        \"[[[[0.485,0.456,0.406]]]]\" \"[[[[0.229,0.224,0.225]]]]\" -cind \"input1\"\n",
            "                        \"./input1.npy\" \"[0.1,...,0.64]\" \"[0.05,...,0.08]\" -cind \"input2\"\n",
            "                        \"input2.npy\" \"[0.3]\" \"[0.07]\" <Using -cotof and -oiqt at the same time> To\n",
            "                        use -cotof and -oiqt simultaneously, you need to enter the Input name of\n",
            "                        OP, path of data file, mean, and std all together. And the data file must\n",
            "                        be in Float32 format, and {input_op_name}, {numpy_file_path}, {mean}, and\n",
            "                        {std} must all be entered. Otherwise, an error will occur during the -oiqt\n",
            "                        stage.\n",
            "  -iqd {int8,uint8,float32}, --input_quant_dtype {int8,uint8,float32}\n",
            "                        Input dtypes when doing Full INT8 Quantization. \"int8\"(default) or \"uint8\"\n",
            "                        or \"float32\"\n",
            "  -oqd {int8,uint8,float32}, --output_quant_dtype {int8,uint8,float32}\n",
            "                        Output dtypes when doing Full INT8 Quantization. \"int8\"(default) or\n",
            "                        \"uint8\" or \"float32\"\n",
            "  -nuo, --not_use_onnxsim\n",
            "                        No optimization by onnx-simplifier is performed. If this option is used,\n",
            "                        the probability of a conversion error is very high.\n",
            "  -nuonag, --not_use_opname_auto_generate\n",
            "                        Automatic generation of each OP name in the old format ONNX file and\n",
            "                        assignment of OP name are not performed.\n",
            "  -b BATCH_SIZE, --batch_size BATCH_SIZE\n",
            "                        Fixes the dynamic batch size to the specified numeric batch size. A value\n",
            "                        of 1 or more must be specified.\n",
            "  -ois OVERWRITE_INPUT_SHAPE [OVERWRITE_INPUT_SHAPE ...], --overwrite_input_shape OVERWRITE_INPUT_SHAPE [OVERWRITE_INPUT_SHAPE ...]\n",
            "                        Overwrite the input shape. The format is \"input_name_1:dim0,...,dimN\"\n",
            "                        \"input_name_2:dim0,...,dimN\" \"input_name_3:dim0,...,dimN\". When there is\n",
            "                        only one input, for example, \"data:1,3,224,224\" When there are multiple\n",
            "                        inputs, for example, \"data1:1,3,224,224\" \"data2:1,3,112,112\" \"data3:5\" A\n",
            "                        value of 1 or more must be specified. Numerical values other than dynamic\n",
            "                        dimensions are ignored. Ignores --batch_size if specified at the same time\n",
            "                        as --batch_size.\n",
            "  -nlt, --no_large_tensor\n",
            "                        Suppresses constant bloat caused by Tile OP when optimizing models in\n",
            "                        onnxsim. See: https://github.com/daquexian/onnx-simplifier/issues/178\n",
            "  -onwdt, --output_nms_with_dynamic_tensor\n",
            "                        The number of bounding boxes in the NMS output results is not fixed at the\n",
            "                        maximum number of max_output_boxes_per_class, but rather at the smallest\n",
            "                        possible number of dynamic tensors. If this option is disabled, NMS output\n",
            "                        is padded to the number set in the max_output_boxes_per_class attribute.\n",
            "                        e.g. disable --output_nms_with_dynamic_tensor: output_tensor_shape: [100,\n",
            "                        7] enable --output_nms_with_dynamic_tensor: output_tensor_shape: [N, 7]\n",
            "  -snms {v4,v5}, --switch_nms_version {v4,v5}\n",
            "                        Switch the NMS version to V4 or V5 to convert. e.g.\n",
            "                        NonMaxSuppressionV4(default): --switch_nms_version v4 NonMaxSuppressionV5:\n",
            "                        --switch_nms_version v5\n",
            "  -k KEEP_NCW_OR_NCHW_OR_NCDHW_INPUT_NAMES [KEEP_NCW_OR_NCHW_OR_NCDHW_INPUT_NAMES ...], --keep_ncw_or_nchw_or_ncdhw_input_names KEEP_NCW_OR_NCHW_OR_NCDHW_INPUT_NAMES [KEEP_NCW_OR_NCHW_OR_NCDHW_INPUT_NAMES ...]\n",
            "                        Holds the NCW or NCHW or NCDHW of the input shape for the specified INPUT\n",
            "                        OP names. If a nonexistent INPUT OP name is specified, it is ignored.\n",
            "                        Valid only for 3D, 4D and 5D input tensors. e.g.\n",
            "                        --keep_ncw_or_nchw_or_ncdhw_input_names \"input0\" \"input1\" \"input2\"\n",
            "  -kt KEEP_NWC_OR_NHWC_OR_NDHWC_INPUT_NAMES [KEEP_NWC_OR_NHWC_OR_NDHWC_INPUT_NAMES ...], --keep_nwc_or_nhwc_or_ndhwc_input_names KEEP_NWC_OR_NHWC_OR_NDHWC_INPUT_NAMES [KEEP_NWC_OR_NHWC_OR_NDHWC_INPUT_NAMES ...]\n",
            "                        Holds the NWC or NHWC or NDHWC of the input shape for the specified INPUT\n",
            "                        OP names. If a nonexistent INPUT OP name is specified, it is ignored. If\n",
            "                        the input OP name is the same as the input OP name specified in the\n",
            "                        keep_ncw_or_nchw_or_ncdhw_input_names option, it is ignored. Valid only\n",
            "                        for 3D, 4D and 5D input tensors. e.g.\n",
            "                        --keep_nwc_or_nhwc_or_ndhwc_input_names \"input0\" \"input1\" \"input2\"\n",
            "  -kat KEEP_SHAPE_ABSOLUTELY_INPUT_NAMES [KEEP_SHAPE_ABSOLUTELY_INPUT_NAMES ...], --keep_shape_absolutely_input_names KEEP_SHAPE_ABSOLUTELY_INPUT_NAMES [KEEP_SHAPE_ABSOLUTELY_INPUT_NAMES ...]\n",
            "                        Name of the INPUT that unconditionally maintains its shape. If a\n",
            "                        nonexistent INPUT OP name is specified, it is ignored. e.g.\n",
            "                        --keep_shape_absolutely_input_names \"input0\" \"input1\" \"input2\"\n",
            "  -inimc INPUT_NAMES_TO_INTERRUPT_MODEL_CONVERSION [INPUT_NAMES_TO_INTERRUPT_MODEL_CONVERSION ...], --input_names_to_interrupt_model_conversion INPUT_NAMES_TO_INTERRUPT_MODEL_CONVERSION [INPUT_NAMES_TO_INTERRUPT_MODEL_CONVERSION ...]\n",
            "                        Input names that interrupt model conversion. Interrupts model\n",
            "                        transformation at the specified input name and inputs the model\n",
            "                        partitioned into subgraphs. e.g.\n",
            "                        --input_names_to_interrupt_model_conversion \"input0\" \"input1\" \"input2\"\n",
            "  -onimc OUTPUT_NAMES_TO_INTERRUPT_MODEL_CONVERSION [OUTPUT_NAMES_TO_INTERRUPT_MODEL_CONVERSION ...], --output_names_to_interrupt_model_conversion OUTPUT_NAMES_TO_INTERRUPT_MODEL_CONVERSION [OUTPUT_NAMES_TO_INTERRUPT_MODEL_CONVERSION ...]\n",
            "                        Output names that interrupt model conversion. Interrupts model\n",
            "                        transformation at the specified output name and outputs the model\n",
            "                        partitioned into subgraphs. e.g.\n",
            "                        --output_names_to_interrupt_model_conversion \"output0\" \"output1\" \"output2\"\n",
            "  -dgc, --disable_group_convolution\n",
            "                        Disable GroupConvolution and replace it with SeparableConvolution for\n",
            "                        output to saved_model format.\n",
            "  -eatfp16, --enable_accumulation_type_float16\n",
            "                        Hint for XNNPack fp16 inference on float16 tflite model. XNNPACK float16\n",
            "                        inference on certain ARM64 cores is 2x faster. Float16 inference doubling\n",
            "                        on devices with ARM64 ARMv8.2 or higher instruction set.\n",
            "  -ebu, --enable_batchmatmul_unfold\n",
            "                        BatchMatMul is separated batch by batch to generate a primitive MatMul.\n",
            "  -eru, --enable_rnn_unroll\n",
            "                        Instead of increasing inference speed by expanding all symbolic loops of\n",
            "                        the RNN (LSTM, GRU, RNN), RAM consumption will increase because all\n",
            "                        tensors are expanded and embedded in the model.\n",
            "                        https://keras.io/api/layers/recurrent_layers/\n",
            "  -dsft, --disable_suppression_flextranspose\n",
            "                        Disables FlexTranspose generation suppression.\n",
            "  -nodaftc NUMBER_OF_DIMENSIONS_AFTER_FLEXTRANSPOSE_COMPRESSION, --number_of_dimensions_after_flextranspose_compression NUMBER_OF_DIMENSIONS_AFTER_FLEXTRANSPOSE_COMPRESSION\n",
            "                        Number of Transpose OP dimensions generated after avoiding FlexTranspose\n",
            "                        generation. Also suppress the creation of the Transpose itself by\n",
            "                        specifying 2. Default: 6\n",
            "  -dsfs, --disable_suppression_flexstridedslice\n",
            "                        Disables FlexStridedSlice generation suppression.\n",
            "  -dsm, --disable_strict_mode\n",
            "                        If specified, the conversion speed is greatly accelerated because the\n",
            "                        strict accuracy correction process is skipped, but the frequency of\n",
            "                        transposition errors increases and accuracy errors are more likely to\n",
            "                        occur. Strict mode is enabled by default.\n",
            "  -nodafsc NUMBER_OF_DIMENSIONS_AFTER_FLEXSTRIDEDSLICE_COMPRESSION, --number_of_dimensions_after_flexstridedslice_compression NUMBER_OF_DIMENSIONS_AFTER_FLEXSTRIDEDSLICE_COMPRESSION\n",
            "                        Number of StricedSlice OP dimensions generated after avoiding\n",
            "                        FlexStridedSlice generation. Default: 5\n",
            "  -ofgd, --optimization_for_gpu_delegate\n",
            "                        Replace operations that do not support gpu delegate with those that do as\n",
            "                        much as possible.\n",
            "  -rari64, --replace_argmax_to_reducemax_and_indices_is_int64\n",
            "                        Replace ArgMax with a ReduceMax. The returned indices are int64. Only one\n",
            "                        of replace_argmax_to_reducemax_and_indices_is_int64 and\n",
            "                        replace_argmax_to_reducemax_and_indices_is_float32 and\n",
            "                        replace_argmax_to_fused_argmax_and_indices_is_int64 and\n",
            "                        replace_argmax_to_fused_argmax_and_indices_is_float32 can be specified.\n",
            "  -rarf32, --replace_argmax_to_reducemax_and_indices_is_float32\n",
            "                        Replace ArgMax with a ReduceMax. The returned indices are float32. Only\n",
            "                        one of replace_argmax_to_reducemax_and_indices_is_int64 and\n",
            "                        replace_argmax_to_reducemax_and_indices_is_float32 and\n",
            "                        replace_argmax_to_fused_argmax_and_indices_is_int64 and\n",
            "                        replace_argmax_to_fused_argmax_and_indices_is_float32 can be specified.\n",
            "  -rafi64, --replace_argmax_to_fused_argmax_and_indices_is_int64\n",
            "                        Replace ArgMax with a Fused_ArgMax. The returned indices are int64. It\n",
            "                        improves inference speed at the cost of a small sacrifice in accuracy.\n",
            "                        See. https://github.com/tensorflow/models/tree/master/official/projects/ed\n",
            "                        getpu/vision#argmax-fusion-to-improve-segmentation-model-latency\n",
            "                        Currently, only 4D tensors are supported. Only one of\n",
            "                        replace_argmax_to_reducemax_and_indices_is_int64 and\n",
            "                        replace_argmax_to_reducemax_and_indices_is_float32 and\n",
            "                        replace_argmax_to_fused_argmax_and_indices_is_int64 and\n",
            "                        replace_argmax_to_fused_argmax_and_indices_is_float32 can be specified.\n",
            "  -raff32, --replace_argmax_to_fused_argmax_and_indices_is_float32\n",
            "                        Replace ArgMax with a Fused_ArgMax. The returned indices are float32. It\n",
            "                        improves inference speed at the cost of a small sacrifice in accuracy.\n",
            "                        See. https://github.com/tensorflow/models/tree/master/official/projects/ed\n",
            "                        getpu/vision#argmax-fusion-to-improve-segmentation-model-latency\n",
            "                        Currently, only 4D tensors are supported. Only one of\n",
            "                        replace_argmax_to_reducemax_and_indices_is_int64 and\n",
            "                        replace_argmax_to_reducemax_and_indices_is_float32 and\n",
            "                        replace_argmax_to_fused_argmax_and_indices_is_int64 and\n",
            "                        replace_argmax_to_fused_argmax_and_indices_is_float32 can be specified.\n",
            "  -fasr FUSED_ARGMAX_SCALE_RATIO, --fused_argmax_scale_ratio FUSED_ARGMAX_SCALE_RATIO\n",
            "                        For Fused ArgMax. Scale ratio when generating Fused ArgMax. 0.0 <\n",
            "                        fused_argmax_scale_ratio <= 1.0 Default: 0.5\n",
            "  -rtpo [REPLACE_TO_PSEUDO_OPERATORS ...], --replace_to_pseudo_operators [REPLACE_TO_PSEUDO_OPERATORS ...]\n",
            "                        Replace list of operators to pseudo operators. Full name of the target\n",
            "                        operators should be given. Currently supported operators : Asin, Acos,\n",
            "                        Atan, Abs, PReLU, LeakyReLU, Power, GatherND, Neg, HardSwish, Erf, GeLU,\n",
            "                        MatMulInteger\n",
            "  -me MVN_EPSILON, --mvn_epsilon MVN_EPSILON\n",
            "                        For MeanVarianceNormalization. The number to be added to the variance to\n",
            "                        avoid division by zero when normalizing the value. (input_tensor - mean) /\n",
            "                        tf.sqrt(variance + mvn_epsilon) Default: 0.0000000001\n",
            "  -prf PARAM_REPLACEMENT_FILE, --param_replacement_file PARAM_REPLACEMENT_FILE\n",
            "                        Parameter replacement file path. (.json)\n",
            "  -cgdc, --check_gpu_delegate_compatibility\n",
            "                        Run TFLite ModelAnalyzer on the generated Float16 tflite model to check if\n",
            "                        the model can be supported by GPU Delegate.\n",
            "  -coto, --check_onnx_tf_outputs_elementwise_close\n",
            "                        Returns \"Matches\" if the output of onnx and the output of TF arewithin\n",
            "                        acceptable proximity element by element. Returns \"Unmatched\" if the output\n",
            "                        of onnx and the output of TF are not within acceptable proximity element\n",
            "                        by element. If the output of onnx is 1D, it returns \"Skipped\" and skips\n",
            "                        the comparison between the output of onnx and that of TF. This is because\n",
            "                        when undefined dimensions are present, a situation often arises where very\n",
            "                        large index values are compared, causing OutOfMemory. Only the output\n",
            "                        content of the models final output OP is checked.\n",
            "  -cotof, --check_onnx_tf_outputs_elementwise_close_full\n",
            "                        Returns \"Matches\" if the output of onnx and the output of TF are within\n",
            "                        acceptable proximity element by element. Check the output of all OPs in\n",
            "                        sequence from the beginning, including all but the final output OP of the\n",
            "                        model. Returns \"Unmatched\" if the output of onnx and the output of TF are\n",
            "                        not within acceptable proximity element by element. If the output of onnx\n",
            "                        is 1D, it returns \"Skipped\" and skips the comparison between the output of\n",
            "                        onnx and that of TF. This is because when undefined dimensions are\n",
            "                        present, a situation often arises where very large index values are\n",
            "                        compared, causing OutOfMemory. It is very time consuming because it\n",
            "                        performs as many inferences as there are operations.\n",
            "  -coton {norm,denorm}, --check_onnx_tf_outputs_sample_data_normalization {norm,denorm}\n",
            "                        norm: Validate using random data normalized to the range 0.0 to 1.0\n",
            "                        denorm: Validate using random data in the range 0.0 to 255.0 If there is a\n",
            "                        normalization layer at the models entry point, or if the model was trained\n",
            "                        on denormalized data, \"denorm\" must be specified. Default: \"norm\"\n",
            "  -cotor CHECK_ONNX_TF_OUTPUTS_ELEMENTWISE_CLOSE_RTOL, --check_onnx_tf_outputs_elementwise_close_rtol CHECK_ONNX_TF_OUTPUTS_ELEMENTWISE_CLOSE_RTOL\n",
            "                        The relative tolerance parameter Default: 0.0\n",
            "  -cotoa CHECK_ONNX_TF_OUTPUTS_ELEMENTWISE_CLOSE_ATOL, --check_onnx_tf_outputs_elementwise_close_atol CHECK_ONNX_TF_OUTPUTS_ELEMENTWISE_CLOSE_ATOL\n",
            "                        The absolute tolerance parameter Default: 1e-4\n",
            "  -dms, --disable_model_save\n",
            "                        Does not save the converted model. For CIs RAM savings.\n",
            "  -n, --non_verbose     Shorthand to specify a verbosity of \"error\".\n",
            "  -v {debug,info,warn,error}, --verbosity {debug,info,warn,error}\n",
            "                        Change the level of information printed. Default: \"debug\" (for backwards\n",
            "                        compatability)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import onnx\n",
        "from tensorflow.keras.models import load_model\n",
        "onnx_model_path = '/content/drive/MyDrive/saved_models/onnx_models/mobile_pruned_finetuned.onnx'\n",
        "model = onnx.load(onnx_model_path)\n",
        "\n",
        "# Check input details\n",
        "for input_tensor in model.graph.input:\n",
        "    print(f\"Input Name: {input_tensor.name}\")\n",
        "    shape = [dim.dim_value for dim in input_tensor.type.tensor_type.shape.dim]\n",
        "    print(f\"Input Shape: {shape}\")\n",
        "    print(f\"Data Type: {input_tensor.type.tensor_type.elem_type}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jf59IFu-1abm",
        "outputId": "af8a28ee-0a84-4f22-fed9-ffb9649b4dd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Name: input\n",
            "Input Shape: [1, 3, 224, 224]\n",
            "Data Type: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!onnx2tf -i mobile_pruned_finetuned.onnx -o mobile_pruned_finetuned -k KEEP_NCW_OR_NCHW_OR_NCDHW_INPUT_NAMES input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8E1TylwlI10G",
        "outputId": "c1f4d92f-cd5c-40d6-f8f3-4ad61504407d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1741376760.568247    3448 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1741376760.589071    3448 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\n",
            "\u001b[07mModel optimizing started\u001b[0m ============================================================\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/onnx2tf/onnx2tf.py\", line 652, in convert\n",
            "    result = subprocess.check_output(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/subprocess.py\", line 466, in check_output\n",
            "    return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/subprocess.py\", line 548, in run\n",
            "    with Popen(*popenargs, **kwargs) as process:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/subprocess.py\", line 1026, in __init__\n",
            "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
            "  File \"/usr/lib/python3.11/subprocess.py\", line 1955, in _execute_child\n",
            "    raise child_exception_type(errno_num, err_msg, err_filename)\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'onnxsim'\n",
            "\n",
            "\u001b[33mWARNING:\u001b[0m Failed to optimize the onnx file.\n",
            "\n",
            "\u001b[07mAutomatic generation of each OP name started\u001b[0m ========================================\n",
            "\u001b[32mAutomatic generation of each OP name complete!\u001b[0m\n",
            "\n",
            "\u001b[07mModel loaded\u001b[0m ========================================================================\n",
            "\n",
            "\u001b[07mModel conversion started\u001b[0m ============================================================\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32minput_op_name\u001b[0m: input \u001b[32mshape\u001b[0m: [1, 3, 224, 224] \u001b[32mdtype\u001b[0m: float32\n",
            "\u001b[33mWARNING:\u001b[0m The optimization process for shape estimation is skipped because it contains OPs that cannot be inferred by the standard onnxruntime.\n",
            "\u001b[33mWARNING:\u001b[0m name 'ort' is not defined\n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m2 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.0/features.0.0/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input \u001b[36mshape\u001b[0m: [1, 3, 224, 224] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_568 \u001b[36mshape\u001b[0m: [32, 3, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_569 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.0/features.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 112, 112] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad/Pad:0 \u001b[34mshape\u001b[0m: (1, 226, 226, 3) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 3, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add/Add:0 \u001b[34mshape\u001b[0m: (1, 112, 112, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m73 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/features/features.0/features.0.2/Clip\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.0/features.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 112, 112] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/features/features.0/features.0.2/Constant_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/features/features.0/features.0.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.0/features.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 112, 112] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add/Add:0 \u001b[34mshape\u001b[0m: (1, 112, 112, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6/Relu6:0 \u001b[34mshape\u001b[0m: (1, 112, 112, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m74 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.1/conv/conv.0/conv.0.0/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.0/features.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 112, 112] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_571 \u001b[36mshape\u001b[0m: [32, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_572 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.1/conv/conv.0/conv.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 112, 112] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6/Relu6:0 \u001b[34mshape\u001b[0m: (1, 112, 112, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 32, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_1/Add:0 \u001b[34mshape\u001b[0m: (1, 112, 112, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m75 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/features/features.1/conv/conv.0/conv.0.2/Clip\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.1/conv/conv.0/conv.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 112, 112] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/features/features.1/conv/conv.0/conv.0.2/Constant_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/features/features.1/conv/conv.0/conv.0.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.1/conv/conv.0/conv.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 112, 112] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_1/Add:0 \u001b[34mshape\u001b[0m: (1, 112, 112, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_1/Relu6:0 \u001b[34mshape\u001b[0m: (1, 112, 112, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m76 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.1/conv/conv.1/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.1/conv/conv.0/conv.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 112, 112] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_574 \u001b[36mshape\u001b[0m: [16, 32, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_575 \u001b[36mshape\u001b[0m: [16] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.1/conv/conv.1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 16, 112, 112] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_1/Relu6:0 \u001b[34mshape\u001b[0m: (1, 112, 112, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 32, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (16,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_2/Add:0 \u001b[34mshape\u001b[0m: (1, 112, 112, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m77 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.2/conv/conv.0/conv.0.0/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.1/conv/conv.1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 16, 112, 112] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_577 \u001b[36mshape\u001b[0m: [32, 16, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_578 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.2/conv/conv.0/conv.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 112, 112] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_2/Add:0 \u001b[34mshape\u001b[0m: (1, 112, 112, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 16, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_3/Add:0 \u001b[34mshape\u001b[0m: (1, 112, 112, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m78 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/features/features.2/conv/conv.0/conv.0.2/Clip\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.2/conv/conv.0/conv.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 112, 112] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/features/features.2/conv/conv.0/conv.0.2/Constant_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/features/features.2/conv/conv.0/conv.0.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.2/conv/conv.0/conv.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 112, 112] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_3/Add:0 \u001b[34mshape\u001b[0m: (1, 112, 112, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_2/Relu6:0 \u001b[34mshape\u001b[0m: (1, 112, 112, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m79 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.2/conv/conv.1/conv.1.0/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.2/conv/conv.0/conv.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 112, 112] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_580 \u001b[36mshape\u001b[0m: [32, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_581 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.2/conv/conv.1/conv.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 56, 56] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_1/Pad:0 \u001b[34mshape\u001b[0m: (1, 114, 114, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 32, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 2, 2, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_4/Add:0 \u001b[34mshape\u001b[0m: (1, 56, 56, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m80 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/features/features.2/conv/conv.1/conv.1.2/Clip\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.2/conv/conv.1/conv.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 56, 56] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/features/features.2/conv/conv.1/conv.1.2/Constant_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/features/features.2/conv/conv.1/conv.1.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.2/conv/conv.1/conv.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 56, 56] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_4/Add:0 \u001b[34mshape\u001b[0m: (1, 56, 56, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_3/Relu6:0 \u001b[34mshape\u001b[0m: (1, 56, 56, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m81 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.2/conv/conv.2/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.2/conv/conv.1/conv.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 56, 56] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_583 \u001b[36mshape\u001b[0m: [24, 32, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_584 \u001b[36mshape\u001b[0m: [24] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.2/conv/conv.2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 24, 56, 56] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_3/Relu6:0 \u001b[34mshape\u001b[0m: (1, 56, 56, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 32, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (24,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_5/Add:0 \u001b[34mshape\u001b[0m: (1, 56, 56, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m82 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.3/conv/conv.0/conv.0.0/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.2/conv/conv.2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 24, 56, 56] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_586 \u001b[36mshape\u001b[0m: [32, 24, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_587 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.3/conv/conv.0/conv.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 56, 56] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_5/Add:0 \u001b[34mshape\u001b[0m: (1, 56, 56, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 24, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_6/Add:0 \u001b[34mshape\u001b[0m: (1, 56, 56, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m83 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/features/features.3/conv/conv.0/conv.0.2/Clip\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.3/conv/conv.0/conv.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 56, 56] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/features/features.3/conv/conv.0/conv.0.2/Constant_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/features/features.3/conv/conv.0/conv.0.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.3/conv/conv.0/conv.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 56, 56] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_6/Add:0 \u001b[34mshape\u001b[0m: (1, 56, 56, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_4/Relu6:0 \u001b[34mshape\u001b[0m: (1, 56, 56, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m84 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.3/conv/conv.1/conv.1.0/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.3/conv/conv.0/conv.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 56, 56] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_589 \u001b[36mshape\u001b[0m: [32, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_590 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.3/conv/conv.1/conv.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 56, 56] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_4/Relu6:0 \u001b[34mshape\u001b[0m: (1, 56, 56, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 32, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_7/Add:0 \u001b[34mshape\u001b[0m: (1, 56, 56, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m85 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/features/features.3/conv/conv.1/conv.1.2/Clip\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.3/conv/conv.1/conv.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 56, 56] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/features/features.3/conv/conv.1/conv.1.2/Constant_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/features/features.3/conv/conv.1/conv.1.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.3/conv/conv.1/conv.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 56, 56] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_7/Add:0 \u001b[34mshape\u001b[0m: (1, 56, 56, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_5/Relu6:0 \u001b[34mshape\u001b[0m: (1, 56, 56, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m86 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.3/conv/conv.2/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.3/conv/conv.1/conv.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 56, 56] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_592 \u001b[36mshape\u001b[0m: [24, 32, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_593 \u001b[36mshape\u001b[0m: [24] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.3/conv/conv.2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 24, 56, 56] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_5/Relu6:0 \u001b[34mshape\u001b[0m: (1, 56, 56, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 32, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (24,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_8/Add:0 \u001b[34mshape\u001b[0m: (1, 56, 56, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m87 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/features/features.3/Add\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.2/conv/conv.2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 24, 56, 56] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/features/features.3/conv/conv.2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 24, 56, 56] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.3/Add_output_0 \u001b[36mshape\u001b[0m: [1, 24, 56, 56] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_5/Add:0 \u001b[34mshape\u001b[0m: (1, 56, 56, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_8/Add:0 \u001b[34mshape\u001b[0m: (1, 56, 56, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_9/Add:0 \u001b[34mshape\u001b[0m: (1, 56, 56, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m88 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.4/conv/conv.0/conv.0.0/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.3/Add_output_0 \u001b[36mshape\u001b[0m: [1, 24, 56, 56] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_595 \u001b[36mshape\u001b[0m: [32, 24, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_596 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.4/conv/conv.0/conv.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 56, 56] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_9/Add:0 \u001b[34mshape\u001b[0m: (1, 56, 56, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 24, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_10/Add:0 \u001b[34mshape\u001b[0m: (1, 56, 56, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m89 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/features/features.4/conv/conv.0/conv.0.2/Clip\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.4/conv/conv.0/conv.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 56, 56] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/features/features.4/conv/conv.0/conv.0.2/Constant_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/features/features.4/conv/conv.0/conv.0.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.4/conv/conv.0/conv.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 56, 56] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_10/Add:0 \u001b[34mshape\u001b[0m: (1, 56, 56, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_6/Relu6:0 \u001b[34mshape\u001b[0m: (1, 56, 56, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m90 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.4/conv/conv.1/conv.1.0/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.4/conv/conv.0/conv.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 56, 56] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_598 \u001b[36mshape\u001b[0m: [32, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_599 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.4/conv/conv.1/conv.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 28, 28] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_2/Pad:0 \u001b[34mshape\u001b[0m: (1, 58, 58, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 32, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 2, 2, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_11/Add:0 \u001b[34mshape\u001b[0m: (1, 28, 28, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m91 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/features/features.4/conv/conv.1/conv.1.2/Clip\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.4/conv/conv.1/conv.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 28, 28] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/features/features.4/conv/conv.1/conv.1.2/Constant_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/features/features.4/conv/conv.1/conv.1.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.4/conv/conv.1/conv.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 28, 28] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_11/Add:0 \u001b[34mshape\u001b[0m: (1, 28, 28, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_7/Relu6:0 \u001b[34mshape\u001b[0m: (1, 28, 28, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m92 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.4/conv/conv.2/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.4/conv/conv.1/conv.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 28, 28] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_601 \u001b[36mshape\u001b[0m: [32, 32, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_602 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.4/conv/conv.2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 28, 28] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_7/Relu6:0 \u001b[34mshape\u001b[0m: (1, 28, 28, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 32, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_12/Add:0 \u001b[34mshape\u001b[0m: (1, 28, 28, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m93 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.5/conv/conv.0/conv.0.0/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.4/conv/conv.2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 28, 28] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_604 \u001b[36mshape\u001b[0m: [32, 32, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_605 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.5/conv/conv.0/conv.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 28, 28] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_12/Add:0 \u001b[34mshape\u001b[0m: (1, 28, 28, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 32, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_13/Add:0 \u001b[34mshape\u001b[0m: (1, 28, 28, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m94 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/features/features.5/conv/conv.0/conv.0.2/Clip\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.5/conv/conv.0/conv.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 28, 28] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/features/features.5/conv/conv.0/conv.0.2/Constant_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/features/features.5/conv/conv.0/conv.0.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.5/conv/conv.0/conv.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 28, 28] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_13/Add:0 \u001b[34mshape\u001b[0m: (1, 28, 28, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_8/Relu6:0 \u001b[34mshape\u001b[0m: (1, 28, 28, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m95 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.5/conv/conv.1/conv.1.0/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.5/conv/conv.0/conv.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 28, 28] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_607 \u001b[36mshape\u001b[0m: [32, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_608 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.5/conv/conv.1/conv.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 28, 28] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_8/Relu6:0 \u001b[34mshape\u001b[0m: (1, 28, 28, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 32, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_14/Add:0 \u001b[34mshape\u001b[0m: (1, 28, 28, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m96 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/features/features.5/conv/conv.1/conv.1.2/Clip\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.5/conv/conv.1/conv.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 28, 28] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/features/features.5/conv/conv.1/conv.1.2/Constant_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/features/features.5/conv/conv.1/conv.1.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.5/conv/conv.1/conv.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 28, 28] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_14/Add:0 \u001b[34mshape\u001b[0m: (1, 28, 28, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_9/Relu6:0 \u001b[34mshape\u001b[0m: (1, 28, 28, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m97 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.5/conv/conv.2/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.5/conv/conv.1/conv.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 28, 28] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_610 \u001b[36mshape\u001b[0m: [32, 32, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_611 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.5/conv/conv.2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 28, 28] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_9/Relu6:0 \u001b[34mshape\u001b[0m: (1, 28, 28, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 32, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_15/Add:0 \u001b[34mshape\u001b[0m: (1, 28, 28, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m98 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/features/features.5/Add\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.4/conv/conv.2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 28, 28] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/features/features.5/conv/conv.2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 28, 28] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.5/Add_output_0 \u001b[36mshape\u001b[0m: [1, 32, 28, 28] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_12/Add:0 \u001b[34mshape\u001b[0m: (1, 28, 28, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_15/Add:0 \u001b[34mshape\u001b[0m: (1, 28, 28, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_16/Add:0 \u001b[34mshape\u001b[0m: (1, 28, 28, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m99 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.6/conv/conv.0/conv.0.0/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.5/Add_output_0 \u001b[36mshape\u001b[0m: [1, 32, 28, 28] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_613 \u001b[36mshape\u001b[0m: [32, 32, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_614 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.6/conv/conv.0/conv.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 28, 28] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_16/Add:0 \u001b[34mshape\u001b[0m: (1, 28, 28, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 32, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_17/Add:0 \u001b[34mshape\u001b[0m: (1, 28, 28, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m100 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/features/features.6/conv/conv.0/conv.0.2/Clip\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.6/conv/conv.0/conv.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 28, 28] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/features/features.6/conv/conv.0/conv.0.2/Constant_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/features/features.6/conv/conv.0/conv.0.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.6/conv/conv.0/conv.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 28, 28] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_17/Add:0 \u001b[34mshape\u001b[0m: (1, 28, 28, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_10/Relu6:0 \u001b[34mshape\u001b[0m: (1, 28, 28, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m101 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.6/conv/conv.1/conv.1.0/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.6/conv/conv.0/conv.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 28, 28] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_616 \u001b[36mshape\u001b[0m: [32, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_617 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.6/conv/conv.1/conv.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 28, 28] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_10/Relu6:0 \u001b[34mshape\u001b[0m: (1, 28, 28, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 32, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_18/Add:0 \u001b[34mshape\u001b[0m: (1, 28, 28, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m102 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/features/features.6/conv/conv.1/conv.1.2/Clip\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.6/conv/conv.1/conv.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 28, 28] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/features/features.6/conv/conv.1/conv.1.2/Constant_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/features/features.6/conv/conv.1/conv.1.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.6/conv/conv.1/conv.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 28, 28] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_18/Add:0 \u001b[34mshape\u001b[0m: (1, 28, 28, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_11/Relu6:0 \u001b[34mshape\u001b[0m: (1, 28, 28, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m103 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.6/conv/conv.2/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.6/conv/conv.1/conv.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 28, 28] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_619 \u001b[36mshape\u001b[0m: [32, 32, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_620 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.6/conv/conv.2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 28, 28] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_11/Relu6:0 \u001b[34mshape\u001b[0m: (1, 28, 28, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 32, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_19/Add:0 \u001b[34mshape\u001b[0m: (1, 28, 28, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m104 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/features/features.6/Add\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.5/Add_output_0 \u001b[36mshape\u001b[0m: [1, 32, 28, 28] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/features/features.6/conv/conv.2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 28, 28] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.6/Add_output_0 \u001b[36mshape\u001b[0m: [1, 32, 28, 28] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_16/Add:0 \u001b[34mshape\u001b[0m: (1, 28, 28, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_19/Add:0 \u001b[34mshape\u001b[0m: (1, 28, 28, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_20/Add:0 \u001b[34mshape\u001b[0m: (1, 28, 28, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m105 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.7/conv/conv.0/conv.0.0/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.6/Add_output_0 \u001b[36mshape\u001b[0m: [1, 32, 28, 28] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_622 \u001b[36mshape\u001b[0m: [32, 32, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_623 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.7/conv/conv.0/conv.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 28, 28] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_20/Add:0 \u001b[34mshape\u001b[0m: (1, 28, 28, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 32, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_21/Add:0 \u001b[34mshape\u001b[0m: (1, 28, 28, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m106 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/features/features.7/conv/conv.0/conv.0.2/Clip\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.7/conv/conv.0/conv.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 28, 28] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/features/features.7/conv/conv.0/conv.0.2/Constant_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/features/features.7/conv/conv.0/conv.0.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.7/conv/conv.0/conv.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 28, 28] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_21/Add:0 \u001b[34mshape\u001b[0m: (1, 28, 28, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_12/Relu6:0 \u001b[34mshape\u001b[0m: (1, 28, 28, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m107 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.7/conv/conv.1/conv.1.0/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.7/conv/conv.0/conv.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 28, 28] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_625 \u001b[36mshape\u001b[0m: [32, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_626 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.7/conv/conv.1/conv.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_3/Pad:0 \u001b[34mshape\u001b[0m: (1, 30, 30, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 32, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 2, 2, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_22/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m108 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/features/features.7/conv/conv.1/conv.1.2/Clip\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.7/conv/conv.1/conv.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/features/features.7/conv/conv.1/conv.1.2/Constant_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/features/features.7/conv/conv.1/conv.1.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.7/conv/conv.1/conv.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_22/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_13/Relu6:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m109 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.7/conv/conv.2/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.7/conv/conv.1/conv.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_628 \u001b[36mshape\u001b[0m: [32, 32, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_629 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.7/conv/conv.2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_13/Relu6:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 32, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_23/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m110 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.8/conv/conv.0/conv.0.0/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.7/conv/conv.2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_631 \u001b[36mshape\u001b[0m: [32, 32, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_632 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.8/conv/conv.0/conv.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_23/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 32, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_24/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m111 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/features/features.8/conv/conv.0/conv.0.2/Clip\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.8/conv/conv.0/conv.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/features/features.8/conv/conv.0/conv.0.2/Constant_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/features/features.8/conv/conv.0/conv.0.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.8/conv/conv.0/conv.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_24/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_14/Relu6:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m112 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.8/conv/conv.1/conv.1.0/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.8/conv/conv.0/conv.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_634 \u001b[36mshape\u001b[0m: [32, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_635 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.8/conv/conv.1/conv.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_14/Relu6:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 32, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_25/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m113 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/features/features.8/conv/conv.1/conv.1.2/Clip\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.8/conv/conv.1/conv.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/features/features.8/conv/conv.1/conv.1.2/Constant_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/features/features.8/conv/conv.1/conv.1.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.8/conv/conv.1/conv.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_25/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_15/Relu6:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m114 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.8/conv/conv.2/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.8/conv/conv.1/conv.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_637 \u001b[36mshape\u001b[0m: [32, 32, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_638 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.8/conv/conv.2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_15/Relu6:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 32, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_26/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m115 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/features/features.8/Add\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.7/conv/conv.2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/features/features.8/conv/conv.2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.8/Add_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_23/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_26/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_27/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m116 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.9/conv/conv.0/conv.0.0/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.8/Add_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_640 \u001b[36mshape\u001b[0m: [32, 32, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_641 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.9/conv/conv.0/conv.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_27/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 32, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_28/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m117 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/features/features.9/conv/conv.0/conv.0.2/Clip\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.9/conv/conv.0/conv.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/features/features.9/conv/conv.0/conv.0.2/Constant_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/features/features.9/conv/conv.0/conv.0.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.9/conv/conv.0/conv.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_28/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_16/Relu6:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m118 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.9/conv/conv.1/conv.1.0/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.9/conv/conv.0/conv.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_643 \u001b[36mshape\u001b[0m: [32, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_644 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.9/conv/conv.1/conv.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_16/Relu6:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 32, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_29/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m119 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/features/features.9/conv/conv.1/conv.1.2/Clip\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.9/conv/conv.1/conv.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/features/features.9/conv/conv.1/conv.1.2/Constant_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/features/features.9/conv/conv.1/conv.1.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.9/conv/conv.1/conv.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_29/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_17/Relu6:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m120 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.9/conv/conv.2/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.9/conv/conv.1/conv.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_646 \u001b[36mshape\u001b[0m: [32, 32, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_647 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.9/conv/conv.2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_17/Relu6:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 32, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_30/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m121 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/features/features.9/Add\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.8/Add_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/features/features.9/conv/conv.2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.9/Add_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_27/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_30/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_31/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m122 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.10/conv/conv.0/conv.0.0/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.9/Add_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_649 \u001b[36mshape\u001b[0m: [32, 32, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_650 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.10/conv/conv.0/conv.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_31/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 32, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_32/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m123 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/features/features.10/conv/conv.0/conv.0.2/Clip\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.10/conv/conv.0/conv.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/features/features.10/conv/conv.0/conv.0.2/Constant_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/features/features.10/conv/conv.0/conv.0.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.10/conv/conv.0/conv.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_32/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_18/Relu6:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m124 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.10/conv/conv.1/conv.1.0/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.10/conv/conv.0/conv.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_652 \u001b[36mshape\u001b[0m: [32, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_653 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.10/conv/conv.1/conv.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_18/Relu6:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 32, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_33/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m125 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/features/features.10/conv/conv.1/conv.1.2/Clip\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.10/conv/conv.1/conv.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/features/features.10/conv/conv.1/conv.1.2/Constant_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/features/features.10/conv/conv.1/conv.1.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.10/conv/conv.1/conv.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_33/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_19/Relu6:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m126 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.10/conv/conv.2/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.10/conv/conv.1/conv.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_655 \u001b[36mshape\u001b[0m: [32, 32, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_656 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.10/conv/conv.2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_19/Relu6:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 32, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_34/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m127 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/features/features.10/Add\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.9/Add_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/features/features.10/conv/conv.2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.10/Add_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_31/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_34/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_35/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m128 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.11/conv/conv.0/conv.0.0/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.10/Add_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_658 \u001b[36mshape\u001b[0m: [32, 32, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_659 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.11/conv/conv.0/conv.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_35/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 32, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_36/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m129 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/features/features.11/conv/conv.0/conv.0.2/Clip\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.11/conv/conv.0/conv.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/features/features.11/conv/conv.0/conv.0.2/Constant_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/features/features.11/conv/conv.0/conv.0.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.11/conv/conv.0/conv.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_36/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_20/Relu6:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m130 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.11/conv/conv.1/conv.1.0/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.11/conv/conv.0/conv.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_661 \u001b[36mshape\u001b[0m: [32, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_662 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.11/conv/conv.1/conv.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_20/Relu6:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 32, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_37/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m131 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/features/features.11/conv/conv.1/conv.1.2/Clip\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.11/conv/conv.1/conv.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/features/features.11/conv/conv.1/conv.1.2/Constant_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/features/features.11/conv/conv.1/conv.1.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.11/conv/conv.1/conv.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_37/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_21/Relu6:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m132 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.11/conv/conv.2/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.11/conv/conv.1/conv.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_664 \u001b[36mshape\u001b[0m: [32, 32, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_665 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.11/conv/conv.2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_21/Relu6:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 32, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_38/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m133 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.12/conv/conv.0/conv.0.0/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.11/conv/conv.2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_667 \u001b[36mshape\u001b[0m: [32, 32, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_668 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.12/conv/conv.0/conv.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_38/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 32, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_39/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m134 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/features/features.12/conv/conv.0/conv.0.2/Clip\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.12/conv/conv.0/conv.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/features/features.12/conv/conv.0/conv.0.2/Constant_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/features/features.12/conv/conv.0/conv.0.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.12/conv/conv.0/conv.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_39/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_22/Relu6:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m135 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.12/conv/conv.1/conv.1.0/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.12/conv/conv.0/conv.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_670 \u001b[36mshape\u001b[0m: [32, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_671 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.12/conv/conv.1/conv.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_22/Relu6:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 32, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_40/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m136 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/features/features.12/conv/conv.1/conv.1.2/Clip\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.12/conv/conv.1/conv.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/features/features.12/conv/conv.1/conv.1.2/Constant_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/features/features.12/conv/conv.1/conv.1.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.12/conv/conv.1/conv.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_40/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_23/Relu6:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m137 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.12/conv/conv.2/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.12/conv/conv.1/conv.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_673 \u001b[36mshape\u001b[0m: [32, 32, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_674 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.12/conv/conv.2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_23/Relu6:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 32, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_41/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m138 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/features/features.12/Add\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.11/conv/conv.2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/features/features.12/conv/conv.2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.12/Add_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_38/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_41/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_42/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m139 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.13/conv/conv.0/conv.0.0/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.12/Add_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_676 \u001b[36mshape\u001b[0m: [32, 32, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_677 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.13/conv/conv.0/conv.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_42/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 32, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_43/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m140 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/features/features.13/conv/conv.0/conv.0.2/Clip\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.13/conv/conv.0/conv.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/features/features.13/conv/conv.0/conv.0.2/Constant_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/features/features.13/conv/conv.0/conv.0.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.13/conv/conv.0/conv.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_43/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_24/Relu6:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m141 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.13/conv/conv.1/conv.1.0/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.13/conv/conv.0/conv.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_679 \u001b[36mshape\u001b[0m: [32, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_680 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.13/conv/conv.1/conv.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_24/Relu6:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 32, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_44/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m142 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/features/features.13/conv/conv.1/conv.1.2/Clip\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.13/conv/conv.1/conv.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/features/features.13/conv/conv.1/conv.1.2/Constant_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/features/features.13/conv/conv.1/conv.1.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.13/conv/conv.1/conv.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_44/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_25/Relu6:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m143 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.13/conv/conv.2/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.13/conv/conv.1/conv.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_682 \u001b[36mshape\u001b[0m: [32, 32, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_683 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.13/conv/conv.2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_25/Relu6:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 32, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_45/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m144 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/features/features.13/Add\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.12/Add_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/features/features.13/conv/conv.2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.13/Add_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_42/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_45/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_46/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m145 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.14/conv/conv.0/conv.0.0/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.13/Add_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_685 \u001b[36mshape\u001b[0m: [32, 32, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_686 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.14/conv/conv.0/conv.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_46/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 32, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_47/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m146 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/features/features.14/conv/conv.0/conv.0.2/Clip\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.14/conv/conv.0/conv.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/features/features.14/conv/conv.0/conv.0.2/Constant_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/features/features.14/conv/conv.0/conv.0.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.14/conv/conv.0/conv.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_47/Add:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_26/Relu6:0 \u001b[34mshape\u001b[0m: (1, 14, 14, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m147 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.14/conv/conv.1/conv.1.0/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.14/conv/conv.0/conv.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 14, 14] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_688 \u001b[36mshape\u001b[0m: [32, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_689 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.14/conv/conv.1/conv.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 7, 7] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_4/Pad:0 \u001b[34mshape\u001b[0m: (1, 16, 16, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 32, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 2, 2, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_48/Add:0 \u001b[34mshape\u001b[0m: (1, 7, 7, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m148 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/features/features.14/conv/conv.1/conv.1.2/Clip\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.14/conv/conv.1/conv.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 7, 7] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/features/features.14/conv/conv.1/conv.1.2/Constant_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/features/features.14/conv/conv.1/conv.1.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.14/conv/conv.1/conv.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 7, 7] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_48/Add:0 \u001b[34mshape\u001b[0m: (1, 7, 7, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_27/Relu6:0 \u001b[34mshape\u001b[0m: (1, 7, 7, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m149 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.14/conv/conv.2/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.14/conv/conv.1/conv.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 32, 7, 7] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_691 \u001b[36mshape\u001b[0m: [32, 32, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_692 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.14/conv/conv.2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 7, 7] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_27/Relu6:0 \u001b[34mshape\u001b[0m: (1, 7, 7, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 32, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_49/Add:0 \u001b[34mshape\u001b[0m: (1, 7, 7, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m150 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.15/conv/conv.0/conv.0.0/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.14/conv/conv.2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 7, 7] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_694 \u001b[36mshape\u001b[0m: [64, 32, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_695 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.15/conv/conv.0/conv.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 7, 7] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_49/Add:0 \u001b[34mshape\u001b[0m: (1, 7, 7, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 32, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_50/Add:0 \u001b[34mshape\u001b[0m: (1, 7, 7, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m151 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/features/features.15/conv/conv.0/conv.0.2/Clip\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.15/conv/conv.0/conv.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 7, 7] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/features/features.15/conv/conv.0/conv.0.2/Constant_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/features/features.15/conv/conv.0/conv.0.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.15/conv/conv.0/conv.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 64, 7, 7] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_50/Add:0 \u001b[34mshape\u001b[0m: (1, 7, 7, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_28/Relu6:0 \u001b[34mshape\u001b[0m: (1, 7, 7, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m152 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.15/conv/conv.1/conv.1.0/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.15/conv/conv.0/conv.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 64, 7, 7] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_697 \u001b[36mshape\u001b[0m: [64, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_698 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.15/conv/conv.1/conv.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 7, 7] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_28/Relu6:0 \u001b[34mshape\u001b[0m: (1, 7, 7, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 64, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 64 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_51/Add:0 \u001b[34mshape\u001b[0m: (1, 7, 7, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m153 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/features/features.15/conv/conv.1/conv.1.2/Clip\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.15/conv/conv.1/conv.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 7, 7] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/features/features.15/conv/conv.1/conv.1.2/Constant_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/features/features.15/conv/conv.1/conv.1.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.15/conv/conv.1/conv.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 64, 7, 7] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_51/Add:0 \u001b[34mshape\u001b[0m: (1, 7, 7, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_29/Relu6:0 \u001b[34mshape\u001b[0m: (1, 7, 7, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m154 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.15/conv/conv.2/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.15/conv/conv.1/conv.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 64, 7, 7] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_700 \u001b[36mshape\u001b[0m: [32, 64, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_701 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.15/conv/conv.2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 7, 7] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_29/Relu6:0 \u001b[34mshape\u001b[0m: (1, 7, 7, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 64, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_52/Add:0 \u001b[34mshape\u001b[0m: (1, 7, 7, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m155 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/features/features.15/Add\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.14/conv/conv.2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 7, 7] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/features/features.15/conv/conv.2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 7, 7] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.15/Add_output_0 \u001b[36mshape\u001b[0m: [1, 32, 7, 7] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_49/Add:0 \u001b[34mshape\u001b[0m: (1, 7, 7, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_52/Add:0 \u001b[34mshape\u001b[0m: (1, 7, 7, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_53/Add:0 \u001b[34mshape\u001b[0m: (1, 7, 7, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m156 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.16/conv/conv.0/conv.0.0/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.15/Add_output_0 \u001b[36mshape\u001b[0m: [1, 32, 7, 7] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_703 \u001b[36mshape\u001b[0m: [64, 32, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_704 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.16/conv/conv.0/conv.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 7, 7] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_53/Add:0 \u001b[34mshape\u001b[0m: (1, 7, 7, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 32, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_54/Add:0 \u001b[34mshape\u001b[0m: (1, 7, 7, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m157 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/features/features.16/conv/conv.0/conv.0.2/Clip\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.16/conv/conv.0/conv.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 7, 7] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/features/features.16/conv/conv.0/conv.0.2/Constant_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/features/features.16/conv/conv.0/conv.0.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.16/conv/conv.0/conv.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 64, 7, 7] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_54/Add:0 \u001b[34mshape\u001b[0m: (1, 7, 7, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_30/Relu6:0 \u001b[34mshape\u001b[0m: (1, 7, 7, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m158 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.16/conv/conv.1/conv.1.0/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.16/conv/conv.0/conv.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 64, 7, 7] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_706 \u001b[36mshape\u001b[0m: [64, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_707 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.16/conv/conv.1/conv.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 7, 7] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_30/Relu6:0 \u001b[34mshape\u001b[0m: (1, 7, 7, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 64, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 64 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_55/Add:0 \u001b[34mshape\u001b[0m: (1, 7, 7, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m159 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/features/features.16/conv/conv.1/conv.1.2/Clip\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.16/conv/conv.1/conv.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 7, 7] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/features/features.16/conv/conv.1/conv.1.2/Constant_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/features/features.16/conv/conv.1/conv.1.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.16/conv/conv.1/conv.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 64, 7, 7] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_55/Add:0 \u001b[34mshape\u001b[0m: (1, 7, 7, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_31/Relu6:0 \u001b[34mshape\u001b[0m: (1, 7, 7, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m160 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.16/conv/conv.2/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.16/conv/conv.1/conv.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 64, 7, 7] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_709 \u001b[36mshape\u001b[0m: [32, 64, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_710 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.16/conv/conv.2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 7, 7] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_31/Relu6:0 \u001b[34mshape\u001b[0m: (1, 7, 7, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 64, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_56/Add:0 \u001b[34mshape\u001b[0m: (1, 7, 7, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m161 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/features/features.16/Add\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.15/Add_output_0 \u001b[36mshape\u001b[0m: [1, 32, 7, 7] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/features/features.16/conv/conv.2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 7, 7] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.16/Add_output_0 \u001b[36mshape\u001b[0m: [1, 32, 7, 7] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_53/Add:0 \u001b[34mshape\u001b[0m: (1, 7, 7, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_56/Add:0 \u001b[34mshape\u001b[0m: (1, 7, 7, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_57/Add:0 \u001b[34mshape\u001b[0m: (1, 7, 7, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m162 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.17/conv/conv.0/conv.0.0/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.16/Add_output_0 \u001b[36mshape\u001b[0m: [1, 32, 7, 7] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_712 \u001b[36mshape\u001b[0m: [64, 32, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_713 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.17/conv/conv.0/conv.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 7, 7] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_57/Add:0 \u001b[34mshape\u001b[0m: (1, 7, 7, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 32, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_58/Add:0 \u001b[34mshape\u001b[0m: (1, 7, 7, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m163 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/features/features.17/conv/conv.0/conv.0.2/Clip\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.17/conv/conv.0/conv.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 7, 7] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/features/features.17/conv/conv.0/conv.0.2/Constant_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/features/features.17/conv/conv.0/conv.0.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.17/conv/conv.0/conv.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 64, 7, 7] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_58/Add:0 \u001b[34mshape\u001b[0m: (1, 7, 7, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_32/Relu6:0 \u001b[34mshape\u001b[0m: (1, 7, 7, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m164 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.17/conv/conv.1/conv.1.0/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.17/conv/conv.0/conv.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 64, 7, 7] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_715 \u001b[36mshape\u001b[0m: [64, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_716 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.17/conv/conv.1/conv.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 7, 7] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_32/Relu6:0 \u001b[34mshape\u001b[0m: (1, 7, 7, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 64, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 64 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_59/Add:0 \u001b[34mshape\u001b[0m: (1, 7, 7, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m165 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/features/features.17/conv/conv.1/conv.1.2/Clip\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.17/conv/conv.1/conv.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 7, 7] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/features/features.17/conv/conv.1/conv.1.2/Constant_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/features/features.17/conv/conv.1/conv.1.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.17/conv/conv.1/conv.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 64, 7, 7] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_59/Add:0 \u001b[34mshape\u001b[0m: (1, 7, 7, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_33/Relu6:0 \u001b[34mshape\u001b[0m: (1, 7, 7, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m166 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.17/conv/conv.2/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.17/conv/conv.1/conv.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 64, 7, 7] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_718 \u001b[36mshape\u001b[0m: [32, 64, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_719 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.17/conv/conv.2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 7, 7] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_33/Relu6:0 \u001b[34mshape\u001b[0m: (1, 7, 7, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 64, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_60/Add:0 \u001b[34mshape\u001b[0m: (1, 7, 7, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m167 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/features/features.18/features.18.0/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.17/conv/conv.2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 7, 7] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_721 \u001b[36mshape\u001b[0m: [1280, 32, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_722 \u001b[36mshape\u001b[0m: [1280] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.18/features.18.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 1280, 7, 7] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_60/Add:0 \u001b[34mshape\u001b[0m: (1, 7, 7, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 32, 1280) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (1280,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_61/Add:0 \u001b[34mshape\u001b[0m: (1, 7, 7, 1280) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m168 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/features/features.18/features.18.2/Clip\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.18/features.18.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 1280, 7, 7] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/features/features.18/features.18.2/Constant_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/features/features.18/features.18.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/features/features.18/features.18.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 1280, 7, 7] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_61/Add:0 \u001b[34mshape\u001b[0m: (1, 7, 7, 1280) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_34/Relu6:0 \u001b[34mshape\u001b[0m: (1, 7, 7, 1280) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m169 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: GlobalAveragePool\u001b[35m onnx_op_name\u001b[0m: wa/avgpool/GlobalAveragePool\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/features/features.18/features.18.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 1280, 7, 7] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/avgpool/GlobalAveragePool_output_0 \u001b[36mshape\u001b[0m: [1, 1280, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reduce_mean\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input_tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_34/Relu6:0 \u001b[34mshape\u001b[0m: (1, 7, 7, 1280) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.axis\u001b[0m: \u001b[34mval\u001b[0m: [1, 2] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.keepdims\u001b[0m: \u001b[34mval\u001b[0m: True \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_mean/Mean:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 1280) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m170 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Flatten\u001b[35m onnx_op_name\u001b[0m: wa/Flatten\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/avgpool/GlobalAveragePool_output_0 \u001b[36mshape\u001b[0m: [1, 1280, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/Flatten_output_0 \u001b[36mshape\u001b[0m: [1, 1280] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reshape\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1/transpose:0 \u001b[34mshape\u001b[0m: (1, 1280, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mval\u001b[0m: [1, 1280] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape/Reshape:0 \u001b[34mshape\u001b[0m: (1, 1280) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m171 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Gemm\u001b[35m onnx_op_name\u001b[0m: wa/classifier/classifier.0/Gemm\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/Flatten_output_0 \u001b[36mshape\u001b[0m: [1, 1280] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: classifier.0.weight \u001b[36mshape\u001b[0m: [256, 1280] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: classifier.0.bias \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/classifier/classifier.0/Gemm_output_0 \u001b[36mshape\u001b[0m: [1, 256] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: matmul\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 1280) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1280, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.z\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.alpha\u001b[0m: \u001b[34mval\u001b[0m: 1.0 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.beta\u001b[0m: \u001b[34mval\u001b[0m: 1.0 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add/AddV2:0 \u001b[34mshape\u001b[0m: (1, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m172 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/classifier/classifier.1/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/classifier/classifier.0/Gemm_output_0 \u001b[36mshape\u001b[0m: [1, 256] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/classifier/classifier.1/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add/AddV2:0 \u001b[34mshape\u001b[0m: (1, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu/Relu:0 \u001b[34mshape\u001b[0m: (1, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m173 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: BatchNormalization\u001b[35m onnx_op_name\u001b[0m: wa/classifier/classifier.2/BatchNormalization\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/classifier/classifier.1/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: classifier.2.weight \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: classifier.2.bias \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: classifier.2.running_mean \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.5\u001b[0m: classifier.2.running_var \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/classifier/classifier.2/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 256] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: BatchNormalization\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.X\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu/Relu:0 \u001b[34mshape\u001b[0m: (1, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.mean\u001b[0m: \u001b[34mname\u001b[0m: classifier.2.running_mean \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.variance\u001b[0m: \u001b[34mname\u001b[0m: classifier.2.running_var \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.offset\u001b[0m: \u001b[34mname\u001b[0m: classifier.2.bias \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.scale\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.variance_epsilon\u001b[0m: \u001b[34mval\u001b[0m: 9.999999747378752e-06 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add_1/AddV2:0 \u001b[34mshape\u001b[0m: (1, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m174 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Gemm\u001b[35m onnx_op_name\u001b[0m: wa/classifier/classifier.4/Gemm\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/classifier/classifier.2/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 256] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: classifier.4.weight \u001b[36mshape\u001b[0m: [128, 256] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: classifier.4.bias \u001b[36mshape\u001b[0m: [128] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/classifier/classifier.4/Gemm_output_0 \u001b[36mshape\u001b[0m: [1, 128] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: matmul\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (256, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.z\u001b[0m: \u001b[34mshape\u001b[0m: (128,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.alpha\u001b[0m: \u001b[34mval\u001b[0m: 1.0 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.beta\u001b[0m: \u001b[34mval\u001b[0m: 1.0 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add_2/AddV2:0 \u001b[34mshape\u001b[0m: (1, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m175 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/classifier/classifier.5/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/classifier/classifier.4/Gemm_output_0 \u001b[36mshape\u001b[0m: [1, 128] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/classifier/classifier.5/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add_2/AddV2:0 \u001b[34mshape\u001b[0m: (1, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_1/Relu:0 \u001b[34mshape\u001b[0m: (1, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m176 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: BatchNormalization\u001b[35m onnx_op_name\u001b[0m: wa/classifier/classifier.6/BatchNormalization\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/classifier/classifier.5/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: classifier.6.weight \u001b[36mshape\u001b[0m: [128] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: classifier.6.bias \u001b[36mshape\u001b[0m: [128] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: classifier.6.running_mean \u001b[36mshape\u001b[0m: [128] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.5\u001b[0m: classifier.6.running_var \u001b[36mshape\u001b[0m: [128] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/classifier/classifier.6/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 128] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: BatchNormalization\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.X\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_1/Relu:0 \u001b[34mshape\u001b[0m: (1, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.mean\u001b[0m: \u001b[34mname\u001b[0m: classifier.6.running_mean \u001b[34mshape\u001b[0m: (128,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.variance\u001b[0m: \u001b[34mname\u001b[0m: classifier.6.running_var \u001b[34mshape\u001b[0m: (128,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.offset\u001b[0m: \u001b[34mname\u001b[0m: classifier.6.bias \u001b[34mshape\u001b[0m: (128,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.scale\u001b[0m: \u001b[34mshape\u001b[0m: (128,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.variance_epsilon\u001b[0m: \u001b[34mval\u001b[0m: 9.999999747378752e-06 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add_3/AddV2:0 \u001b[34mshape\u001b[0m: (1, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m177 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Gemm\u001b[35m onnx_op_name\u001b[0m: wa/classifier/classifier.8/Gemm\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/classifier/classifier.6/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 128] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: classifier.8.weight \u001b[36mshape\u001b[0m: [64, 128] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: classifier.8.bias \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/classifier/classifier.8/Gemm_output_0 \u001b[36mshape\u001b[0m: [1, 64] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: matmul\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (128, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.z\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.alpha\u001b[0m: \u001b[34mval\u001b[0m: 1.0 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.beta\u001b[0m: \u001b[34mval\u001b[0m: 1.0 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add_4/AddV2:0 \u001b[34mshape\u001b[0m: (1, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m178 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/classifier/classifier.9/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/classifier/classifier.8/Gemm_output_0 \u001b[36mshape\u001b[0m: [1, 64] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/classifier/classifier.9/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add_4/AddV2:0 \u001b[34mshape\u001b[0m: (1, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_2/Relu:0 \u001b[34mshape\u001b[0m: (1, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m179 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: BatchNormalization\u001b[35m onnx_op_name\u001b[0m: wa/classifier/classifier.10/BatchNormalization\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/classifier/classifier.9/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: classifier.10.weight \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: classifier.10.bias \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: classifier.10.running_mean \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.5\u001b[0m: classifier.10.running_var \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/classifier/classifier.10/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 64] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: BatchNormalization\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.X\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_2/Relu:0 \u001b[34mshape\u001b[0m: (1, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.mean\u001b[0m: \u001b[34mname\u001b[0m: classifier.10.running_mean \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.variance\u001b[0m: \u001b[34mname\u001b[0m: classifier.10.running_var \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.offset\u001b[0m: \u001b[34mname\u001b[0m: classifier.10.bias \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.scale\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.variance_epsilon\u001b[0m: \u001b[34mval\u001b[0m: 9.999999747378752e-06 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add_5/AddV2:0 \u001b[34mshape\u001b[0m: (1, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m180 / 180\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Gemm\u001b[35m onnx_op_name\u001b[0m: wa/classifier/classifier.12/Gemm\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/classifier/classifier.10/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: [1, 64] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: classifier.12.weight \u001b[36mshape\u001b[0m: [10, 64] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: classifier.12.bias \u001b[36mshape\u001b[0m: [10] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: output \u001b[36mshape\u001b[0m: [1, 10] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: matmul\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (64, 10) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.z\u001b[0m: \u001b[34mshape\u001b[0m: (10,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.alpha\u001b[0m: \u001b[34mval\u001b[0m: 1.0 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.beta\u001b[0m: \u001b[34mval\u001b[0m: 1.0 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add_6/AddV2:0 \u001b[34mshape\u001b[0m: (1, 10) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[07msaved_model output started\u001b[0m ==========================================================\n",
            "Saved artifact at 'mobile_pruned_finetuned'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serving_default'\n",
            "  inputs_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 3, 224, 224), dtype=tf.float32, name='input')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(1, 10), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  138047233441616: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  138047233441232: TensorSpec(shape=(3, 3, 3, 32), dtype=tf.float32, name=None)\n",
            "  138047228068112: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138047228082704: TensorSpec(shape=(3, 3, 32, 1), dtype=tf.float32, name=None)\n",
            "  138047228082512: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138047228083280: TensorSpec(shape=(1, 1, 32, 16), dtype=tf.float32, name=None)\n",
            "  138047228084048: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
            "  138047228082896: TensorSpec(shape=(1, 1, 16, 32), dtype=tf.float32, name=None)\n",
            "  138047228082320: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138047226429712: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  138047226430672: TensorSpec(shape=(3, 3, 32, 1), dtype=tf.float32, name=None)\n",
            "  138047228067920: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138047226431056: TensorSpec(shape=(1, 1, 32, 24), dtype=tf.float32, name=None)\n",
            "  138047226430864: TensorSpec(shape=(24,), dtype=tf.float32, name=None)\n",
            "  138047226431248: TensorSpec(shape=(1, 1, 24, 32), dtype=tf.float32, name=None)\n",
            "  138047226430096: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138047226431824: TensorSpec(shape=(3, 3, 32, 1), dtype=tf.float32, name=None)\n",
            "  138047226431440: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138047226432208: TensorSpec(shape=(1, 1, 32, 24), dtype=tf.float32, name=None)\n",
            "  138047226432016: TensorSpec(shape=(24,), dtype=tf.float32, name=None)\n",
            "  138047226431632: TensorSpec(shape=(1, 1, 24, 32), dtype=tf.float32, name=None)\n",
            "  138047226432592: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138047226432400: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  138047226432976: TensorSpec(shape=(3, 3, 32, 1), dtype=tf.float32, name=None)\n",
            "  138047226432784: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138047226433552: TensorSpec(shape=(1, 1, 32, 32), dtype=tf.float32, name=None)\n",
            "  138047226433360: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138047226433744: TensorSpec(shape=(1, 1, 32, 32), dtype=tf.float32, name=None)\n",
            "  138047226433168: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138047226434320: TensorSpec(shape=(3, 3, 32, 1), dtype=tf.float32, name=None)\n",
            "  138047226433936: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138047226434704: TensorSpec(shape=(1, 1, 32, 32), dtype=tf.float32, name=None)\n",
            "  138047226434512: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138047226434896: TensorSpec(shape=(1, 1, 32, 32), dtype=tf.float32, name=None)\n",
            "  138047226435088: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138047226435472: TensorSpec(shape=(3, 3, 32, 1), dtype=tf.float32, name=None)\n",
            "  138047226435280: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138047226435856: TensorSpec(shape=(1, 1, 32, 32), dtype=tf.float32, name=None)\n",
            "  138047226435664: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138047226434128: TensorSpec(shape=(1, 1, 32, 32), dtype=tf.float32, name=None)\n",
            "  138047226436240: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138047226436048: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  138047226436624: TensorSpec(shape=(3, 3, 32, 1), dtype=tf.float32, name=None)\n",
            "  138047226436432: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138047226437200: TensorSpec(shape=(1, 1, 32, 32), dtype=tf.float32, name=None)\n",
            "  138047226437008: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138047226437392: TensorSpec(shape=(1, 1, 32, 32), dtype=tf.float32, name=None)\n",
            "  138047226436816: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138047226437968: TensorSpec(shape=(3, 3, 32, 1), dtype=tf.float32, name=None)\n",
            "  138047226437584: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138047226438352: TensorSpec(shape=(1, 1, 32, 32), dtype=tf.float32, name=None)\n",
            "  138047226438160: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138047226438544: TensorSpec(shape=(1, 1, 32, 32), dtype=tf.float32, name=None)\n",
            "  138047226438736: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138047226439120: TensorSpec(shape=(3, 3, 32, 1), dtype=tf.float32, name=None)\n",
            "  138047226438928: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138047226437776: TensorSpec(shape=(1, 1, 32, 32), dtype=tf.float32, name=None)\n",
            "  138047226439312: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138047226439696: TensorSpec(shape=(1, 1, 32, 32), dtype=tf.float32, name=None)\n",
            "  138047226439888: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138047226440272: TensorSpec(shape=(3, 3, 32, 1), dtype=tf.float32, name=None)\n",
            "  138047226439504: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138047226440464: TensorSpec(shape=(1, 1, 32, 32), dtype=tf.float32, name=None)\n",
            "  138047226440080: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138047226440656: TensorSpec(shape=(1, 1, 32, 32), dtype=tf.float32, name=None)\n",
            "  138047226441040: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138047226441424: TensorSpec(shape=(3, 3, 32, 1), dtype=tf.float32, name=None)\n",
            "  138047226440848: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138047226441616: TensorSpec(shape=(1, 1, 32, 32), dtype=tf.float32, name=None)\n",
            "  138047226441808: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138047226441232: TensorSpec(shape=(1, 1, 32, 32), dtype=tf.float32, name=None)\n",
            "  138047226442000: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138047226442576: TensorSpec(shape=(3, 3, 32, 1), dtype=tf.float32, name=None)\n",
            "  138047226442384: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138047226442768: TensorSpec(shape=(1, 1, 32, 32), dtype=tf.float32, name=None)\n",
            "  138047226442960: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138047226443152: TensorSpec(shape=(1, 1, 32, 32), dtype=tf.float32, name=None)\n",
            "  138047226443344: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138047226443728: TensorSpec(shape=(3, 3, 32, 1), dtype=tf.float32, name=None)\n",
            "  138047226442192: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138047226443920: TensorSpec(shape=(1, 1, 32, 32), dtype=tf.float32, name=None)\n",
            "  138047226444112: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138047226444304: TensorSpec(shape=(1, 1, 32, 32), dtype=tf.float32, name=None)\n",
            "  138047226444496: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138047226443536: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  138047226444880: TensorSpec(shape=(3, 3, 32, 1), dtype=tf.float32, name=None)\n",
            "  138047226444688: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138047226445264: TensorSpec(shape=(1, 1, 32, 32), dtype=tf.float32, name=None)\n",
            "  138047226445456: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138047226445072: TensorSpec(shape=(1, 1, 32, 64), dtype=tf.float32, name=None)\n",
            "  138047226445648: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  138047226905040: TensorSpec(shape=(3, 3, 64, 1), dtype=tf.float32, name=None)\n",
            "  138047226904848: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  138047226905232: TensorSpec(shape=(1, 1, 64, 32), dtype=tf.float32, name=None)\n",
            "  138047226905424: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138047226905616: TensorSpec(shape=(1, 1, 32, 64), dtype=tf.float32, name=None)\n",
            "  138047226905808: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  138047226906192: TensorSpec(shape=(3, 3, 64, 1), dtype=tf.float32, name=None)\n",
            "  138047226904656: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  138047226906384: TensorSpec(shape=(1, 1, 64, 32), dtype=tf.float32, name=None)\n",
            "  138047226906576: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138047226906000: TensorSpec(shape=(1, 1, 32, 64), dtype=tf.float32, name=None)\n",
            "  138047226906960: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  138047226907344: TensorSpec(shape=(3, 3, 64, 1), dtype=tf.float32, name=None)\n",
            "  138047226906768: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  138047226907536: TensorSpec(shape=(1, 1, 64, 32), dtype=tf.float32, name=None)\n",
            "  138047226907728: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138047226907920: TensorSpec(shape=(1, 1, 32, 1280), dtype=tf.float32, name=None)\n",
            "  138047226907152: TensorSpec(shape=(1280,), dtype=tf.float32, name=None)\n",
            "  138047226911184: TensorSpec(shape=(1280, 256), dtype=tf.float32, name=None)\n",
            "  138047226911568: TensorSpec(shape=(), dtype=tf.float32, name=None)\n",
            "  138047226911760: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  138047226912720: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  138047226912912: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  138047226912144: TensorSpec(shape=(256, 128), dtype=tf.float32, name=None)\n",
            "  138047226913680: TensorSpec(shape=(), dtype=tf.float32, name=None)\n",
            "  138047226911952: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  138047226913488: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  138047226913872: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  138047226913296: TensorSpec(shape=(128, 64), dtype=tf.float32, name=None)\n",
            "  138047226912528: TensorSpec(shape=(), dtype=tf.float32, name=None)\n",
            "  138047226910992: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  138047226914640: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  138047226914832: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  138047226914448: TensorSpec(shape=(64, 10), dtype=tf.float32, name=None)\n",
            "  138047226915216: TensorSpec(shape=(), dtype=tf.float32, name=None)\n",
            "  138047226913104: TensorSpec(shape=(10,), dtype=tf.float32, name=None)\n",
            "\u001b[32msaved_model output complete!\u001b[0m\n",
            "I0000 00:00:1741376768.925924    3448 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1741376768.926249    3448 single_machine.cc:361] Starting new session\n",
            "W0000 00:00:1741376769.373946    3448 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
            "W0000 00:00:1741376769.374033    3448 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
            "\u001b[32mFloat32 tflite output complete!\u001b[0m\n",
            "I0000 00:00:1741376769.930608    3448 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
            "I0000 00:00:1741376769.930795    3448 single_machine.cc:361] Starting new session\n",
            "W0000 00:00:1741376770.281378    3448 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
            "W0000 00:00:1741376770.281432    3448 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
            "\u001b[32mFloat16 tflite output complete!\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing the converted model"
      ],
      "metadata": {
        "id": "p1zffg6Zli51"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading dataset"
      ],
      "metadata": {
        "id": "SYxEXU-8lnE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNet\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization,RandomFlip, RandomRotation, RandomZoom\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import time\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pandas as pd\n",
        "# Load dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print(f\"Original Train set: {x_train.shape}\")\n",
        "print(f\"Original Test set: {x_test.shape}\")\n",
        "# Reserve 5000 samples from the training set for validation\n",
        "x_train, x_dev = x_train[:45000], x_train[45000:]\n",
        "y_train, y_dev = y_train[:45000], y_train[45000:]\n",
        "\n",
        "print(f\"Train set: {x_train.shape}\")\n",
        "print(f\"Dev set: {x_dev.shape}\")\n",
        "print(f\"Test set: {x_test.shape}\")\n",
        "# Define batch size\n",
        "BATCH_SIZE = 64\n",
        "AUTOTUNE = tf.data.AUTOTUNE  # Optimizes performance\n",
        "# Define batch size\n",
        "BATCH_SIZE = 64\n",
        "AUTOTUNE = tf.data.AUTOTUNE  # Optimizes performance\n",
        "# Define data augmentation layers\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    RandomFlip(\"horizontal\"),  # Random horizontal flipping\n",
        "    RandomRotation(0.1),       # Random rotation (10% of 360 degrees)\n",
        "    RandomZoom(0.1)            # Random zoom\n",
        "])\n",
        "\n",
        "# Function to resize and normalize images\n",
        "def preprocess(image, label, augment=False):\n",
        "    image = tf.image.resize(image, (224, 224))  # Resize dynamically\n",
        "\n",
        "    if augment:\n",
        "        image = data_augmentation(image)  # Apply augmentations\n",
        "    image = preprocess_input(image)  # Normalize for MobileNet\n",
        "    return image, label\n",
        "\n",
        "# Convert datasets to tf.data.Dataset\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "dev_dataset = tf.data.Dataset.from_tensor_slices((x_dev, y_dev))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "\n",
        "# Apply preprocessing and batching\n",
        "train_dataset = (\n",
        "    tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "    .shuffle(buffer_size=10000)  # Shuffle data for randomness\n",
        "    .map(lambda x, y: preprocess(x, y, augment=True), num_parallel_calls=AUTOTUNE)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(AUTOTUNE)\n",
        ")\n",
        "dev_dataset = (\n",
        "    dev_dataset\n",
        "    .map(preprocess, num_parallel_calls=AUTOTUNE)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(AUTOTUNE)\n",
        ")\n",
        "\n",
        "test_dataset = (\n",
        "    test_dataset\n",
        "    .map(preprocess, num_parallel_calls=AUTOTUNE)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(AUTOTUNE)\n",
        ")\n",
        "\n",
        "# Print dataset structure\n",
        "print(train_dataset)\n",
        "print(dev_dataset)\n",
        "print(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3C0zv8Rliud",
        "outputId": "afc062be-482a-4f8c-ccf9-405f8de0cb5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n",
            "Original Train set: (50000, 32, 32, 3)\n",
            "Original Test set: (10000, 32, 32, 3)\n",
            "Train set: (45000, 32, 32, 3)\n",
            "Dev set: (5000, 32, 32, 3)\n",
            "Test set: (10000, 32, 32, 3)\n",
            "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.uint8, name=None))>\n",
            "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.uint8, name=None))>\n",
            "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.uint8, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take only the first 1000 images from the test dataset\n",
        "num_images = 1000\n",
        "inference_testset = test_dataset.take(num_images // BATCH_SIZE)  # Take enough batches\n",
        "# print the length of the inference testset\n",
        "test_img_count = 0\n",
        "for images, _ in inference_testset:\n",
        "    test_img_count += images.shape[0]  # Add the batch size each time\n",
        "\n",
        "print(f\"Subset contains {test_img_count} images\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbUT1KkcX4Ng",
        "outputId": "c72e2345-c2ed-40dc-933b-3ac1cdafa9e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subset contains 960 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### converting protobuff to tflite"
      ],
      "metadata": {
        "id": "Eaec202OnQkJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "original_model_path = '/content/drive/MyDrive/saved_models/tf_model'\n",
        "\n",
        "# Load the model\n",
        "model = tf.saved_model.load(original_model_path)\n",
        "concrete_func = model.signatures[\"serving_default\"]  # Explicitly get the function\n",
        "# Convert using the concrete function\n",
        "converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the TFLite model\n",
        "tflite_original_model_path = \"/content/drive/My Drive/saved_models/test.tflite\"\n",
        "with open(tflite_original_model_path, \"wb\") as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(f\"TFLite model saved at: {tflite_original_model_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXHoqDLbnXr7",
        "outputId": "441072ff-f872-46ea-b466-e5579d763d29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Please consider providing the trackable_obj argument in the from_concrete_functions. Providing without the trackable_obj argument is deprecated and it will use the deprecated conversion path.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TFLite model saved at: /content/drive/My Drive/saved_models/test.tflite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Running inference"
      ],
      "metadata": {
        "id": "y0U9cWUVnUsd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to run inference on TFLite model with CIFAR-10 dataset\n",
        "def evaluate_tflite_model(interpreter, dataset):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # Get input and output tensor details\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "\n",
        "    # Get quantization scale and zero point for input and output tensors\n",
        "    input_scale, input_zero_point = input_details[0]['quantization']\n",
        "    output_scale, output_zero_point = output_details[0]['quantization']\n",
        "    start_time = time.time()\n",
        "\n",
        "    for images, labels in dataset:\n",
        "        for i in range(len(images)):\n",
        "            # Prepare input image\n",
        "            input_data = np.expand_dims(images[i].numpy(), axis=0)\n",
        "\n",
        "            # Ensure proper INT8 conversion if the model is quantized\n",
        "            if input_details[0]['dtype'] == np.int8:\n",
        "                input_data = ((input_data / input_scale) + input_zero_point).astype(np.int8)\n",
        "            else:\n",
        "                input_data = input_data.astype(np.float32)\n",
        "\n",
        "            # Set the input tensor\n",
        "            interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "\n",
        "            # Run inference\n",
        "            interpreter.invoke()\n",
        "\n",
        "            # Get the output tensor\n",
        "            output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "            # If the model is quantized (INT8), dequantize output\n",
        "            if output_details[0]['dtype'] == np.int8:\n",
        "                output_data = (output_data.astype(np.float32) - output_zero_point) * output_scale\n",
        "\n",
        "            # Get the predicted class (highest probability)\n",
        "            predicted_label = np.argmax(output_data, axis=1)[0]\n",
        "            # Compare with ground truth\n",
        "            if predicted_label == labels[i].numpy():\n",
        "                correct += 1\n",
        "            total += 1\n",
        "    end_time  = time.time()\n",
        "    execution_time = end_time - start_time\n",
        "    accuracy = (correct / total) * 100\n",
        "    return accuracy, execution_time\n"
      ],
      "metadata": {
        "id": "TQsD9AHHl0vR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tflite_original_model_path = '/content/drive/MyDrive/saved_models/tf_model/test_float32.tflite'"
      ],
      "metadata": {
        "id": "Imndu-tyl4S7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model\n",
        "interpreter = tf.lite.Interpreter(model_path=tflite_original_model_path)\n",
        "interpreter.allocate_tensors()\n",
        "# Get input and output details\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "print(\"Input details:\", input_details)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBFxYYLqtIPW",
        "outputId": "d260ba23-6f46-406b-a581-f3f0baaac356"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input details: [{'name': 'input', 'index': 0, 'shape': array([  1, 224, 224,   3], dtype=int32), 'shape_signature': array([ -1, 224, 224,   3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run evaluation on TFLite model\n",
        "original_accuracy, original_execution_time = evaluate_tflite_model(interpreter, inference_testset)\n",
        "print(f\"TFLite Model Accuracy: {original_accuracy:.2f} %\")\n",
        "print(f\"TFLite Inference Time for {test_img_count} images: {original_execution_time:.2f} s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOT-4-esl16f",
        "outputId": "23f47175-df41-44d5-bc2c-7fac739cb464"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TFLite Model Accuracy: 94.48 %\n",
            "TFLite Inference Time for 960 images: 16.80 s\n"
          ]
        }
      ]
    }
  ]
}