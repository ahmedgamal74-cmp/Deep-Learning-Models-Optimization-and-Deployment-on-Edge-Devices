{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports ‚§µÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset, random_split\n",
    "from torchvision import models\n",
    "from torchvision.models import mobilenet_v2\n",
    "from tqdm import tqdm\n",
    "from torchsummary import summary\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the dataset (CIFAR-10) üìä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 170M/170M [00:55<00:00, 3.06MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 50000\n",
      "Dev set size: 4000\n",
      "Test set size: 6000\n"
     ]
    }
   ],
   "source": [
    "# Fix the seed to ensure reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Data augmentation for training (applied only to the train dataset)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), # Resize to MobileNet input size\n",
    "    transforms.RandomHorizontalFlip(), # Flip horizontally\n",
    "    transforms.RandomRotation(15), # Random rotation 15 degress\n",
    "    transforms.ToTensor(), # Convert to tensor\n",
    "    transforms.Normalize((0.5,), (0.5,)) # Normalize (mean=0.5, std=0.5)\n",
    "])\n",
    "\n",
    "# No augmentation for validation/test (only resizing and normalization)\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "# Download CIFAR-10 dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
    "test_data = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
    "\n",
    "# Split the test_data into test (6k) and dev (4k)\n",
    "test_size = 6000\n",
    "dev_size = 4000\n",
    "test_dataset, dev_dataset = random_split(test_data, [test_size, dev_size])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "# Print dataset sizes\n",
    "print(f\"Train set size: {len(train_dataset)}\")\n",
    "print(f\"Dev set size: {len(dev_dataset)}\")\n",
    "print(f\"Test set size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the model architecture üìêüë∑üèª‚Äç‚ôÄÔ∏è and loading the pre-trained weights üß†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained MobileNet model\n",
    "base_model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# Unfreeze some of the top layers\n",
    "for param in base_model.features[:-10].parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the classifier for CIFAR-10 (10 classes)\n",
    "class MobileNetV2(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super(MobileNetV2, self).__init__()\n",
    "        self.features = base_model.features\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(1280, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, 10)  # CIFAR-10 has 10 classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model = MobileNetV2(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "model_weights_path = '../pytorch_models/mobilenet_cifar10.pth'\n",
    "# load the full model\n",
    "model.load_state_dict(torch.load(model_weights_path))\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "print(\"Model weights loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting device and model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV2(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): Conv2dNormActivation(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=1280, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.5, inplace=False)\n",
       "    (8): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (9): ReLU()\n",
       "    (10): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): Dropout(p=0.5, inplace=False)\n",
       "    (12): Linear(in_features=64, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure the model is on the correct device (cuda or cpu)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 112, 112]             864\n",
      "       BatchNorm2d-2         [-1, 32, 112, 112]              64\n",
      "             ReLU6-3         [-1, 32, 112, 112]               0\n",
      "            Conv2d-4         [-1, 32, 112, 112]             288\n",
      "       BatchNorm2d-5         [-1, 32, 112, 112]              64\n",
      "             ReLU6-6         [-1, 32, 112, 112]               0\n",
      "            Conv2d-7         [-1, 16, 112, 112]             512\n",
      "       BatchNorm2d-8         [-1, 16, 112, 112]              32\n",
      "  InvertedResidual-9         [-1, 16, 112, 112]               0\n",
      "           Conv2d-10         [-1, 96, 112, 112]           1,536\n",
      "      BatchNorm2d-11         [-1, 96, 112, 112]             192\n",
      "            ReLU6-12         [-1, 96, 112, 112]               0\n",
      "           Conv2d-13           [-1, 96, 56, 56]             864\n",
      "      BatchNorm2d-14           [-1, 96, 56, 56]             192\n",
      "            ReLU6-15           [-1, 96, 56, 56]               0\n",
      "           Conv2d-16           [-1, 24, 56, 56]           2,304\n",
      "      BatchNorm2d-17           [-1, 24, 56, 56]              48\n",
      " InvertedResidual-18           [-1, 24, 56, 56]               0\n",
      "           Conv2d-19          [-1, 144, 56, 56]           3,456\n",
      "      BatchNorm2d-20          [-1, 144, 56, 56]             288\n",
      "            ReLU6-21          [-1, 144, 56, 56]               0\n",
      "           Conv2d-22          [-1, 144, 56, 56]           1,296\n",
      "      BatchNorm2d-23          [-1, 144, 56, 56]             288\n",
      "            ReLU6-24          [-1, 144, 56, 56]               0\n",
      "           Conv2d-25           [-1, 24, 56, 56]           3,456\n",
      "      BatchNorm2d-26           [-1, 24, 56, 56]              48\n",
      " InvertedResidual-27           [-1, 24, 56, 56]               0\n",
      "           Conv2d-28          [-1, 144, 56, 56]           3,456\n",
      "      BatchNorm2d-29          [-1, 144, 56, 56]             288\n",
      "            ReLU6-30          [-1, 144, 56, 56]               0\n",
      "           Conv2d-31          [-1, 144, 28, 28]           1,296\n",
      "      BatchNorm2d-32          [-1, 144, 28, 28]             288\n",
      "            ReLU6-33          [-1, 144, 28, 28]               0\n",
      "           Conv2d-34           [-1, 32, 28, 28]           4,608\n",
      "      BatchNorm2d-35           [-1, 32, 28, 28]              64\n",
      " InvertedResidual-36           [-1, 32, 28, 28]               0\n",
      "           Conv2d-37          [-1, 192, 28, 28]           6,144\n",
      "      BatchNorm2d-38          [-1, 192, 28, 28]             384\n",
      "            ReLU6-39          [-1, 192, 28, 28]               0\n",
      "           Conv2d-40          [-1, 192, 28, 28]           1,728\n",
      "      BatchNorm2d-41          [-1, 192, 28, 28]             384\n",
      "            ReLU6-42          [-1, 192, 28, 28]               0\n",
      "           Conv2d-43           [-1, 32, 28, 28]           6,144\n",
      "      BatchNorm2d-44           [-1, 32, 28, 28]              64\n",
      " InvertedResidual-45           [-1, 32, 28, 28]               0\n",
      "           Conv2d-46          [-1, 192, 28, 28]           6,144\n",
      "      BatchNorm2d-47          [-1, 192, 28, 28]             384\n",
      "            ReLU6-48          [-1, 192, 28, 28]               0\n",
      "           Conv2d-49          [-1, 192, 28, 28]           1,728\n",
      "      BatchNorm2d-50          [-1, 192, 28, 28]             384\n",
      "            ReLU6-51          [-1, 192, 28, 28]               0\n",
      "           Conv2d-52           [-1, 32, 28, 28]           6,144\n",
      "      BatchNorm2d-53           [-1, 32, 28, 28]              64\n",
      " InvertedResidual-54           [-1, 32, 28, 28]               0\n",
      "           Conv2d-55          [-1, 192, 28, 28]           6,144\n",
      "      BatchNorm2d-56          [-1, 192, 28, 28]             384\n",
      "            ReLU6-57          [-1, 192, 28, 28]               0\n",
      "           Conv2d-58          [-1, 192, 14, 14]           1,728\n",
      "      BatchNorm2d-59          [-1, 192, 14, 14]             384\n",
      "            ReLU6-60          [-1, 192, 14, 14]               0\n",
      "           Conv2d-61           [-1, 64, 14, 14]          12,288\n",
      "      BatchNorm2d-62           [-1, 64, 14, 14]             128\n",
      " InvertedResidual-63           [-1, 64, 14, 14]               0\n",
      "           Conv2d-64          [-1, 384, 14, 14]          24,576\n",
      "      BatchNorm2d-65          [-1, 384, 14, 14]             768\n",
      "            ReLU6-66          [-1, 384, 14, 14]               0\n",
      "           Conv2d-67          [-1, 384, 14, 14]           3,456\n",
      "      BatchNorm2d-68          [-1, 384, 14, 14]             768\n",
      "            ReLU6-69          [-1, 384, 14, 14]               0\n",
      "           Conv2d-70           [-1, 64, 14, 14]          24,576\n",
      "      BatchNorm2d-71           [-1, 64, 14, 14]             128\n",
      " InvertedResidual-72           [-1, 64, 14, 14]               0\n",
      "           Conv2d-73          [-1, 384, 14, 14]          24,576\n",
      "      BatchNorm2d-74          [-1, 384, 14, 14]             768\n",
      "            ReLU6-75          [-1, 384, 14, 14]               0\n",
      "           Conv2d-76          [-1, 384, 14, 14]           3,456\n",
      "      BatchNorm2d-77          [-1, 384, 14, 14]             768\n",
      "            ReLU6-78          [-1, 384, 14, 14]               0\n",
      "           Conv2d-79           [-1, 64, 14, 14]          24,576\n",
      "      BatchNorm2d-80           [-1, 64, 14, 14]             128\n",
      " InvertedResidual-81           [-1, 64, 14, 14]               0\n",
      "           Conv2d-82          [-1, 384, 14, 14]          24,576\n",
      "      BatchNorm2d-83          [-1, 384, 14, 14]             768\n",
      "            ReLU6-84          [-1, 384, 14, 14]               0\n",
      "           Conv2d-85          [-1, 384, 14, 14]           3,456\n",
      "      BatchNorm2d-86          [-1, 384, 14, 14]             768\n",
      "            ReLU6-87          [-1, 384, 14, 14]               0\n",
      "           Conv2d-88           [-1, 64, 14, 14]          24,576\n",
      "      BatchNorm2d-89           [-1, 64, 14, 14]             128\n",
      " InvertedResidual-90           [-1, 64, 14, 14]               0\n",
      "           Conv2d-91          [-1, 384, 14, 14]          24,576\n",
      "      BatchNorm2d-92          [-1, 384, 14, 14]             768\n",
      "            ReLU6-93          [-1, 384, 14, 14]               0\n",
      "           Conv2d-94          [-1, 384, 14, 14]           3,456\n",
      "      BatchNorm2d-95          [-1, 384, 14, 14]             768\n",
      "            ReLU6-96          [-1, 384, 14, 14]               0\n",
      "           Conv2d-97           [-1, 96, 14, 14]          36,864\n",
      "      BatchNorm2d-98           [-1, 96, 14, 14]             192\n",
      " InvertedResidual-99           [-1, 96, 14, 14]               0\n",
      "          Conv2d-100          [-1, 576, 14, 14]          55,296\n",
      "     BatchNorm2d-101          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-102          [-1, 576, 14, 14]               0\n",
      "          Conv2d-103          [-1, 576, 14, 14]           5,184\n",
      "     BatchNorm2d-104          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-105          [-1, 576, 14, 14]               0\n",
      "          Conv2d-106           [-1, 96, 14, 14]          55,296\n",
      "     BatchNorm2d-107           [-1, 96, 14, 14]             192\n",
      "InvertedResidual-108           [-1, 96, 14, 14]               0\n",
      "          Conv2d-109          [-1, 576, 14, 14]          55,296\n",
      "     BatchNorm2d-110          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-111          [-1, 576, 14, 14]               0\n",
      "          Conv2d-112          [-1, 576, 14, 14]           5,184\n",
      "     BatchNorm2d-113          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-114          [-1, 576, 14, 14]               0\n",
      "          Conv2d-115           [-1, 96, 14, 14]          55,296\n",
      "     BatchNorm2d-116           [-1, 96, 14, 14]             192\n",
      "InvertedResidual-117           [-1, 96, 14, 14]               0\n",
      "          Conv2d-118          [-1, 576, 14, 14]          55,296\n",
      "     BatchNorm2d-119          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-120          [-1, 576, 14, 14]               0\n",
      "          Conv2d-121            [-1, 576, 7, 7]           5,184\n",
      "     BatchNorm2d-122            [-1, 576, 7, 7]           1,152\n",
      "           ReLU6-123            [-1, 576, 7, 7]               0\n",
      "          Conv2d-124            [-1, 160, 7, 7]          92,160\n",
      "     BatchNorm2d-125            [-1, 160, 7, 7]             320\n",
      "InvertedResidual-126            [-1, 160, 7, 7]               0\n",
      "          Conv2d-127            [-1, 960, 7, 7]         153,600\n",
      "     BatchNorm2d-128            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-129            [-1, 960, 7, 7]               0\n",
      "          Conv2d-130            [-1, 960, 7, 7]           8,640\n",
      "     BatchNorm2d-131            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-132            [-1, 960, 7, 7]               0\n",
      "          Conv2d-133            [-1, 160, 7, 7]         153,600\n",
      "     BatchNorm2d-134            [-1, 160, 7, 7]             320\n",
      "InvertedResidual-135            [-1, 160, 7, 7]               0\n",
      "          Conv2d-136            [-1, 960, 7, 7]         153,600\n",
      "     BatchNorm2d-137            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-138            [-1, 960, 7, 7]               0\n",
      "          Conv2d-139            [-1, 960, 7, 7]           8,640\n",
      "     BatchNorm2d-140            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-141            [-1, 960, 7, 7]               0\n",
      "          Conv2d-142            [-1, 160, 7, 7]         153,600\n",
      "     BatchNorm2d-143            [-1, 160, 7, 7]             320\n",
      "InvertedResidual-144            [-1, 160, 7, 7]               0\n",
      "          Conv2d-145            [-1, 960, 7, 7]         153,600\n",
      "     BatchNorm2d-146            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-147            [-1, 960, 7, 7]               0\n",
      "          Conv2d-148            [-1, 960, 7, 7]           8,640\n",
      "     BatchNorm2d-149            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-150            [-1, 960, 7, 7]               0\n",
      "          Conv2d-151            [-1, 320, 7, 7]         307,200\n",
      "     BatchNorm2d-152            [-1, 320, 7, 7]             640\n",
      "InvertedResidual-153            [-1, 320, 7, 7]               0\n",
      "          Conv2d-154           [-1, 1280, 7, 7]         409,600\n",
      "     BatchNorm2d-155           [-1, 1280, 7, 7]           2,560\n",
      "           ReLU6-156           [-1, 1280, 7, 7]               0\n",
      "AdaptiveAvgPool2d-157           [-1, 1280, 1, 1]               0\n",
      "          Linear-158                  [-1, 256]         327,936\n",
      "            ReLU-159                  [-1, 256]               0\n",
      "     BatchNorm1d-160                  [-1, 256]             512\n",
      "         Dropout-161                  [-1, 256]               0\n",
      "          Linear-162                  [-1, 128]          32,896\n",
      "            ReLU-163                  [-1, 128]               0\n",
      "     BatchNorm1d-164                  [-1, 128]             256\n",
      "         Dropout-165                  [-1, 128]               0\n",
      "          Linear-166                   [-1, 64]           8,256\n",
      "            ReLU-167                   [-1, 64]               0\n",
      "     BatchNorm1d-168                   [-1, 64]             128\n",
      "         Dropout-169                   [-1, 64]               0\n",
      "          Linear-170                   [-1, 10]             650\n",
      "================================================================\n",
      "Total params: 2,594,506\n",
      "Trainable params: 2,463,690\n",
      "Non-trainable params: 130,816\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 152.87\n",
      "Params size (MB): 9.90\n",
      "Estimated Total Size (MB): 163.34\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required functions for training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train_model(model, train_loader, dev_loader, criterion, optimizer, num_epochs=10, mask_enforcer=None):\n",
    "    for epoch in range(num_epochs):\n",
    "        ### Training Phase ###\n",
    "        model.train()  # Set model to training mode\n",
    "        running_loss = 0.0\n",
    "        correct, total = 0, 0\n",
    "\n",
    "        loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=True)\n",
    "        for images, labels in loop:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Enforce pruning mask if provided\n",
    "            if mask_enforcer:\n",
    "                mask_enforcer.enforce()\n",
    "\n",
    "            # Compute training metrics\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "            # Update progress bar\n",
    "            loop.set_postfix(train_loss=running_loss / total, train_acc=100. * correct / total)\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = 100. * correct / total\n",
    "\n",
    "        ### Validation (Dev) Phase ###\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        dev_loss, dev_correct, dev_total = 0.0, 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in dev_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                dev_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                dev_total += labels.size(0)\n",
    "                dev_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        dev_loss /= len(dev_loader)\n",
    "        dev_acc = 100. * dev_correct / dev_total\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, Dev Loss: {dev_loss:.4f}, Dev Acc: {dev_acc:.2f}%\")\n",
    "\n",
    "    print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, criterion, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():  # No gradients for validation (Disable gradient calculations for efficiency)\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Update loss\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # Get predictions\n",
    "            _, predicted = outputs.max(1)\n",
    "\n",
    "            # Update metrics\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    end_time = time.time()\n",
    "    inference_time = end_time - start_time\n",
    "    avg_loss = test_loss / len(test_loader)\n",
    "    accuracy = 100. * correct / total\n",
    "\n",
    "    #print(f\"Test Loss: {avg_loss:.4f}, Test Accuracy: {accuracy:.2f}%\")\n",
    "    return avg_loss, accuracy, inference_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation (before pruning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average test Loss: 0.2781, Test Accuracy: 91.35%, Inference Time for 6000 images: 10.53 seconds\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "avgLoss, acc, inf_time = evaluate_model(model, test_loader, criterion, device)\n",
    "# Print evaluation results\n",
    "print(f\"Average test Loss: {avgLoss:.4f}, Test Accuracy: {acc:.2f}%, Inference Time for {len(test_dataset)} images: {inf_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying pruning\n",
    "following this link: https://nvidia.github.io/TensorRT-Model-Optimizer/guides/2_pruning.html#pruning-fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'config', 'fastnas', 'gradnas', 'mcore_gpt_minitron', 'mode', 'modelopt', 'plugins', 'prune', 'pruning']\n"
     ]
    }
   ],
   "source": [
    "import modelopt.torch.prune as mtp\n",
    "# Checking available pruning methods\n",
    "print(dir(mtp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does FastNAS work?\n",
    "\n",
    "- Step 1: Randomly generates multiple smaller sub-models from the original model.\n",
    "- Step 2: Measures the FLOPs of each sub-model.\n",
    "- Step 3: Evaluates each sub-model using the score_func (accuracy).\n",
    "- Step 4: Selects the best-performing pruned model that meets the FLOPs constraint.\n",
    "- Step 5: Outputs the pruned model (pruned_model) and results (prune_res)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khaled/tf_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-03-05 22:33:26.961274: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741206807.067552   15919 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741206807.099374   15919 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-05 22:33:27.355086: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Profiling the following subnets from the given model: ('min', 'centroid', 'max').\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m                                                                             \u001b[0m\n",
      "\u001b[3m                              Profiling Results                              \u001b[0m\n",
      "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
      "‚îÉ\u001b[1m \u001b[0m\u001b[1mConstraint  \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mmin         \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mcentroid    \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mmax         \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mmax/min ratio\u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
      "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
      "‚îÇ flops        ‚îÇ 55.46M       ‚îÇ 156.84M      ‚îÇ 336.89M      ‚îÇ 6.07          ‚îÇ\n",
      "‚îÇ params       ‚îÇ 455.21K      ‚îÇ 1.12M        ‚îÇ 2.56M        ‚îÇ 5.62          ‚îÇ\n",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
      "\u001b[3m                                              \u001b[0m\n",
      "\u001b[3m            Constraints Evaluation            \u001b[0m\n",
      "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
      "‚îÉ\u001b[1m              \u001b[0m‚îÉ\u001b[1m              \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mSatisfiable \u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
      "‚îÉ\u001b[1m \u001b[0m\u001b[1mConstraint  \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mUpper Bound \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mUpper Bound \u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
      "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
      "‚îÇ flops        ‚îÇ 168.44M      ‚îÇ True         ‚îÇ\n",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
      "\n",
      "\n",
      "Search Space Summary:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "  features.depth                                                                   [19]\n",
      "  features.0.0.out_channels                                                        [32]\n",
      "  features.0.0.in_channels                                                         [3]\n",
      "  features.0.1.num_features                                                        [32]\n",
      "  features.1.conv.0.0.out_channels                                                 [32]\n",
      "  features.1.conv.0.0.in_channels                                                  [32]\n",
      "  features.1.conv.0.1.num_features                                                 [32]\n",
      "  features.1.conv.1.out_channels                                                   [16]\n",
      "  features.1.conv.1.in_channels                                                    [32]\n",
      "  features.1.conv.2.num_features                                                   [16]\n",
      "* features.2.conv.0.0.out_channels                                                 [32, 64, 96]\n",
      "  features.2.conv.0.0.in_channels                                                  [16]\n",
      "  features.2.conv.0.1.num_features                                                 [32, 64, 96]\n",
      "  features.2.conv.1.0.out_channels                                                 [32, 64, 96]\n",
      "  features.2.conv.1.0.in_channels                                                  [32, 64, 96]\n",
      "  features.2.conv.1.1.num_features                                                 [32, 64, 96]\n",
      "  features.2.conv.2.out_channels                                                   [24]\n",
      "  features.2.conv.2.in_channels                                                    [32, 64, 96]\n",
      "  features.2.conv.3.num_features                                                   [24]\n",
      "* features.3.conv.0.0.out_channels                                                 [32, 64, 96, 128, 144]\n",
      "  features.3.conv.0.0.in_channels                                                  [24]\n",
      "  features.3.conv.0.1.num_features                                                 [32, 64, 96, 128, 144]\n",
      "  features.3.conv.1.0.out_channels                                                 [32, 64, 96, 128, 144]\n",
      "  features.3.conv.1.0.in_channels                                                  [32, 64, 96, 128, 144]\n",
      "  features.3.conv.1.1.num_features                                                 [32, 64, 96, 128, 144]\n",
      "  features.3.conv.2.out_channels                                                   [24]\n",
      "  features.3.conv.2.in_channels                                                    [32, 64, 96, 128, 144]\n",
      "  features.3.conv.3.num_features                                                   [24]\n",
      "* features.4.conv.0.0.out_channels                                                 [32, 64, 96, 128, 144]\n",
      "  features.4.conv.0.0.in_channels                                                  [24]\n",
      "  features.4.conv.0.1.num_features                                                 [32, 64, 96, 128, 144]\n",
      "  features.4.conv.1.0.out_channels                                                 [32, 64, 96, 128, 144]\n",
      "  features.4.conv.1.0.in_channels                                                  [32, 64, 96, 128, 144]\n",
      "  features.4.conv.1.1.num_features                                                 [32, 64, 96, 128, 144]\n",
      "  features.4.conv.2.out_channels                                                   [32]\n",
      "  features.4.conv.2.in_channels                                                    [32, 64, 96, 128, 144]\n",
      "  features.4.conv.3.num_features                                                   [32]\n",
      "* features.5.conv.0.0.out_channels                                                 [32, 64, 96, 128, 160, 192]\n",
      "  features.5.conv.0.0.in_channels                                                  [32]\n",
      "  features.5.conv.0.1.num_features                                                 [32, 64, 96, 128, 160, 192]\n",
      "  features.5.conv.1.0.out_channels                                                 [32, 64, 96, 128, 160, 192]\n",
      "  features.5.conv.1.0.in_channels                                                  [32, 64, 96, 128, 160, 192]\n",
      "  features.5.conv.1.1.num_features                                                 [32, 64, 96, 128, 160, 192]\n",
      "  features.5.conv.2.out_channels                                                   [32]\n",
      "  features.5.conv.2.in_channels                                                    [32, 64, 96, 128, 160, 192]\n",
      "  features.5.conv.3.num_features                                                   [32]\n",
      "* features.6.conv.0.0.out_channels                                                 [32, 64, 96, 128, 160, 192]\n",
      "  features.6.conv.0.0.in_channels                                                  [32]\n",
      "  features.6.conv.0.1.num_features                                                 [32, 64, 96, 128, 160, 192]\n",
      "  features.6.conv.1.0.out_channels                                                 [32, 64, 96, 128, 160, 192]\n",
      "  features.6.conv.1.0.in_channels                                                  [32, 64, 96, 128, 160, 192]\n",
      "  features.6.conv.1.1.num_features                                                 [32, 64, 96, 128, 160, 192]\n",
      "  features.6.conv.2.out_channels                                                   [32]\n",
      "  features.6.conv.2.in_channels                                                    [32, 64, 96, 128, 160, 192]\n",
      "  features.6.conv.3.num_features                                                   [32]\n",
      "* features.7.conv.0.0.out_channels                                                 [32, 64, 96, 128, 160, 192]\n",
      "  features.7.conv.0.0.in_channels                                                  [32]\n",
      "  features.7.conv.0.1.num_features                                                 [32, 64, 96, 128, 160, 192]\n",
      "  features.7.conv.1.0.out_channels                                                 [32, 64, 96, 128, 160, 192]\n",
      "  features.7.conv.1.0.in_channels                                                  [32, 64, 96, 128, 160, 192]\n",
      "  features.7.conv.1.1.num_features                                                 [32, 64, 96, 128, 160, 192]\n",
      "* features.7.conv.2.out_channels                                                   [32, 64]\n",
      "  features.7.conv.2.in_channels                                                    [32, 64, 96, 128, 160, 192]\n",
      "  features.7.conv.3.num_features                                                   [32, 64]\n",
      "* features.8.conv.0.0.out_channels                                                 [32, 64, 96, 128, '...', 288, 320, 352, 384]\n",
      "  features.8.conv.0.0.in_channels                                                  [32, 64]\n",
      "  features.8.conv.0.1.num_features                                                 [32, 64, 96, 128, '...', 288, 320, 352, 384]\n",
      "  features.8.conv.1.0.out_channels                                                 [32, 64, 96, 128, '...', 288, 320, 352, 384]\n",
      "  features.8.conv.1.0.in_channels                                                  [32, 64, 96, 128, '...', 288, 320, 352, 384]\n",
      "  features.8.conv.1.1.num_features                                                 [32, 64, 96, 128, '...', 288, 320, 352, 384]\n",
      "  features.8.conv.2.out_channels                                                   [32, 64]\n",
      "  features.8.conv.2.in_channels                                                    [32, 64, 96, 128, '...', 288, 320, 352, 384]\n",
      "  features.8.conv.3.num_features                                                   [32, 64]\n",
      "* features.9.conv.0.0.out_channels                                                 [32, 64, 96, 128, '...', 288, 320, 352, 384]\n",
      "  features.9.conv.0.0.in_channels                                                  [32, 64]\n",
      "  features.9.conv.0.1.num_features                                                 [32, 64, 96, 128, '...', 288, 320, 352, 384]\n",
      "  features.9.conv.1.0.out_channels                                                 [32, 64, 96, 128, '...', 288, 320, 352, 384]\n",
      "  features.9.conv.1.0.in_channels                                                  [32, 64, 96, 128, '...', 288, 320, 352, 384]\n",
      "  features.9.conv.1.1.num_features                                                 [32, 64, 96, 128, '...', 288, 320, 352, 384]\n",
      "  features.9.conv.2.out_channels                                                   [32, 64]\n",
      "  features.9.conv.2.in_channels                                                    [32, 64, 96, 128, '...', 288, 320, 352, 384]\n",
      "  features.9.conv.3.num_features                                                   [32, 64]\n",
      "* features.10.conv.0.0.out_channels                                                [32, 64, 96, 128, '...', 288, 320, 352, 384]\n",
      "  features.10.conv.0.0.in_channels                                                 [32, 64]\n",
      "  features.10.conv.0.1.num_features                                                [32, 64, 96, 128, '...', 288, 320, 352, 384]\n",
      "  features.10.conv.1.0.out_channels                                                [32, 64, 96, 128, '...', 288, 320, 352, 384]\n",
      "  features.10.conv.1.0.in_channels                                                 [32, 64, 96, 128, '...', 288, 320, 352, 384]\n",
      "  features.10.conv.1.1.num_features                                                [32, 64, 96, 128, '...', 288, 320, 352, 384]\n",
      "  features.10.conv.2.out_channels                                                  [32, 64]\n",
      "  features.10.conv.2.in_channels                                                   [32, 64, 96, 128, '...', 288, 320, 352, 384]\n",
      "  features.10.conv.3.num_features                                                  [32, 64]\n",
      "* features.11.conv.0.0.out_channels                                                [32, 64, 96, 128, '...', 288, 320, 352, 384]\n",
      "  features.11.conv.0.0.in_channels                                                 [32, 64]\n",
      "  features.11.conv.0.1.num_features                                                [32, 64, 96, 128, '...', 288, 320, 352, 384]\n",
      "  features.11.conv.1.0.out_channels                                                [32, 64, 96, 128, '...', 288, 320, 352, 384]\n",
      "  features.11.conv.1.0.in_channels                                                 [32, 64, 96, 128, '...', 288, 320, 352, 384]\n",
      "  features.11.conv.1.1.num_features                                                [32, 64, 96, 128, '...', 288, 320, 352, 384]\n",
      "* features.11.conv.2.out_channels                                                  [32, 64, 96]\n",
      "  features.11.conv.2.in_channels                                                   [32, 64, 96, 128, '...', 288, 320, 352, 384]\n",
      "  features.11.conv.3.num_features                                                  [32, 64, 96]\n",
      "* features.12.conv.0.0.out_channels                                                [32, 64, 96, 128, '...', 480, 512, 544, 576]\n",
      "  features.12.conv.0.0.in_channels                                                 [32, 64, 96]\n",
      "  features.12.conv.0.1.num_features                                                [32, 64, 96, 128, '...', 480, 512, 544, 576]\n",
      "  features.12.conv.1.0.out_channels                                                [32, 64, 96, 128, '...', 480, 512, 544, 576]\n",
      "  features.12.conv.1.0.in_channels                                                 [32, 64, 96, 128, '...', 480, 512, 544, 576]\n",
      "  features.12.conv.1.1.num_features                                                [32, 64, 96, 128, '...', 480, 512, 544, 576]\n",
      "  features.12.conv.2.out_channels                                                  [32, 64, 96]\n",
      "  features.12.conv.2.in_channels                                                   [32, 64, 96, 128, '...', 480, 512, 544, 576]\n",
      "  features.12.conv.3.num_features                                                  [32, 64, 96]\n",
      "* features.13.conv.0.0.out_channels                                                [32, 64, 96, 128, '...', 480, 512, 544, 576]\n",
      "  features.13.conv.0.0.in_channels                                                 [32, 64, 96]\n",
      "  features.13.conv.0.1.num_features                                                [32, 64, 96, 128, '...', 480, 512, 544, 576]\n",
      "  features.13.conv.1.0.out_channels                                                [32, 64, 96, 128, '...', 480, 512, 544, 576]\n",
      "  features.13.conv.1.0.in_channels                                                 [32, 64, 96, 128, '...', 480, 512, 544, 576]\n",
      "  features.13.conv.1.1.num_features                                                [32, 64, 96, 128, '...', 480, 512, 544, 576]\n",
      "  features.13.conv.2.out_channels                                                  [32, 64, 96]\n",
      "  features.13.conv.2.in_channels                                                   [32, 64, 96, 128, '...', 480, 512, 544, 576]\n",
      "  features.13.conv.3.num_features                                                  [32, 64, 96]\n",
      "* features.14.conv.0.0.out_channels                                                [32, 64, 96, 128, '...', 480, 512, 544, 576]\n",
      "  features.14.conv.0.0.in_channels                                                 [32, 64, 96]\n",
      "  features.14.conv.0.1.num_features                                                [32, 64, 96, 128, '...', 480, 512, 544, 576]\n",
      "  features.14.conv.1.0.out_channels                                                [32, 64, 96, 128, '...', 480, 512, 544, 576]\n",
      "  features.14.conv.1.0.in_channels                                                 [32, 64, 96, 128, '...', 480, 512, 544, 576]\n",
      "  features.14.conv.1.1.num_features                                                [32, 64, 96, 128, '...', 480, 512, 544, 576]\n",
      "* features.14.conv.2.out_channels                                                  [32, 64, 96, 128, 160]\n",
      "  features.14.conv.2.in_channels                                                   [32, 64, 96, 128, '...', 480, 512, 544, 576]\n",
      "  features.14.conv.3.num_features                                                  [32, 64, 96, 128, 160]\n",
      "* features.15.conv.0.0.out_channels                                                [64, 96, 160, 192, '...', 832, 864, 928, 960]\n",
      "  features.15.conv.0.0.in_channels                                                 [32, 64, 96, 128, 160]\n",
      "  features.15.conv.0.1.num_features                                                [64, 96, 160, 192, '...', 832, 864, 928, 960]\n",
      "  features.15.conv.1.0.out_channels                                                [64, 96, 160, 192, '...', 832, 864, 928, 960]\n",
      "  features.15.conv.1.0.in_channels                                                 [64, 96, 160, 192, '...', 832, 864, 928, 960]\n",
      "  features.15.conv.1.1.num_features                                                [64, 96, 160, 192, '...', 832, 864, 928, 960]\n",
      "  features.15.conv.2.out_channels                                                  [32, 64, 96, 128, 160]\n",
      "  features.15.conv.2.in_channels                                                   [64, 96, 160, 192, '...', 832, 864, 928, 960]\n",
      "  features.15.conv.3.num_features                                                  [32, 64, 96, 128, 160]\n",
      "* features.16.conv.0.0.out_channels                                                [64, 96, 160, 192, '...', 832, 864, 928, 960]\n",
      "  features.16.conv.0.0.in_channels                                                 [32, 64, 96, 128, 160]\n",
      "  features.16.conv.0.1.num_features                                                [64, 96, 160, 192, '...', 832, 864, 928, 960]\n",
      "  features.16.conv.1.0.out_channels                                                [64, 96, 160, 192, '...', 832, 864, 928, 960]\n",
      "  features.16.conv.1.0.in_channels                                                 [64, 96, 160, 192, '...', 832, 864, 928, 960]\n",
      "  features.16.conv.1.1.num_features                                                [64, 96, 160, 192, '...', 832, 864, 928, 960]\n",
      "  features.16.conv.2.out_channels                                                  [32, 64, 96, 128, 160]\n",
      "  features.16.conv.2.in_channels                                                   [64, 96, 160, 192, '...', 832, 864, 928, 960]\n",
      "  features.16.conv.3.num_features                                                  [32, 64, 96, 128, 160]\n",
      "* features.17.conv.0.0.out_channels                                                [64, 96, 160, 192, '...', 832, 864, 928, 960]\n",
      "  features.17.conv.0.0.in_channels                                                 [32, 64, 96, 128, 160]\n",
      "  features.17.conv.0.1.num_features                                                [64, 96, 160, 192, '...', 832, 864, 928, 960]\n",
      "  features.17.conv.1.0.out_channels                                                [64, 96, 160, 192, '...', 832, 864, 928, 960]\n",
      "  features.17.conv.1.0.in_channels                                                 [64, 96, 160, 192, '...', 832, 864, 928, 960]\n",
      "  features.17.conv.1.1.num_features                                                [64, 96, 160, 192, '...', 832, 864, 928, 960]\n",
      "* features.17.conv.2.out_channels                                                  [32, 64, 96, 128, '...', 224, 256, 288, 320]\n",
      "  features.17.conv.2.in_channels                                                   [64, 96, 160, 192, '...', 832, 864, 928, 960]\n",
      "  features.17.conv.3.num_features                                                  [32, 64, 96, 128, '...', 224, 256, 288, 320]\n",
      "  features.18.0.out_channels                                                       [1280]\n",
      "  features.18.0.in_channels                                                        [32, 64, 96, 128, '...', 224, 256, 288, 320]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Number of configurable hparams: 20\n",
      "Total size of the search space: 4.70e+18\n",
      "Note: all constraints can be satisfied within the search space!\n",
      "\n",
      "\n",
      "Beginning pre-search estimation. If the runtime of score function is longer than a few minutes, consider subsampling the dataset used in score function. \n",
      "A PyTorch dataset can be subsampled using torch.utils.data.Subset (https://pytorch.org/docs/stable/data.html#torch.utils.data.Subset) as following:\n",
      " subset_dataset = torch.utils.data.Subset(dataset, indices)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting pre-search statistics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 213/213 [06:56<00:00,  1.96s/it, cur=features.17.conv.2.out_channels(320/320): 0.00]  \n",
      "[num_satisfied] = 1:   0%|          | 1/5000 [00:05<7:05:12,  5.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[best_subnet_constraints] = {'params': '455.21K', 'flops': '55.46M'}\n"
     ]
    }
   ],
   "source": [
    "import modelopt.torch.prune as mtp\n",
    "import modelopt.torch.opt as mto\n",
    "\n",
    "# Wrap your original validation function to only take the model as input.\n",
    "# This function acts as the score function to rank models.\n",
    "def score_func(model):\n",
    "    accuracy, _ , _ = evaluate_model(model, test_loader, criterion, device)\n",
    "    return accuracy\n",
    "\n",
    "# Define a dummy input with similar shape as that of your input data\n",
    "dummy_input = torch.randn(1, 3, 224, 244).to(device)\n",
    "\n",
    "# Prune the model to at most 50% of the original FLOPs\n",
    "prune_constraints = {\"flops\": \"50%\"}\n",
    "\n",
    "pruned_model, prune_res = mtp.prune(\n",
    "    model=model,\n",
    "    mode=\"fastnas\",\n",
    "    constraints=prune_constraints,\n",
    "    dummy_input=dummy_input,\n",
    "    config={\n",
    "        \"data_loader\": train_loader,  # training data is used for calibrating BN layers\n",
    "        \"score_func\": score_func,  # validation score is used to rank the subnets\n",
    "        # checkpoint to store the search state and resume or re-run the search with different constraint\n",
    "        \"checkpoint\": \"modelopt_fastnas_search_checkpoint.pth\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# Save the pruned model.\n",
    "mto.save(pruned_model, \"modelopt_pruned_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khaled/tf_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-04-16 10:16:30.335146: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744791390.450741     930 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744791390.483893     930 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-16 10:16:30.764288: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import modelopt.torch.prune as mtp\n",
    "import modelopt.torch.opt as mto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of pruned model: 1.93 MB\n"
     ]
    }
   ],
   "source": [
    "# Load the pruned weights\n",
    "pruned_model_path = \"../pytorch_models/modelopt_pruned_model.pth\"\n",
    "# get size of pruned model\n",
    "pruned_model_size = os.path.getsize(pruned_model_path) / (1024 * 1024)\n",
    "print(f\"Size of pruned model: {pruned_model_size:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_pruned = models.mobilenet_v2(weights=None)\n",
    "model = MobileNetV2(base_pruned)\n",
    "# Restore the pruned architecture and weights\n",
    "pruned_model = mto.restore(model, \"../pytorch_models/modelopt_pruned_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV2(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(32, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(32, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): Conv2dNormActivation(\n",
       "      (0): Conv2d(32, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=1280, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.5, inplace=False)\n",
       "    (8): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (9): ReLU()\n",
       "    (10): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): Dropout(p=0.5, inplace=False)\n",
       "    (12): Linear(in_features=64, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 112, 112]             864\n",
      "       BatchNorm2d-2         [-1, 32, 112, 112]              64\n",
      "             ReLU6-3         [-1, 32, 112, 112]               0\n",
      "            Conv2d-4         [-1, 32, 112, 112]             288\n",
      "       BatchNorm2d-5         [-1, 32, 112, 112]              64\n",
      "             ReLU6-6         [-1, 32, 112, 112]               0\n",
      "            Conv2d-7         [-1, 16, 112, 112]             512\n",
      "       BatchNorm2d-8         [-1, 16, 112, 112]              32\n",
      "  InvertedResidual-9         [-1, 16, 112, 112]               0\n",
      "           Conv2d-10         [-1, 32, 112, 112]             512\n",
      "      BatchNorm2d-11         [-1, 32, 112, 112]              64\n",
      "            ReLU6-12         [-1, 32, 112, 112]               0\n",
      "           Conv2d-13           [-1, 32, 56, 56]             288\n",
      "      BatchNorm2d-14           [-1, 32, 56, 56]              64\n",
      "            ReLU6-15           [-1, 32, 56, 56]               0\n",
      "           Conv2d-16           [-1, 24, 56, 56]             768\n",
      "      BatchNorm2d-17           [-1, 24, 56, 56]              48\n",
      " InvertedResidual-18           [-1, 24, 56, 56]               0\n",
      "           Conv2d-19           [-1, 32, 56, 56]             768\n",
      "      BatchNorm2d-20           [-1, 32, 56, 56]              64\n",
      "            ReLU6-21           [-1, 32, 56, 56]               0\n",
      "           Conv2d-22           [-1, 32, 56, 56]             288\n",
      "      BatchNorm2d-23           [-1, 32, 56, 56]              64\n",
      "            ReLU6-24           [-1, 32, 56, 56]               0\n",
      "           Conv2d-25           [-1, 24, 56, 56]             768\n",
      "      BatchNorm2d-26           [-1, 24, 56, 56]              48\n",
      " InvertedResidual-27           [-1, 24, 56, 56]               0\n",
      "           Conv2d-28           [-1, 32, 56, 56]             768\n",
      "      BatchNorm2d-29           [-1, 32, 56, 56]              64\n",
      "            ReLU6-30           [-1, 32, 56, 56]               0\n",
      "           Conv2d-31           [-1, 32, 28, 28]             288\n",
      "      BatchNorm2d-32           [-1, 32, 28, 28]              64\n",
      "            ReLU6-33           [-1, 32, 28, 28]               0\n",
      "           Conv2d-34           [-1, 32, 28, 28]           1,024\n",
      "      BatchNorm2d-35           [-1, 32, 28, 28]              64\n",
      " InvertedResidual-36           [-1, 32, 28, 28]               0\n",
      "           Conv2d-37           [-1, 32, 28, 28]           1,024\n",
      "      BatchNorm2d-38           [-1, 32, 28, 28]              64\n",
      "            ReLU6-39           [-1, 32, 28, 28]               0\n",
      "           Conv2d-40           [-1, 32, 28, 28]             288\n",
      "      BatchNorm2d-41           [-1, 32, 28, 28]              64\n",
      "            ReLU6-42           [-1, 32, 28, 28]               0\n",
      "           Conv2d-43           [-1, 32, 28, 28]           1,024\n",
      "      BatchNorm2d-44           [-1, 32, 28, 28]              64\n",
      " InvertedResidual-45           [-1, 32, 28, 28]               0\n",
      "           Conv2d-46           [-1, 32, 28, 28]           1,024\n",
      "      BatchNorm2d-47           [-1, 32, 28, 28]              64\n",
      "            ReLU6-48           [-1, 32, 28, 28]               0\n",
      "           Conv2d-49           [-1, 32, 28, 28]             288\n",
      "      BatchNorm2d-50           [-1, 32, 28, 28]              64\n",
      "            ReLU6-51           [-1, 32, 28, 28]               0\n",
      "           Conv2d-52           [-1, 32, 28, 28]           1,024\n",
      "      BatchNorm2d-53           [-1, 32, 28, 28]              64\n",
      " InvertedResidual-54           [-1, 32, 28, 28]               0\n",
      "           Conv2d-55           [-1, 32, 28, 28]           1,024\n",
      "      BatchNorm2d-56           [-1, 32, 28, 28]              64\n",
      "            ReLU6-57           [-1, 32, 28, 28]               0\n",
      "           Conv2d-58           [-1, 32, 14, 14]             288\n",
      "      BatchNorm2d-59           [-1, 32, 14, 14]              64\n",
      "            ReLU6-60           [-1, 32, 14, 14]               0\n",
      "           Conv2d-61           [-1, 32, 14, 14]           1,024\n",
      "      BatchNorm2d-62           [-1, 32, 14, 14]              64\n",
      " InvertedResidual-63           [-1, 32, 14, 14]               0\n",
      "           Conv2d-64           [-1, 32, 14, 14]           1,024\n",
      "      BatchNorm2d-65           [-1, 32, 14, 14]              64\n",
      "            ReLU6-66           [-1, 32, 14, 14]               0\n",
      "           Conv2d-67           [-1, 32, 14, 14]             288\n",
      "      BatchNorm2d-68           [-1, 32, 14, 14]              64\n",
      "            ReLU6-69           [-1, 32, 14, 14]               0\n",
      "           Conv2d-70           [-1, 32, 14, 14]           1,024\n",
      "      BatchNorm2d-71           [-1, 32, 14, 14]              64\n",
      " InvertedResidual-72           [-1, 32, 14, 14]               0\n",
      "           Conv2d-73           [-1, 32, 14, 14]           1,024\n",
      "      BatchNorm2d-74           [-1, 32, 14, 14]              64\n",
      "            ReLU6-75           [-1, 32, 14, 14]               0\n",
      "           Conv2d-76           [-1, 32, 14, 14]             288\n",
      "      BatchNorm2d-77           [-1, 32, 14, 14]              64\n",
      "            ReLU6-78           [-1, 32, 14, 14]               0\n",
      "           Conv2d-79           [-1, 32, 14, 14]           1,024\n",
      "      BatchNorm2d-80           [-1, 32, 14, 14]              64\n",
      " InvertedResidual-81           [-1, 32, 14, 14]               0\n",
      "           Conv2d-82           [-1, 32, 14, 14]           1,024\n",
      "      BatchNorm2d-83           [-1, 32, 14, 14]              64\n",
      "            ReLU6-84           [-1, 32, 14, 14]               0\n",
      "           Conv2d-85           [-1, 32, 14, 14]             288\n",
      "      BatchNorm2d-86           [-1, 32, 14, 14]              64\n",
      "            ReLU6-87           [-1, 32, 14, 14]               0\n",
      "           Conv2d-88           [-1, 32, 14, 14]           1,024\n",
      "      BatchNorm2d-89           [-1, 32, 14, 14]              64\n",
      " InvertedResidual-90           [-1, 32, 14, 14]               0\n",
      "           Conv2d-91           [-1, 32, 14, 14]           1,024\n",
      "      BatchNorm2d-92           [-1, 32, 14, 14]              64\n",
      "            ReLU6-93           [-1, 32, 14, 14]               0\n",
      "           Conv2d-94           [-1, 32, 14, 14]             288\n",
      "      BatchNorm2d-95           [-1, 32, 14, 14]              64\n",
      "            ReLU6-96           [-1, 32, 14, 14]               0\n",
      "           Conv2d-97           [-1, 32, 14, 14]           1,024\n",
      "      BatchNorm2d-98           [-1, 32, 14, 14]              64\n",
      " InvertedResidual-99           [-1, 32, 14, 14]               0\n",
      "          Conv2d-100           [-1, 32, 14, 14]           1,024\n",
      "     BatchNorm2d-101           [-1, 32, 14, 14]              64\n",
      "           ReLU6-102           [-1, 32, 14, 14]               0\n",
      "          Conv2d-103           [-1, 32, 14, 14]             288\n",
      "     BatchNorm2d-104           [-1, 32, 14, 14]              64\n",
      "           ReLU6-105           [-1, 32, 14, 14]               0\n",
      "          Conv2d-106           [-1, 32, 14, 14]           1,024\n",
      "     BatchNorm2d-107           [-1, 32, 14, 14]              64\n",
      "InvertedResidual-108           [-1, 32, 14, 14]               0\n",
      "          Conv2d-109           [-1, 32, 14, 14]           1,024\n",
      "     BatchNorm2d-110           [-1, 32, 14, 14]              64\n",
      "           ReLU6-111           [-1, 32, 14, 14]               0\n",
      "          Conv2d-112           [-1, 32, 14, 14]             288\n",
      "     BatchNorm2d-113           [-1, 32, 14, 14]              64\n",
      "           ReLU6-114           [-1, 32, 14, 14]               0\n",
      "          Conv2d-115           [-1, 32, 14, 14]           1,024\n",
      "     BatchNorm2d-116           [-1, 32, 14, 14]              64\n",
      "InvertedResidual-117           [-1, 32, 14, 14]               0\n",
      "          Conv2d-118           [-1, 32, 14, 14]           1,024\n",
      "     BatchNorm2d-119           [-1, 32, 14, 14]              64\n",
      "           ReLU6-120           [-1, 32, 14, 14]               0\n",
      "          Conv2d-121             [-1, 32, 7, 7]             288\n",
      "     BatchNorm2d-122             [-1, 32, 7, 7]              64\n",
      "           ReLU6-123             [-1, 32, 7, 7]               0\n",
      "          Conv2d-124             [-1, 32, 7, 7]           1,024\n",
      "     BatchNorm2d-125             [-1, 32, 7, 7]              64\n",
      "InvertedResidual-126             [-1, 32, 7, 7]               0\n",
      "          Conv2d-127             [-1, 64, 7, 7]           2,048\n",
      "     BatchNorm2d-128             [-1, 64, 7, 7]             128\n",
      "           ReLU6-129             [-1, 64, 7, 7]               0\n",
      "          Conv2d-130             [-1, 64, 7, 7]             576\n",
      "     BatchNorm2d-131             [-1, 64, 7, 7]             128\n",
      "           ReLU6-132             [-1, 64, 7, 7]               0\n",
      "          Conv2d-133             [-1, 32, 7, 7]           2,048\n",
      "     BatchNorm2d-134             [-1, 32, 7, 7]              64\n",
      "InvertedResidual-135             [-1, 32, 7, 7]               0\n",
      "          Conv2d-136             [-1, 64, 7, 7]           2,048\n",
      "     BatchNorm2d-137             [-1, 64, 7, 7]             128\n",
      "           ReLU6-138             [-1, 64, 7, 7]               0\n",
      "          Conv2d-139             [-1, 64, 7, 7]             576\n",
      "     BatchNorm2d-140             [-1, 64, 7, 7]             128\n",
      "           ReLU6-141             [-1, 64, 7, 7]               0\n",
      "          Conv2d-142             [-1, 32, 7, 7]           2,048\n",
      "     BatchNorm2d-143             [-1, 32, 7, 7]              64\n",
      "InvertedResidual-144             [-1, 32, 7, 7]               0\n",
      "          Conv2d-145             [-1, 64, 7, 7]           2,048\n",
      "     BatchNorm2d-146             [-1, 64, 7, 7]             128\n",
      "           ReLU6-147             [-1, 64, 7, 7]               0\n",
      "          Conv2d-148             [-1, 64, 7, 7]             576\n",
      "     BatchNorm2d-149             [-1, 64, 7, 7]             128\n",
      "           ReLU6-150             [-1, 64, 7, 7]               0\n",
      "          Conv2d-151             [-1, 32, 7, 7]           2,048\n",
      "     BatchNorm2d-152             [-1, 32, 7, 7]              64\n",
      "InvertedResidual-153             [-1, 32, 7, 7]               0\n",
      "          Conv2d-154           [-1, 1280, 7, 7]          40,960\n",
      "     BatchNorm2d-155           [-1, 1280, 7, 7]           2,560\n",
      "           ReLU6-156           [-1, 1280, 7, 7]               0\n",
      "AdaptiveAvgPool2d-157           [-1, 1280, 1, 1]               0\n",
      "          Linear-158                  [-1, 256]         327,936\n",
      "            ReLU-159                  [-1, 256]               0\n",
      "     BatchNorm1d-160                  [-1, 256]             512\n",
      "         Dropout-161                  [-1, 256]               0\n",
      "          Linear-162                  [-1, 128]          32,896\n",
      "            ReLU-163                  [-1, 128]               0\n",
      "     BatchNorm1d-164                  [-1, 128]             256\n",
      "         Dropout-165                  [-1, 128]               0\n",
      "          Linear-166                   [-1, 64]           8,256\n",
      "            ReLU-167                   [-1, 64]               0\n",
      "     BatchNorm1d-168                   [-1, 64]             128\n",
      "         Dropout-169                   [-1, 64]               0\n",
      "          Linear-170                   [-1, 10]             650\n",
      "================================================================\n",
      "Total params: 462,250\n",
      "Trainable params: 462,250\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 55.04\n",
      "Params size (MB): 1.76\n",
      "Estimated Total Size (MB): 57.38\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(pruned_model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model after pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average test Loss: 6.4287, Test Accuracy: 9.73%, Inference Time for 6000 images: 5.12 seconds\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "# Evaluate pruned model\n",
    "avgLoss, acc, inf_time = evaluate_model(pruned_model, test_loader, criterion, device)\n",
    "# Print evaluation results\n",
    "print(f\"Average test Loss: {avgLoss:.4f}, Test Accuracy: {acc:.2f}%, Inference Time for {len(test_dataset)} images: {inf_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tune the pruned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:49<00:00,  7.15it/s, train_acc=21.9, train_loss=0.0552]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 3.5282, Train Acc: 21.93%, Dev Loss: 2.1358, Dev Acc: 29.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:49<00:00,  7.14it/s, train_acc=29.7, train_loss=0.0339]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 2.1706, Train Acc: 29.68%, Dev Loss: 1.6870, Dev Acc: 38.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:50<00:00,  7.06it/s, train_acc=35.3, train_loss=0.0287]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 1.8349, Train Acc: 35.26%, Dev Loss: 1.5453, Dev Acc: 42.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:51<00:00,  7.01it/s, train_acc=39.4, train_loss=0.0262]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss: 1.6746, Train Acc: 39.44%, Dev Loss: 1.4498, Dev Acc: 45.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:51<00:00,  6.99it/s, train_acc=43, train_loss=0.0244]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss: 1.5612, Train Acc: 42.99%, Dev Loss: 1.3786, Dev Acc: 48.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:49<00:00,  7.13it/s, train_acc=47.1, train_loss=0.0229]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss: 1.4665, Train Acc: 47.08%, Dev Loss: 1.2868, Dev Acc: 52.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:50<00:00,  7.11it/s, train_acc=50.2, train_loss=0.0218]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss: 1.3941, Train Acc: 50.16%, Dev Loss: 1.2250, Dev Acc: 55.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:50<00:00,  7.07it/s, train_acc=53, train_loss=0.0207]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss: 1.3260, Train Acc: 53.01%, Dev Loss: 1.1593, Dev Acc: 57.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:49<00:00,  7.11it/s, train_acc=55.4, train_loss=0.0199]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss: 1.2718, Train Acc: 55.43%, Dev Loss: 1.1149, Dev Acc: 59.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:49<00:00,  7.17it/s, train_acc=57.4, train_loss=0.0191]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss: 1.2212, Train Acc: 57.43%, Dev Loss: 1.0721, Dev Acc: 60.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:57<00:00,  6.68it/s, train_acc=59.4, train_loss=0.0183]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss: 1.1703, Train Acc: 59.39%, Dev Loss: 1.0335, Dev Acc: 62.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:52<00:00,  6.95it/s, train_acc=61, train_loss=0.0176]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss: 1.1268, Train Acc: 60.97%, Dev Loss: 0.9821, Dev Acc: 64.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:53<00:00,  6.91it/s, train_acc=62.4, train_loss=0.0171]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss: 1.0903, Train Acc: 62.44%, Dev Loss: 0.9569, Dev Acc: 64.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:52<00:00,  6.93it/s, train_acc=63.5, train_loss=0.0166]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss: 1.0634, Train Acc: 63.48%, Dev Loss: 0.9410, Dev Acc: 65.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:47<00:00,  7.29it/s, train_acc=64.3, train_loss=0.0163]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss: 1.0397, Train Acc: 64.34%, Dev Loss: 0.9124, Dev Acc: 67.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:46<00:00,  7.31it/s, train_acc=65.3, train_loss=0.0158]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Train Loss: 1.0095, Train Acc: 65.26%, Dev Loss: 0.8902, Dev Acc: 67.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:47<00:00,  7.29it/s, train_acc=66.1, train_loss=0.0154]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Train Loss: 0.9848, Train Acc: 66.09%, Dev Loss: 0.8818, Dev Acc: 68.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:47<00:00,  7.29it/s, train_acc=66.7, train_loss=0.0151]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Train Loss: 0.9669, Train Acc: 66.67%, Dev Loss: 0.8589, Dev Acc: 68.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:47<00:00,  7.28it/s, train_acc=67.3, train_loss=0.015] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Train Loss: 0.9569, Train Acc: 67.34%, Dev Loss: 0.8371, Dev Acc: 70.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:47<00:00,  7.29it/s, train_acc=68, train_loss=0.0146]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Train Loss: 0.9344, Train Acc: 68.01%, Dev Loss: 0.8139, Dev Acc: 71.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:47<00:00,  7.30it/s, train_acc=68.9, train_loss=0.0143]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: Train Loss: 0.9123, Train Acc: 68.91%, Dev Loss: 0.8174, Dev Acc: 71.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:47<00:00,  7.29it/s, train_acc=69.4, train_loss=0.014] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Train Loss: 0.8977, Train Acc: 69.36%, Dev Loss: 0.8006, Dev Acc: 71.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:54<00:00,  6.85it/s, train_acc=69.9, train_loss=0.0138]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: Train Loss: 0.8802, Train Acc: 69.95%, Dev Loss: 0.7771, Dev Acc: 72.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:47<00:00,  7.25it/s, train_acc=70.2, train_loss=0.0137]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Train Loss: 0.8738, Train Acc: 70.15%, Dev Loss: 0.7688, Dev Acc: 72.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:46<00:00,  7.31it/s, train_acc=71.3, train_loss=0.0133]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: Train Loss: 0.8500, Train Acc: 71.30%, Dev Loss: 0.7519, Dev Acc: 72.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:47<00:00,  7.28it/s, train_acc=71.5, train_loss=0.0132]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: Train Loss: 0.8431, Train Acc: 71.49%, Dev Loss: 0.7315, Dev Acc: 74.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:47<00:00,  7.27it/s, train_acc=72, train_loss=0.013]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: Train Loss: 0.8292, Train Acc: 71.96%, Dev Loss: 0.7338, Dev Acc: 74.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:47<00:00,  7.27it/s, train_acc=72.4, train_loss=0.0128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: Train Loss: 0.8182, Train Acc: 72.36%, Dev Loss: 0.7349, Dev Acc: 74.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:47<00:00,  7.26it/s, train_acc=73, train_loss=0.0126]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: Train Loss: 0.8063, Train Acc: 72.97%, Dev Loss: 0.7145, Dev Acc: 75.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:47<00:00,  7.28it/s, train_acc=73.4, train_loss=0.0124]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Train Loss: 0.7940, Train Acc: 73.38%, Dev Loss: 0.6887, Dev Acc: 75.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:48<00:00,  7.23it/s, train_acc=73.7, train_loss=0.0123]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: Train Loss: 0.7861, Train Acc: 73.67%, Dev Loss: 0.7022, Dev Acc: 75.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:47<00:00,  7.25it/s, train_acc=73.8, train_loss=0.0122]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: Train Loss: 0.7779, Train Acc: 73.80%, Dev Loss: 0.6938, Dev Acc: 75.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:47<00:00,  7.26it/s, train_acc=74.1, train_loss=0.0121]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: Train Loss: 0.7711, Train Acc: 74.14%, Dev Loss: 0.6772, Dev Acc: 76.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:47<00:00,  7.26it/s, train_acc=74.5, train_loss=0.0119]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: Train Loss: 0.7605, Train Acc: 74.50%, Dev Loss: 0.6629, Dev Acc: 76.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:47<00:00,  7.25it/s, train_acc=74.6, train_loss=0.0117]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: Train Loss: 0.7497, Train Acc: 74.64%, Dev Loss: 0.6607, Dev Acc: 76.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:48<00:00,  7.24it/s, train_acc=75.4, train_loss=0.0116]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: Train Loss: 0.7414, Train Acc: 75.43%, Dev Loss: 0.6562, Dev Acc: 76.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:47<00:00,  7.24it/s, train_acc=75.4, train_loss=0.0116]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: Train Loss: 0.7402, Train Acc: 75.45%, Dev Loss: 0.6506, Dev Acc: 76.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:47<00:00,  7.27it/s, train_acc=75.9, train_loss=0.0114]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: Train Loss: 0.7277, Train Acc: 75.92%, Dev Loss: 0.6392, Dev Acc: 77.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:48<00:00,  7.23it/s, train_acc=76, train_loss=0.0113]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: Train Loss: 0.7218, Train Acc: 76.01%, Dev Loss: 0.6336, Dev Acc: 77.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:48<00:00,  7.24it/s, train_acc=76.2, train_loss=0.0112]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: Train Loss: 0.7161, Train Acc: 76.21%, Dev Loss: 0.6342, Dev Acc: 77.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:48<00:00,  7.24it/s, train_acc=76.4, train_loss=0.011] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: Train Loss: 0.7047, Train Acc: 76.37%, Dev Loss: 0.6255, Dev Acc: 78.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:47<00:00,  7.25it/s, train_acc=76.6, train_loss=0.011] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: Train Loss: 0.7024, Train Acc: 76.61%, Dev Loss: 0.6272, Dev Acc: 78.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:47<00:00,  7.26it/s, train_acc=76.9, train_loss=0.0109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: Train Loss: 0.6946, Train Acc: 76.94%, Dev Loss: 0.6170, Dev Acc: 78.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:47<00:00,  7.26it/s, train_acc=77.5, train_loss=0.0106]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: Train Loss: 0.6801, Train Acc: 77.50%, Dev Loss: 0.6038, Dev Acc: 78.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:48<00:00,  7.22it/s, train_acc=77.5, train_loss=0.0107]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: Train Loss: 0.6832, Train Acc: 77.52%, Dev Loss: 0.6043, Dev Acc: 79.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:48<00:00,  7.23it/s, train_acc=77.8, train_loss=0.0106]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: Train Loss: 0.6759, Train Acc: 77.77%, Dev Loss: 0.6078, Dev Acc: 78.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:47<00:00,  7.26it/s, train_acc=78, train_loss=0.0105]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: Train Loss: 0.6682, Train Acc: 78.01%, Dev Loss: 0.5925, Dev Acc: 79.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:47<00:00,  7.25it/s, train_acc=78.5, train_loss=0.0103]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: Train Loss: 0.6577, Train Acc: 78.46%, Dev Loss: 0.5933, Dev Acc: 79.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:48<00:00,  7.19it/s, train_acc=78.3, train_loss=0.0103]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: Train Loss: 0.6570, Train Acc: 78.31%, Dev Loss: 0.5895, Dev Acc: 79.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:48<00:00,  7.23it/s, train_acc=78.7, train_loss=0.0102]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: Train Loss: 0.6499, Train Acc: 78.66%, Dev Loss: 0.5765, Dev Acc: 79.97%\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# fine tine the pruned model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "train_model(pruned_model, train_loader, dev_loader, criterion, optimizer, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:46<00:00,  7.32it/s, train_acc=72.1, train_loss=0.0132]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.8446, Train Acc: 72.05%, Dev Loss: 0.7944, Dev Acc: 72.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:46<00:00,  7.33it/s, train_acc=73.8, train_loss=0.0125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 0.8009, Train Acc: 73.78%, Dev Loss: 0.7054, Dev Acc: 75.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:46<00:00,  7.31it/s, train_acc=75.3, train_loss=0.0119]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 0.7608, Train Acc: 75.28%, Dev Loss: 0.7007, Dev Acc: 76.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:47<00:00,  7.28it/s, train_acc=76, train_loss=0.0115]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss: 0.7373, Train Acc: 75.97%, Dev Loss: 0.6505, Dev Acc: 78.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:47<00:00,  7.26it/s, train_acc=76.9, train_loss=0.0111]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss: 0.7114, Train Acc: 76.94%, Dev Loss: 0.6188, Dev Acc: 79.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:47<00:00,  7.29it/s, train_acc=77.6, train_loss=0.0108]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss: 0.6911, Train Acc: 77.59%, Dev Loss: 0.6204, Dev Acc: 80.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:48<00:00,  7.21it/s, train_acc=78.3, train_loss=0.0105]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss: 0.6689, Train Acc: 78.35%, Dev Loss: 0.6748, Dev Acc: 77.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:47<00:00,  7.28it/s, train_acc=79, train_loss=0.0103]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss: 0.6576, Train Acc: 78.98%, Dev Loss: 0.6213, Dev Acc: 79.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:47<00:00,  7.25it/s, train_acc=78.3, train_loss=0.0105]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss: 0.6731, Train Acc: 78.35%, Dev Loss: 0.5518, Dev Acc: 81.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:47<00:00,  7.25it/s, train_acc=79.8, train_loss=0.00979]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss: 0.6257, Train Acc: 79.78%, Dev Loss: 0.5733, Dev Acc: 81.17%\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# fine tine the pruned model for more epochs\n",
    "optimizer = torch.optim.Adam(pruned_model.parameters(), lr=1e-3)\n",
    "train_model(pruned_model, train_loader, dev_loader, criterion, optimizer, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:45<00:00,  7.38it/s, train_acc=80.2, train_loss=0.00969]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.6199, Train Acc: 80.22%, Dev Loss: 0.5908, Dev Acc: 79.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:46<00:00,  7.34it/s, train_acc=80.5, train_loss=0.00951]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 0.6080, Train Acc: 80.48%, Dev Loss: 0.5432, Dev Acc: 81.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:46<00:00,  7.32it/s, train_acc=80.9, train_loss=0.00933]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 0.5967, Train Acc: 80.93%, Dev Loss: 0.5004, Dev Acc: 83.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:46<00:00,  7.32it/s, train_acc=81.3, train_loss=0.00917]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss: 0.5863, Train Acc: 81.30%, Dev Loss: 0.5523, Dev Acc: 81.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:46<00:00,  7.31it/s, train_acc=81.6, train_loss=0.00896]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss: 0.5731, Train Acc: 81.58%, Dev Loss: 0.5116, Dev Acc: 82.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:47<00:00,  7.30it/s, train_acc=81.9, train_loss=0.00884]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss: 0.5653, Train Acc: 81.87%, Dev Loss: 0.4841, Dev Acc: 83.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:47<00:00,  7.27it/s, train_acc=82.3, train_loss=0.00863]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss: 0.5516, Train Acc: 82.32%, Dev Loss: 0.4782, Dev Acc: 84.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:47<00:00,  7.27it/s, train_acc=82.8, train_loss=0.00851]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss: 0.5439, Train Acc: 82.80%, Dev Loss: 0.4675, Dev Acc: 84.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:48<00:00,  7.19it/s, train_acc=83, train_loss=0.00841]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss: 0.5378, Train Acc: 82.98%, Dev Loss: 0.4800, Dev Acc: 83.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [01:48<00:00,  7.23it/s, train_acc=83.1, train_loss=0.0083] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss: 0.5305, Train Acc: 83.13%, Dev Loss: 0.5113, Dev Acc: 82.97%\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# fine tine the pruned model for more epochs\n",
    "optimizer = torch.optim.Adam(pruned_model.parameters(), lr=1e-3)\n",
    "train_model(pruned_model, train_loader, dev_loader, criterion, optimizer, num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate after fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average test Loss: 0.5165, Test Accuracy: 82.98%, Inference Time for 6000 images: 5.19 seconds\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "# Evaluate pruned model\n",
    "avgLoss, acc, inf_time = evaluate_model(pruned_model, test_loader, criterion, device)\n",
    "# Print evaluation results\n",
    "print(f\"Average test Loss: {avgLoss:.4f}, Test Accuracy: {acc:.2f}%, Inference Time for {len(test_dataset)} images: {inf_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of original model: 10.14 MB\n",
      "Size of pruned model: 1.91 MB\n",
      "Size reduction: 8.24 MB\n",
      "Percentage reduction: 81.19%\n"
     ]
    }
   ],
   "source": [
    "model_weights_path = \"../pytorch_models/mobilenet_cifar10.pth\"\n",
    "pruned_weights_path = \"../pytorch_models/mobileNet_pruned_finetuned_weights.pth\"\n",
    "# Compare model sizes\n",
    "original_model_size = os.path.getsize(model_weights_path) / (1024 * 1024)\n",
    "print(f\"Size of original model: {original_model_size:.2f} MB\")\n",
    "pruned_model_size = os.path.getsize(pruned_weights_path) / (1024 * 1024)\n",
    "print(f\"Size of pruned model: {pruned_model_size:.2f} MB\")\n",
    "# Calculate the size reduction\n",
    "size_reduction = original_model_size - pruned_model_size\n",
    "print(f\"Size reduction: {size_reduction:.2f} MB\")\n",
    "# Calculate the percentage reduction\n",
    "percentage_reduction = (size_reduction / original_model_size) * 100\n",
    "print(f\"Percentage reduction: {percentage_reduction:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights saved successfully at: ./mobileNet_pruned_finetuned_weights.pth\n"
     ]
    }
   ],
   "source": [
    "model_save_path = \"./mobileNet_pruned_finetuned_weights.pth\"\n",
    "# Save model weights (recommended approach)\n",
    "torch.save(pruned_model.state_dict(), model_save_path)\n",
    "print(f\"Model weights saved successfully at: {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full model saved successfully at: ./mobileNet_pruned_finetuned.pth\n"
     ]
    }
   ],
   "source": [
    "full_model_save_path = \"./mobileNet_pruned_finetuned.pth\"\n",
    "# Save the entire model (optional if you want to keep the architecture too)\n",
    "torch.save(pruned_model, full_model_save_path)\n",
    "print(f\"Full model saved successfully at: {full_model_save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
