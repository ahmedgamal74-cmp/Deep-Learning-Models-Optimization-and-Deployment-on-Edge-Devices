{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "ajIYwE6iBzyC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LoNYNkmHscDR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Subset, random_split\n",
        "from torchvision import models\n",
        "from tqdm import tqdm\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating the mobileNet Model"
      ],
      "metadata": {
        "id": "Kwnmb5QiB3fm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained MobileNet model\n",
        "base_model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1)\n",
        "\n",
        "# Unfreeze some of the top layers\n",
        "for param in base_model.features[:-10].parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Modify the classifier for CIFAR-10 (10 classes)\n",
        "class MobileNetV2(nn.Module):\n",
        "    def __init__(self, base_model):\n",
        "        super(MobileNetV2, self).__init__()\n",
        "        self.features = base_model.features\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(1280, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(64, 10)  # CIFAR-10 has 10 classes\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "model = MobileNetV2(base_model)"
      ],
      "metadata": {
        "id": "owPFX8xP-dlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Match the input tensor's device (cuda or cpu) with the model's device."
      ],
      "metadata": {
        "id": "6ThhApYoCFdY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure the model is on the correct device (cuda or cpu)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lCROpSlA_zd",
        "outputId": "5644cecc-1705-4e5f-9c99-9b0b91385f33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MobileNetV2(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2dNormActivation(\n",
              "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU6(inplace=True)\n",
              "    )\n",
              "    (1): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (2): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
              "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (3): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (4): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (5): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (6): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (7): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (8): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (9): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (10): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (11): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (12): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (13): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (14): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (15): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (16): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (17): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (18): Conv2dNormActivation(\n",
              "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU6(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=1280, out_features=256, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
              "    (5): ReLU()\n",
              "    (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (7): Dropout(p=0.5, inplace=False)\n",
              "    (8): Linear(in_features=128, out_features=64, bias=True)\n",
              "    (9): ReLU()\n",
              "    (10): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (11): Dropout(p=0.5, inplace=False)\n",
              "    (12): Linear(in_features=64, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Print model Summary"
      ],
      "metadata": {
        "id": "MEvndxANCCDv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model, (3, 224, 224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eKbdI5kBA0w",
        "outputId": "b942970f-295c-4f8a-a27d-9760ce7686da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 112, 112]             864\n",
            "       BatchNorm2d-2         [-1, 32, 112, 112]              64\n",
            "             ReLU6-3         [-1, 32, 112, 112]               0\n",
            "            Conv2d-4         [-1, 32, 112, 112]             288\n",
            "       BatchNorm2d-5         [-1, 32, 112, 112]              64\n",
            "             ReLU6-6         [-1, 32, 112, 112]               0\n",
            "            Conv2d-7         [-1, 16, 112, 112]             512\n",
            "       BatchNorm2d-8         [-1, 16, 112, 112]              32\n",
            "  InvertedResidual-9         [-1, 16, 112, 112]               0\n",
            "           Conv2d-10         [-1, 96, 112, 112]           1,536\n",
            "      BatchNorm2d-11         [-1, 96, 112, 112]             192\n",
            "            ReLU6-12         [-1, 96, 112, 112]               0\n",
            "           Conv2d-13           [-1, 96, 56, 56]             864\n",
            "      BatchNorm2d-14           [-1, 96, 56, 56]             192\n",
            "            ReLU6-15           [-1, 96, 56, 56]               0\n",
            "           Conv2d-16           [-1, 24, 56, 56]           2,304\n",
            "      BatchNorm2d-17           [-1, 24, 56, 56]              48\n",
            " InvertedResidual-18           [-1, 24, 56, 56]               0\n",
            "           Conv2d-19          [-1, 144, 56, 56]           3,456\n",
            "      BatchNorm2d-20          [-1, 144, 56, 56]             288\n",
            "            ReLU6-21          [-1, 144, 56, 56]               0\n",
            "           Conv2d-22          [-1, 144, 56, 56]           1,296\n",
            "      BatchNorm2d-23          [-1, 144, 56, 56]             288\n",
            "            ReLU6-24          [-1, 144, 56, 56]               0\n",
            "           Conv2d-25           [-1, 24, 56, 56]           3,456\n",
            "      BatchNorm2d-26           [-1, 24, 56, 56]              48\n",
            " InvertedResidual-27           [-1, 24, 56, 56]               0\n",
            "           Conv2d-28          [-1, 144, 56, 56]           3,456\n",
            "      BatchNorm2d-29          [-1, 144, 56, 56]             288\n",
            "            ReLU6-30          [-1, 144, 56, 56]               0\n",
            "           Conv2d-31          [-1, 144, 28, 28]           1,296\n",
            "      BatchNorm2d-32          [-1, 144, 28, 28]             288\n",
            "            ReLU6-33          [-1, 144, 28, 28]               0\n",
            "           Conv2d-34           [-1, 32, 28, 28]           4,608\n",
            "      BatchNorm2d-35           [-1, 32, 28, 28]              64\n",
            " InvertedResidual-36           [-1, 32, 28, 28]               0\n",
            "           Conv2d-37          [-1, 192, 28, 28]           6,144\n",
            "      BatchNorm2d-38          [-1, 192, 28, 28]             384\n",
            "            ReLU6-39          [-1, 192, 28, 28]               0\n",
            "           Conv2d-40          [-1, 192, 28, 28]           1,728\n",
            "      BatchNorm2d-41          [-1, 192, 28, 28]             384\n",
            "            ReLU6-42          [-1, 192, 28, 28]               0\n",
            "           Conv2d-43           [-1, 32, 28, 28]           6,144\n",
            "      BatchNorm2d-44           [-1, 32, 28, 28]              64\n",
            " InvertedResidual-45           [-1, 32, 28, 28]               0\n",
            "           Conv2d-46          [-1, 192, 28, 28]           6,144\n",
            "      BatchNorm2d-47          [-1, 192, 28, 28]             384\n",
            "            ReLU6-48          [-1, 192, 28, 28]               0\n",
            "           Conv2d-49          [-1, 192, 28, 28]           1,728\n",
            "      BatchNorm2d-50          [-1, 192, 28, 28]             384\n",
            "            ReLU6-51          [-1, 192, 28, 28]               0\n",
            "           Conv2d-52           [-1, 32, 28, 28]           6,144\n",
            "      BatchNorm2d-53           [-1, 32, 28, 28]              64\n",
            " InvertedResidual-54           [-1, 32, 28, 28]               0\n",
            "           Conv2d-55          [-1, 192, 28, 28]           6,144\n",
            "      BatchNorm2d-56          [-1, 192, 28, 28]             384\n",
            "            ReLU6-57          [-1, 192, 28, 28]               0\n",
            "           Conv2d-58          [-1, 192, 14, 14]           1,728\n",
            "      BatchNorm2d-59          [-1, 192, 14, 14]             384\n",
            "            ReLU6-60          [-1, 192, 14, 14]               0\n",
            "           Conv2d-61           [-1, 64, 14, 14]          12,288\n",
            "      BatchNorm2d-62           [-1, 64, 14, 14]             128\n",
            " InvertedResidual-63           [-1, 64, 14, 14]               0\n",
            "           Conv2d-64          [-1, 384, 14, 14]          24,576\n",
            "      BatchNorm2d-65          [-1, 384, 14, 14]             768\n",
            "            ReLU6-66          [-1, 384, 14, 14]               0\n",
            "           Conv2d-67          [-1, 384, 14, 14]           3,456\n",
            "      BatchNorm2d-68          [-1, 384, 14, 14]             768\n",
            "            ReLU6-69          [-1, 384, 14, 14]               0\n",
            "           Conv2d-70           [-1, 64, 14, 14]          24,576\n",
            "      BatchNorm2d-71           [-1, 64, 14, 14]             128\n",
            " InvertedResidual-72           [-1, 64, 14, 14]               0\n",
            "           Conv2d-73          [-1, 384, 14, 14]          24,576\n",
            "      BatchNorm2d-74          [-1, 384, 14, 14]             768\n",
            "            ReLU6-75          [-1, 384, 14, 14]               0\n",
            "           Conv2d-76          [-1, 384, 14, 14]           3,456\n",
            "      BatchNorm2d-77          [-1, 384, 14, 14]             768\n",
            "            ReLU6-78          [-1, 384, 14, 14]               0\n",
            "           Conv2d-79           [-1, 64, 14, 14]          24,576\n",
            "      BatchNorm2d-80           [-1, 64, 14, 14]             128\n",
            " InvertedResidual-81           [-1, 64, 14, 14]               0\n",
            "           Conv2d-82          [-1, 384, 14, 14]          24,576\n",
            "      BatchNorm2d-83          [-1, 384, 14, 14]             768\n",
            "            ReLU6-84          [-1, 384, 14, 14]               0\n",
            "           Conv2d-85          [-1, 384, 14, 14]           3,456\n",
            "      BatchNorm2d-86          [-1, 384, 14, 14]             768\n",
            "            ReLU6-87          [-1, 384, 14, 14]               0\n",
            "           Conv2d-88           [-1, 64, 14, 14]          24,576\n",
            "      BatchNorm2d-89           [-1, 64, 14, 14]             128\n",
            " InvertedResidual-90           [-1, 64, 14, 14]               0\n",
            "           Conv2d-91          [-1, 384, 14, 14]          24,576\n",
            "      BatchNorm2d-92          [-1, 384, 14, 14]             768\n",
            "            ReLU6-93          [-1, 384, 14, 14]               0\n",
            "           Conv2d-94          [-1, 384, 14, 14]           3,456\n",
            "      BatchNorm2d-95          [-1, 384, 14, 14]             768\n",
            "            ReLU6-96          [-1, 384, 14, 14]               0\n",
            "           Conv2d-97           [-1, 96, 14, 14]          36,864\n",
            "      BatchNorm2d-98           [-1, 96, 14, 14]             192\n",
            " InvertedResidual-99           [-1, 96, 14, 14]               0\n",
            "          Conv2d-100          [-1, 576, 14, 14]          55,296\n",
            "     BatchNorm2d-101          [-1, 576, 14, 14]           1,152\n",
            "           ReLU6-102          [-1, 576, 14, 14]               0\n",
            "          Conv2d-103          [-1, 576, 14, 14]           5,184\n",
            "     BatchNorm2d-104          [-1, 576, 14, 14]           1,152\n",
            "           ReLU6-105          [-1, 576, 14, 14]               0\n",
            "          Conv2d-106           [-1, 96, 14, 14]          55,296\n",
            "     BatchNorm2d-107           [-1, 96, 14, 14]             192\n",
            "InvertedResidual-108           [-1, 96, 14, 14]               0\n",
            "          Conv2d-109          [-1, 576, 14, 14]          55,296\n",
            "     BatchNorm2d-110          [-1, 576, 14, 14]           1,152\n",
            "           ReLU6-111          [-1, 576, 14, 14]               0\n",
            "          Conv2d-112          [-1, 576, 14, 14]           5,184\n",
            "     BatchNorm2d-113          [-1, 576, 14, 14]           1,152\n",
            "           ReLU6-114          [-1, 576, 14, 14]               0\n",
            "          Conv2d-115           [-1, 96, 14, 14]          55,296\n",
            "     BatchNorm2d-116           [-1, 96, 14, 14]             192\n",
            "InvertedResidual-117           [-1, 96, 14, 14]               0\n",
            "          Conv2d-118          [-1, 576, 14, 14]          55,296\n",
            "     BatchNorm2d-119          [-1, 576, 14, 14]           1,152\n",
            "           ReLU6-120          [-1, 576, 14, 14]               0\n",
            "          Conv2d-121            [-1, 576, 7, 7]           5,184\n",
            "     BatchNorm2d-122            [-1, 576, 7, 7]           1,152\n",
            "           ReLU6-123            [-1, 576, 7, 7]               0\n",
            "          Conv2d-124            [-1, 160, 7, 7]          92,160\n",
            "     BatchNorm2d-125            [-1, 160, 7, 7]             320\n",
            "InvertedResidual-126            [-1, 160, 7, 7]               0\n",
            "          Conv2d-127            [-1, 960, 7, 7]         153,600\n",
            "     BatchNorm2d-128            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-129            [-1, 960, 7, 7]               0\n",
            "          Conv2d-130            [-1, 960, 7, 7]           8,640\n",
            "     BatchNorm2d-131            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-132            [-1, 960, 7, 7]               0\n",
            "          Conv2d-133            [-1, 160, 7, 7]         153,600\n",
            "     BatchNorm2d-134            [-1, 160, 7, 7]             320\n",
            "InvertedResidual-135            [-1, 160, 7, 7]               0\n",
            "          Conv2d-136            [-1, 960, 7, 7]         153,600\n",
            "     BatchNorm2d-137            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-138            [-1, 960, 7, 7]               0\n",
            "          Conv2d-139            [-1, 960, 7, 7]           8,640\n",
            "     BatchNorm2d-140            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-141            [-1, 960, 7, 7]               0\n",
            "          Conv2d-142            [-1, 160, 7, 7]         153,600\n",
            "     BatchNorm2d-143            [-1, 160, 7, 7]             320\n",
            "InvertedResidual-144            [-1, 160, 7, 7]               0\n",
            "          Conv2d-145            [-1, 960, 7, 7]         153,600\n",
            "     BatchNorm2d-146            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-147            [-1, 960, 7, 7]               0\n",
            "          Conv2d-148            [-1, 960, 7, 7]           8,640\n",
            "     BatchNorm2d-149            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-150            [-1, 960, 7, 7]               0\n",
            "          Conv2d-151            [-1, 320, 7, 7]         307,200\n",
            "     BatchNorm2d-152            [-1, 320, 7, 7]             640\n",
            "InvertedResidual-153            [-1, 320, 7, 7]               0\n",
            "          Conv2d-154           [-1, 1280, 7, 7]         409,600\n",
            "     BatchNorm2d-155           [-1, 1280, 7, 7]           2,560\n",
            "           ReLU6-156           [-1, 1280, 7, 7]               0\n",
            "AdaptiveAvgPool2d-157           [-1, 1280, 1, 1]               0\n",
            "          Linear-158                  [-1, 256]         327,936\n",
            "            ReLU-159                  [-1, 256]               0\n",
            "     BatchNorm1d-160                  [-1, 256]             512\n",
            "         Dropout-161                  [-1, 256]               0\n",
            "          Linear-162                  [-1, 128]          32,896\n",
            "            ReLU-163                  [-1, 128]               0\n",
            "     BatchNorm1d-164                  [-1, 128]             256\n",
            "         Dropout-165                  [-1, 128]               0\n",
            "          Linear-166                   [-1, 64]           8,256\n",
            "            ReLU-167                   [-1, 64]               0\n",
            "     BatchNorm1d-168                   [-1, 64]             128\n",
            "         Dropout-169                   [-1, 64]               0\n",
            "          Linear-170                   [-1, 10]             650\n",
            "================================================================\n",
            "Total params: 2,594,506\n",
            "Trainable params: 2,463,690\n",
            "Non-trainable params: 130,816\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 152.87\n",
            "Params size (MB): 9.90\n",
            "Estimated Total Size (MB): 163.34\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading dataset"
      ],
      "metadata": {
        "id": "DaXS7JM-Cb2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix the seed to ensure reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Data augmentation for training (applied only to the train dataset)\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)), # Resize to MobileNet input size\n",
        "    transforms.RandomHorizontalFlip(), # Flip horizontally\n",
        "    transforms.RandomRotation(15), # Random rotation 15 degress\n",
        "    transforms.ToTensor(), # Convert to tensor\n",
        "    transforms.Normalize((0.5,), (0.5,)) # Normalize (mean=0.5, std=0.5)\n",
        "])\n",
        "\n",
        "# No augmentation for validation/test (only resizing and normalization)\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])"
      ],
      "metadata": {
        "id": "-Yt3zjQgBo_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download CIFAR-10 dataset\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
        "test_data = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
        "\n",
        "# Split the test_data into test (6k) and dev (4k)\n",
        "test_size = 6000\n",
        "dev_size = 4000\n",
        "test_dataset, dev_dataset = random_split(test_data, [test_size, dev_size])\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
        "dev_loader = DataLoader(dev_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
        "\n",
        "# Print dataset sizes\n",
        "print(f\"Train set size: {len(train_dataset)}\")\n",
        "print(f\"Dev set size: {len(dev_dataset)}\")\n",
        "print(f\"Test set size: {len(test_dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tML6jmfVCbYs",
        "outputId": "65eef225-cbae-4f07-897d-670c654a4831"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Train set size: 50000\n",
            "Dev set size: 4000\n",
            "Test set size: 6000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model"
      ],
      "metadata": {
        "id": "zMdy5Z_HDGgW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "def train_model(model, train_loader, dev_loader, criterion, optimizer, num_epochs=10):\n",
        "    for epoch in range(num_epochs):\n",
        "        ### Training Phase ###\n",
        "        model.train()  # Set model to training mode\n",
        "        running_loss = 0.0\n",
        "        correct, total = 0, 0\n",
        "\n",
        "        loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=True)\n",
        "        for images, labels in loop:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)           # Forward pass through the model\n",
        "            loss = criterion(outputs, labels) # Calculate the loss\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            optimizer.zero_grad() # Clear gradients from the previous iteration\n",
        "            loss.backward()       # Compute gradients (backpropagation)\n",
        "            optimizer.step()\n",
        "\n",
        "            # Compute training metrics\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "            # Update progress bar\n",
        "            loop.set_postfix(train_loss=running_loss/total, train_acc=100.*correct/total)\n",
        "\n",
        "        train_loss = running_loss / len(train_loader)\n",
        "        train_acc = 100. * correct / total\n",
        "\n",
        "        ### Validation (Dev) Phase ###\n",
        "        model.eval()  # Set model to evaluation mode\n",
        "        dev_loss, dev_correct, dev_total = 0.0, 0, 0\n",
        "\n",
        "        with torch.no_grad():  # No gradients for validation (Disable gradient calculations for efficiency)\n",
        "            for images, labels in dev_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                dev_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                dev_total += labels.size(0)\n",
        "                dev_correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        dev_loss /= len(dev_loader)\n",
        "        dev_acc = 100. * dev_correct / dev_total\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, Dev Loss: {dev_loss:.4f}, Dev Acc: {dev_acc:.2f}%\")\n",
        "\n",
        "    print(\"Training complete!\")"
      ],
      "metadata": {
        "id": "73jfeYWnDFsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "train_model(model, train_loader, dev_loader, criterion, optimizer, num_epochs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2V8_fNnhFWCr",
        "outputId": "fdd2066c-5267-42ec-a302-0b3850b619b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/20: 100%|██████████| 782/782 [02:07<00:00,  6.12it/s, train_acc=66.9, train_loss=0.0157]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 1.0041, Train Acc: 66.91%, Dev Loss: 0.5126, Dev Acc: 82.90%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/20: 100%|██████████| 782/782 [02:08<00:00,  6.09it/s, train_acc=81.7, train_loss=0.00945]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train Loss: 0.6042, Train Acc: 81.74%, Dev Loss: 0.4537, Dev Acc: 85.22%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/20: 100%|██████████| 782/782 [02:08<00:00,  6.09it/s, train_acc=84.3, train_loss=0.00812]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Train Loss: 0.5192, Train Acc: 84.29%, Dev Loss: 0.4098, Dev Acc: 86.15%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/20: 100%|██████████| 782/782 [02:08<00:00,  6.07it/s, train_acc=86.1, train_loss=0.00725]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Train Loss: 0.4633, Train Acc: 86.13%, Dev Loss: 0.3170, Dev Acc: 89.60%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/20: 100%|██████████| 782/782 [02:08<00:00,  6.09it/s, train_acc=87.1, train_loss=0.00665]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train Loss: 0.4253, Train Acc: 87.08%, Dev Loss: 0.3239, Dev Acc: 89.47%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/20: 100%|██████████| 782/782 [02:13<00:00,  5.88it/s, train_acc=88.1, train_loss=0.00616]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Train Loss: 0.3938, Train Acc: 88.13%, Dev Loss: 0.3165, Dev Acc: 89.85%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/20: 100%|██████████| 782/782 [02:12<00:00,  5.90it/s, train_acc=88.9, train_loss=0.00575]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: Train Loss: 0.3677, Train Acc: 88.86%, Dev Loss: 0.3057, Dev Acc: 90.30%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/20: 100%|██████████| 782/782 [02:12<00:00,  5.88it/s, train_acc=89.4, train_loss=0.00547]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: Train Loss: 0.3497, Train Acc: 89.44%, Dev Loss: 0.2971, Dev Acc: 90.30%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/20: 100%|██████████| 782/782 [02:15<00:00,  5.77it/s, train_acc=90, train_loss=0.00518]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9: Train Loss: 0.3313, Train Acc: 89.98%, Dev Loss: 0.2669, Dev Acc: 91.67%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/20: 100%|██████████| 782/782 [02:14<00:00,  5.81it/s, train_acc=90.4, train_loss=0.00502]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: Train Loss: 0.3207, Train Acc: 90.45%, Dev Loss: 0.2975, Dev Acc: 90.47%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/20: 100%|██████████| 782/782 [02:15<00:00,  5.78it/s, train_acc=90.7, train_loss=0.00476]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11: Train Loss: 0.3045, Train Acc: 90.69%, Dev Loss: 0.2649, Dev Acc: 91.08%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/20: 100%|██████████| 782/782 [02:16<00:00,  5.71it/s, train_acc=91.6, train_loss=0.00438]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12: Train Loss: 0.2798, Train Acc: 91.61%, Dev Loss: 0.2635, Dev Acc: 91.62%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/20: 100%|██████████| 782/782 [02:09<00:00,  6.04it/s, train_acc=91.6, train_loss=0.00434]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13: Train Loss: 0.2776, Train Acc: 91.59%, Dev Loss: 0.2628, Dev Acc: 91.47%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/20: 100%|██████████| 782/782 [02:10<00:00,  6.01it/s, train_acc=92.1, train_loss=0.00409]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14: Train Loss: 0.2616, Train Acc: 92.10%, Dev Loss: 0.2588, Dev Acc: 91.95%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/20: 100%|██████████| 782/782 [02:11<00:00,  5.93it/s, train_acc=92.3, train_loss=0.00391]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15: Train Loss: 0.2501, Train Acc: 92.28%, Dev Loss: 0.2456, Dev Acc: 92.15%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/20: 100%|██████████| 782/782 [02:10<00:00,  6.01it/s, train_acc=92.6, train_loss=0.00381]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16: Train Loss: 0.2438, Train Acc: 92.64%, Dev Loss: 0.2450, Dev Acc: 92.33%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/20: 100%|██████████| 782/782 [02:10<00:00,  5.98it/s, train_acc=92.8, train_loss=0.00366]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17: Train Loss: 0.2340, Train Acc: 92.82%, Dev Loss: 0.2636, Dev Acc: 91.88%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/20: 100%|██████████| 782/782 [02:09<00:00,  6.02it/s, train_acc=93, train_loss=0.00356]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18: Train Loss: 0.2274, Train Acc: 93.01%, Dev Loss: 0.2747, Dev Acc: 91.67%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/20: 100%|██████████| 782/782 [02:10<00:00,  6.01it/s, train_acc=93.4, train_loss=0.00337]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19: Train Loss: 0.2154, Train Acc: 93.37%, Dev Loss: 0.2490, Dev Acc: 92.28%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/20: 100%|██████████| 782/782 [02:08<00:00,  6.06it/s, train_acc=93.5, train_loss=0.00327]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20: Train Loss: 0.2090, Train Acc: 93.54%, Dev Loss: 0.2672, Dev Acc: 91.55%\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating the model's performance on the test dataset"
      ],
      "metadata": {
        "id": "9vU6KmS5XIAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_loader, criterion, device):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    test_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():  # No gradients for validation (Disable gradient calculations for efficiency)\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Update loss\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            # Get predictions\n",
        "            _, predicted = outputs.max(1)\n",
        "\n",
        "            # Update metrics\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    avg_loss = test_loss / len(test_loader)\n",
        "    accuracy = 100. * correct / total\n",
        "\n",
        "    print(f\"Test Loss: {avg_loss:.4f}, Test Accuracy: {accuracy:.2f}%\")\n",
        "    return avg_loss, accuracy"
      ],
      "metadata": {
        "id": "wnUJoEiMXHpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(model, test_loader, criterion, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ix-atFhbaFi5",
        "outputId": "263ef063-ac1e-4baa-b33d-5a6728888761"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.2781, Test Accuracy: 91.35%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.27812374422841885, 91.35)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🌐 Connect to google drive"
      ],
      "metadata": {
        "id": "VHf56UndW7bv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7mcWjyUW9s-",
        "outputId": "ffbc2f79-d788-4da4-a2de-888c8e62c54c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# check if pytorch_models directory doesn't exist & create it if it doesn't\n",
        "if not os.path.exists('/content/drive/My Drive/saved_models/pytorch_models'):\n",
        "    os.makedirs('/content/drive/My Drive/saved_models/pytorch_models')\n",
        "    print(\"pytorch_models folder is created successfully\")\n",
        "else:\n",
        "    print(\"pytorch_models folder already exists skipping folder creation...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNH7q0kdXuNX",
        "outputId": "b142484f-fbf9-4243-e15c-7145219d862a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pytorch_models folder is created successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving the model"
      ],
      "metadata": {
        "id": "lsihR-7qVKwo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_path = '/content/drive/My Drive/saved_models/pytorch_models/mobilenet_cifar10.pth'\n",
        "full_model_save_path = '/content/drive/My Drive/saved_models/pytorch_models/mobilenet_cifar10_full.pth'"
      ],
      "metadata": {
        "id": "YVlNijdlYRQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Saving the weights only (recommended approach)\n",
        "When loading the model later we have to define the architecture first like the following example:\n",
        "```python\n",
        "# define the model architecture first\n",
        "model = MobileNetV2\n",
        "# Load the saved weights\n",
        "model.load_state_dict(torch.load('mobilenet_cifar10.pth'))\n",
        "```\n",
        "\n",
        "✅ Why is state_dict() the preferred method?\n",
        "- Flexibility: to reuse the weights with different architectures.\n",
        "- Compatibility: Avoids issues when saving/loading across PyTorch versions.\n",
        "- Efficiency: Smaller file size and faster loading."
      ],
      "metadata": {
        "id": "Ov2PrGvWVbU-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model weights (recommended approach)\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "print(f\"Model weights saved successfully at: {model_save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adhxCIEsVWkn",
        "outputId": "cbfa4f9d-43fa-4ee5-e47f-384f087e6e9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model weights saved successfully at: /content/drive/My Drive/saved_models/pytorch_models/mobilenet_cifar10.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Saving the entire model (including architecture)\n",
        "to load the model we can load it directly without defining the model architecture\n",
        "```python\n",
        "# Directly load the full model\n",
        "model = torch.load('mobilenet_cifar10_full.pth')\n",
        "```"
      ],
      "metadata": {
        "id": "ABtH7tdbWfFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the entire model (optional if you want to keep the architecture too)\n",
        "torch.save(model, full_model_save_path)\n",
        "print(f\"Full model saved successfully at: {full_model_save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8DLWY4TVORu",
        "outputId": "ddf7219d-71b7-4a37-d937-d406d1c932df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full model saved successfully at: /content/drive/My Drive/saved_models/pytorch_models/mobilenet_cifar10_full.pth\n"
          ]
        }
      ]
    }
  ]
}