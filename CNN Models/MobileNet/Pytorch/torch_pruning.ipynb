{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f516327",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "da08e7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset, random_split\n",
    "from torchvision import models\n",
    "from torchvision.models import mobilenet_v2\n",
    "from torchvision.models.mobilenetv2 import InvertedResidual\n",
    "from tqdm import tqdm\n",
    "from torchsummary import summary\n",
    "import time\n",
    "import os\n",
    "import torch_pruning as tp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113c4e7a",
   "metadata": {},
   "source": [
    "# Loading the dataset (CIFAR-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "014edf1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 50000\n",
      "Dev set size: 4000\n",
      "Test set size: 6000\n"
     ]
    }
   ],
   "source": [
    "# Fix the seed to ensure reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Data augmentation for training (applied only to the train dataset)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), # Resize to MobileNet input size\n",
    "    transforms.RandomHorizontalFlip(), # Flip horizontally\n",
    "    transforms.RandomRotation(15), # Random rotation 15 degress\n",
    "    transforms.ToTensor(), # Convert to tensor\n",
    "    transforms.Normalize((0.5,), (0.5,)) # Normalize (mean=0.5, std=0.5)\n",
    "])\n",
    "\n",
    "# No augmentation for validation/test (only resizing and normalization)\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "# Download CIFAR-10 dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
    "test_data = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
    "\n",
    "# Split the test_data into test (6k) and dev (4k)\n",
    "test_size = 6000\n",
    "dev_size = 4000\n",
    "test_dataset, dev_dataset = random_split(test_data, [test_size, dev_size])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "# Print dataset sizes\n",
    "print(f\"Train set size: {len(train_dataset)}\")\n",
    "print(f\"Dev set size: {len(dev_dataset)}\")\n",
    "print(f\"Test set size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeaf3d7",
   "metadata": {},
   "source": [
    "# Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "55aae467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained MobileNet model\n",
    "base_model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# Unfreeze some of the top layers\n",
    "for param in base_model.features[:-10].parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the classifier for CIFAR-10 (10 classes)\n",
    "class MobileNetV2(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super(MobileNetV2, self).__init__()\n",
    "        self.features = base_model.features\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(1280, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, 10)  # CIFAR-10 has 10 classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model = MobileNetV2(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "1fa6a9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Model weights loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "model = MobileNetV2(base_model)\n",
    "model_weights_path = '../pytorch_models/mobilenet_cifar10_fullyTrained.pth'\n",
    "# load the full model\n",
    "model.load_state_dict(torch.load(model_weights_path))\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "print(\"Original Model weights loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "041c6c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV2(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): Conv2dNormActivation(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=1280, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.5, inplace=False)\n",
       "    (8): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (9): ReLU()\n",
       "    (10): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): Dropout(p=0.5, inplace=False)\n",
       "    (12): Linear(in_features=64, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "0e821913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Model Summary:\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 112, 112]             864\n",
      "       BatchNorm2d-2         [-1, 32, 112, 112]              64\n",
      "             ReLU6-3         [-1, 32, 112, 112]               0\n",
      "            Conv2d-4         [-1, 32, 112, 112]             288\n",
      "       BatchNorm2d-5         [-1, 32, 112, 112]              64\n",
      "             ReLU6-6         [-1, 32, 112, 112]               0\n",
      "            Conv2d-7         [-1, 16, 112, 112]             512\n",
      "       BatchNorm2d-8         [-1, 16, 112, 112]              32\n",
      "  InvertedResidual-9         [-1, 16, 112, 112]               0\n",
      "           Conv2d-10         [-1, 96, 112, 112]           1,536\n",
      "      BatchNorm2d-11         [-1, 96, 112, 112]             192\n",
      "            ReLU6-12         [-1, 96, 112, 112]               0\n",
      "           Conv2d-13           [-1, 96, 56, 56]             864\n",
      "      BatchNorm2d-14           [-1, 96, 56, 56]             192\n",
      "            ReLU6-15           [-1, 96, 56, 56]               0\n",
      "           Conv2d-16           [-1, 24, 56, 56]           2,304\n",
      "      BatchNorm2d-17           [-1, 24, 56, 56]              48\n",
      " InvertedResidual-18           [-1, 24, 56, 56]               0\n",
      "           Conv2d-19          [-1, 144, 56, 56]           3,456\n",
      "      BatchNorm2d-20          [-1, 144, 56, 56]             288\n",
      "            ReLU6-21          [-1, 144, 56, 56]               0\n",
      "           Conv2d-22          [-1, 144, 56, 56]           1,296\n",
      "      BatchNorm2d-23          [-1, 144, 56, 56]             288\n",
      "            ReLU6-24          [-1, 144, 56, 56]               0\n",
      "           Conv2d-25           [-1, 24, 56, 56]           3,456\n",
      "      BatchNorm2d-26           [-1, 24, 56, 56]              48\n",
      " InvertedResidual-27           [-1, 24, 56, 56]               0\n",
      "           Conv2d-28          [-1, 144, 56, 56]           3,456\n",
      "      BatchNorm2d-29          [-1, 144, 56, 56]             288\n",
      "            ReLU6-30          [-1, 144, 56, 56]               0\n",
      "           Conv2d-31          [-1, 144, 28, 28]           1,296\n",
      "      BatchNorm2d-32          [-1, 144, 28, 28]             288\n",
      "            ReLU6-33          [-1, 144, 28, 28]               0\n",
      "           Conv2d-34           [-1, 32, 28, 28]           4,608\n",
      "      BatchNorm2d-35           [-1, 32, 28, 28]              64\n",
      " InvertedResidual-36           [-1, 32, 28, 28]               0\n",
      "           Conv2d-37          [-1, 192, 28, 28]           6,144\n",
      "      BatchNorm2d-38          [-1, 192, 28, 28]             384\n",
      "            ReLU6-39          [-1, 192, 28, 28]               0\n",
      "           Conv2d-40          [-1, 192, 28, 28]           1,728\n",
      "      BatchNorm2d-41          [-1, 192, 28, 28]             384\n",
      "            ReLU6-42          [-1, 192, 28, 28]               0\n",
      "           Conv2d-43           [-1, 32, 28, 28]           6,144\n",
      "      BatchNorm2d-44           [-1, 32, 28, 28]              64\n",
      " InvertedResidual-45           [-1, 32, 28, 28]               0\n",
      "           Conv2d-46          [-1, 192, 28, 28]           6,144\n",
      "      BatchNorm2d-47          [-1, 192, 28, 28]             384\n",
      "            ReLU6-48          [-1, 192, 28, 28]               0\n",
      "           Conv2d-49          [-1, 192, 28, 28]           1,728\n",
      "      BatchNorm2d-50          [-1, 192, 28, 28]             384\n",
      "            ReLU6-51          [-1, 192, 28, 28]               0\n",
      "           Conv2d-52           [-1, 32, 28, 28]           6,144\n",
      "      BatchNorm2d-53           [-1, 32, 28, 28]              64\n",
      " InvertedResidual-54           [-1, 32, 28, 28]               0\n",
      "           Conv2d-55          [-1, 192, 28, 28]           6,144\n",
      "      BatchNorm2d-56          [-1, 192, 28, 28]             384\n",
      "            ReLU6-57          [-1, 192, 28, 28]               0\n",
      "           Conv2d-58          [-1, 192, 14, 14]           1,728\n",
      "      BatchNorm2d-59          [-1, 192, 14, 14]             384\n",
      "            ReLU6-60          [-1, 192, 14, 14]               0\n",
      "           Conv2d-61           [-1, 64, 14, 14]          12,288\n",
      "      BatchNorm2d-62           [-1, 64, 14, 14]             128\n",
      " InvertedResidual-63           [-1, 64, 14, 14]               0\n",
      "           Conv2d-64          [-1, 384, 14, 14]          24,576\n",
      "      BatchNorm2d-65          [-1, 384, 14, 14]             768\n",
      "            ReLU6-66          [-1, 384, 14, 14]               0\n",
      "           Conv2d-67          [-1, 384, 14, 14]           3,456\n",
      "      BatchNorm2d-68          [-1, 384, 14, 14]             768\n",
      "            ReLU6-69          [-1, 384, 14, 14]               0\n",
      "           Conv2d-70           [-1, 64, 14, 14]          24,576\n",
      "      BatchNorm2d-71           [-1, 64, 14, 14]             128\n",
      " InvertedResidual-72           [-1, 64, 14, 14]               0\n",
      "           Conv2d-73          [-1, 384, 14, 14]          24,576\n",
      "      BatchNorm2d-74          [-1, 384, 14, 14]             768\n",
      "            ReLU6-75          [-1, 384, 14, 14]               0\n",
      "           Conv2d-76          [-1, 384, 14, 14]           3,456\n",
      "      BatchNorm2d-77          [-1, 384, 14, 14]             768\n",
      "            ReLU6-78          [-1, 384, 14, 14]               0\n",
      "           Conv2d-79           [-1, 64, 14, 14]          24,576\n",
      "      BatchNorm2d-80           [-1, 64, 14, 14]             128\n",
      " InvertedResidual-81           [-1, 64, 14, 14]               0\n",
      "           Conv2d-82          [-1, 384, 14, 14]          24,576\n",
      "      BatchNorm2d-83          [-1, 384, 14, 14]             768\n",
      "            ReLU6-84          [-1, 384, 14, 14]               0\n",
      "           Conv2d-85          [-1, 384, 14, 14]           3,456\n",
      "      BatchNorm2d-86          [-1, 384, 14, 14]             768\n",
      "            ReLU6-87          [-1, 384, 14, 14]               0\n",
      "           Conv2d-88           [-1, 64, 14, 14]          24,576\n",
      "      BatchNorm2d-89           [-1, 64, 14, 14]             128\n",
      " InvertedResidual-90           [-1, 64, 14, 14]               0\n",
      "           Conv2d-91          [-1, 384, 14, 14]          24,576\n",
      "      BatchNorm2d-92          [-1, 384, 14, 14]             768\n",
      "            ReLU6-93          [-1, 384, 14, 14]               0\n",
      "           Conv2d-94          [-1, 384, 14, 14]           3,456\n",
      "      BatchNorm2d-95          [-1, 384, 14, 14]             768\n",
      "            ReLU6-96          [-1, 384, 14, 14]               0\n",
      "           Conv2d-97           [-1, 96, 14, 14]          36,864\n",
      "      BatchNorm2d-98           [-1, 96, 14, 14]             192\n",
      " InvertedResidual-99           [-1, 96, 14, 14]               0\n",
      "          Conv2d-100          [-1, 576, 14, 14]          55,296\n",
      "     BatchNorm2d-101          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-102          [-1, 576, 14, 14]               0\n",
      "          Conv2d-103          [-1, 576, 14, 14]           5,184\n",
      "     BatchNorm2d-104          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-105          [-1, 576, 14, 14]               0\n",
      "          Conv2d-106           [-1, 96, 14, 14]          55,296\n",
      "     BatchNorm2d-107           [-1, 96, 14, 14]             192\n",
      "InvertedResidual-108           [-1, 96, 14, 14]               0\n",
      "          Conv2d-109          [-1, 576, 14, 14]          55,296\n",
      "     BatchNorm2d-110          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-111          [-1, 576, 14, 14]               0\n",
      "          Conv2d-112          [-1, 576, 14, 14]           5,184\n",
      "     BatchNorm2d-113          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-114          [-1, 576, 14, 14]               0\n",
      "          Conv2d-115           [-1, 96, 14, 14]          55,296\n",
      "     BatchNorm2d-116           [-1, 96, 14, 14]             192\n",
      "InvertedResidual-117           [-1, 96, 14, 14]               0\n",
      "          Conv2d-118          [-1, 576, 14, 14]          55,296\n",
      "     BatchNorm2d-119          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-120          [-1, 576, 14, 14]               0\n",
      "          Conv2d-121            [-1, 576, 7, 7]           5,184\n",
      "     BatchNorm2d-122            [-1, 576, 7, 7]           1,152\n",
      "           ReLU6-123            [-1, 576, 7, 7]               0\n",
      "          Conv2d-124            [-1, 160, 7, 7]          92,160\n",
      "     BatchNorm2d-125            [-1, 160, 7, 7]             320\n",
      "InvertedResidual-126            [-1, 160, 7, 7]               0\n",
      "          Conv2d-127            [-1, 960, 7, 7]         153,600\n",
      "     BatchNorm2d-128            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-129            [-1, 960, 7, 7]               0\n",
      "          Conv2d-130            [-1, 960, 7, 7]           8,640\n",
      "     BatchNorm2d-131            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-132            [-1, 960, 7, 7]               0\n",
      "          Conv2d-133            [-1, 160, 7, 7]         153,600\n",
      "     BatchNorm2d-134            [-1, 160, 7, 7]             320\n",
      "InvertedResidual-135            [-1, 160, 7, 7]               0\n",
      "          Conv2d-136            [-1, 960, 7, 7]         153,600\n",
      "     BatchNorm2d-137            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-138            [-1, 960, 7, 7]               0\n",
      "          Conv2d-139            [-1, 960, 7, 7]           8,640\n",
      "     BatchNorm2d-140            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-141            [-1, 960, 7, 7]               0\n",
      "          Conv2d-142            [-1, 160, 7, 7]         153,600\n",
      "     BatchNorm2d-143            [-1, 160, 7, 7]             320\n",
      "InvertedResidual-144            [-1, 160, 7, 7]               0\n",
      "          Conv2d-145            [-1, 960, 7, 7]         153,600\n",
      "     BatchNorm2d-146            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-147            [-1, 960, 7, 7]               0\n",
      "          Conv2d-148            [-1, 960, 7, 7]           8,640\n",
      "     BatchNorm2d-149            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-150            [-1, 960, 7, 7]               0\n",
      "          Conv2d-151            [-1, 320, 7, 7]         307,200\n",
      "     BatchNorm2d-152            [-1, 320, 7, 7]             640\n",
      "InvertedResidual-153            [-1, 320, 7, 7]               0\n",
      "          Conv2d-154           [-1, 1280, 7, 7]         409,600\n",
      "     BatchNorm2d-155           [-1, 1280, 7, 7]           2,560\n",
      "           ReLU6-156           [-1, 1280, 7, 7]               0\n",
      "AdaptiveAvgPool2d-157           [-1, 1280, 1, 1]               0\n",
      "          Linear-158                  [-1, 256]         327,936\n",
      "            ReLU-159                  [-1, 256]               0\n",
      "     BatchNorm1d-160                  [-1, 256]             512\n",
      "         Dropout-161                  [-1, 256]               0\n",
      "          Linear-162                  [-1, 128]          32,896\n",
      "            ReLU-163                  [-1, 128]               0\n",
      "     BatchNorm1d-164                  [-1, 128]             256\n",
      "         Dropout-165                  [-1, 128]               0\n",
      "          Linear-166                   [-1, 64]           8,256\n",
      "            ReLU-167                   [-1, 64]               0\n",
      "     BatchNorm1d-168                   [-1, 64]             128\n",
      "         Dropout-169                   [-1, 64]               0\n",
      "          Linear-170                   [-1, 10]             650\n",
      "================================================================\n",
      "Total params: 2,594,506\n",
      "Trainable params: 2,463,690\n",
      "Non-trainable params: 130,816\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 152.87\n",
      "Params size (MB): 9.90\n",
      "Estimated Total Size (MB): 163.34\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# print model summary\n",
    "print(\"Original Model Summary:\")\n",
    "summary(model, (3, 224, 224), device=device.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a90a023",
   "metadata": {},
   "source": [
    "# Required functions for training and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "47327f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train_model(model, train_loader, dev_loader, criterion, optimizer, num_epochs=10, mask_enforcer=None):\n",
    "    for epoch in range(num_epochs):\n",
    "        ### Training Phase ###\n",
    "        model.train()  # Set model to training mode\n",
    "        running_loss = 0.0\n",
    "        correct, total = 0, 0\n",
    "\n",
    "        loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=True)\n",
    "        for images, labels in loop:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Enforce pruning mask if provided\n",
    "            if mask_enforcer:\n",
    "                mask_enforcer.enforce()\n",
    "\n",
    "            # Compute training metrics\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "            # Update progress bar\n",
    "            loop.set_postfix(train_loss=running_loss / total, train_acc=100. * correct / total)\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = 100. * correct / total\n",
    "\n",
    "        ### Validation (Dev) Phase ###\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        dev_loss, dev_correct, dev_total = 0.0, 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in dev_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                dev_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                dev_total += labels.size(0)\n",
    "                dev_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        dev_loss /= len(dev_loader)\n",
    "        dev_acc = 100. * dev_correct / dev_total\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, Dev Loss: {dev_loss:.4f}, Dev Acc: {dev_acc:.2f}%\")\n",
    "\n",
    "    print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e0ce3909",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, criterion, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():  # No gradients for validation (Disable gradient calculations for efficiency)\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Update loss\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # Get predictions\n",
    "            _, predicted = outputs.max(1)\n",
    "\n",
    "            # Update metrics\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    end_time = time.time()\n",
    "    inference_time = end_time - start_time\n",
    "    avg_loss = test_loss / len(test_loader)\n",
    "    accuracy = 100. * correct / total\n",
    "\n",
    "    #print(f\"Test Loss: {avg_loss:.4f}, Test Accuracy: {accuracy:.2f}%\")\n",
    "    return avg_loss, accuracy, inference_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5393dab1",
   "metadata": {},
   "source": [
    "# Test model before pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "27619840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results before pruning:\n",
      "Average test Loss: 0.2305, Test Accuracy: 93.33%, Inference Time for 6000 images: 12.88 seconds\n",
      "Original Model FLOPs: 319.39 MFLOPs, Parameters: 2.59 M\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "# Results before pruning\n",
    "bp_loss, bp_acc, bp_inf_time = evaluate_model(model, test_loader, criterion, device)\n",
    "print(\"Results before pruning:\")\n",
    "print(f\"Average test Loss: {bp_loss:.4f}, Test Accuracy: {bp_acc:.2f}%, Inference Time for {len(test_dataset)} images: {bp_inf_time:.2f} seconds\")\n",
    "example_inputs = torch.randn(1, 3, 224, 224).to(device)\n",
    "bp_flops, bp_params = tp.utils.count_ops_and_params(model, example_inputs)\n",
    "print(f\"Original Model FLOPs: {bp_flops / 1e6:.2f} MFLOPs, Parameters: {bp_params / 1e6:.2f} M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fc1600",
   "metadata": {},
   "source": [
    "# Apply pruning using torch pruning library\n",
    "https://pypi.org/project/torch-pruning/#why-torch-pruning\n",
    "\n",
    "To install use: `pip install torch-pruning`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "334ef830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store layers we want to ignore during pruning\n",
    "ignored_layers = []\n",
    "\n",
    "# Loop through all modules in model.features\n",
    "for m in model.features.modules():\n",
    "    # Check if the module is an InvertedResidual block with residual connection\n",
    "    if isinstance(m, InvertedResidual) and m.use_res_connect:\n",
    "        # Add all layers in this residual block to ignored_layers\n",
    "        for name, layer in m.named_modules():\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                ignored_layers.append(layer)\n",
    "\n",
    "# Also ignore the classifier\n",
    "ignored_layers.append(model.classifier)\n",
    "\n",
    "# Now create pruner with ignored_layers\n",
    "pruner = tp.pruner.MagnitudePruner(\n",
    "    model,\n",
    "    example_inputs=example_inputs,\n",
    "    importance=tp.importance.MagnitudeImportance(p=1),\n",
    "    global_pruning=True,\n",
    "    pruning_ratio=0.8,\n",
    "    ignored_layers=ignored_layers,\n",
    ")\n",
    "\n",
    "# Perform pruning\n",
    "pruner.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "fcca47c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results before pruning:\n",
      "Average test Loss: 0.2305, Test Accuracy: 93.33%, Inference Time for 6000 images: 12.88 seconds\n",
      "Original Model FLOPs: 319.39 MFLOPs, Parameters: 2.59 M\n",
      "Results after pruning:\n",
      "Average test Loss: 4.2113, Test Accuracy: 10.00%, Inference Time for 6000 images: 8.57 seconds\n",
      "Pruned Model FLOPs: 256.15 MFLOPs, Parameters: 1.30 M\n"
     ]
    }
   ],
   "source": [
    "print(\"Results before pruning:\")\n",
    "print(f\"Average test Loss: {bp_loss:.4f}, Test Accuracy: {bp_acc:.2f}%, Inference Time for {len(test_dataset)} images: {bp_inf_time:.2f} seconds\")\n",
    "print(f\"Original Model FLOPs: {bp_flops / 1e6:.2f} MFLOPs, Parameters: {bp_params / 1e6:.2f} M\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "ap_loss, ap_acc, ap_inf = evaluate_model(model, test_loader, criterion, device)\n",
    "print(\"Results after pruning:\")\n",
    "print(f\"Average test Loss: {ap_loss:.4f}, Test Accuracy: {ap_acc:.2f}%, Inference Time for {len(test_dataset)} images: {ap_inf:.2f} seconds\")\n",
    "# Calculate FLOPs and parameters after pruning\n",
    "ap_flops, ap_params = tp.utils.count_ops_and_params(model, example_inputs)\n",
    "print(f\"Pruned Model FLOPs: {ap_flops / 1e6:.2f} MFLOPs, Parameters: {ap_params / 1e6:.2f} M\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "a9326fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 782/782 [02:12<00:00,  5.90it/s, train_acc=87.2, train_loss=0.00654]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.4183, Train Acc: 87.19%, Dev Loss: 0.3276, Dev Acc: 89.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 782/782 [02:13<00:00,  5.85it/s, train_acc=90.1, train_loss=0.00511]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 0.3265, Train Acc: 90.08%, Dev Loss: 0.3057, Dev Acc: 90.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 782/782 [02:17<00:00,  5.70it/s, train_acc=91.2, train_loss=0.0045] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 0.2877, Train Acc: 91.22%, Dev Loss: 0.2780, Dev Acc: 91.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 782/782 [02:13<00:00,  5.84it/s, train_acc=91.6, train_loss=0.00432]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss: 0.2765, Train Acc: 91.57%, Dev Loss: 0.2862, Dev Acc: 91.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 782/782 [02:11<00:00,  5.94it/s, train_acc=91.9, train_loss=0.00417]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss: 0.2663, Train Acc: 91.95%, Dev Loss: 0.2549, Dev Acc: 91.70%\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# fine tune the pruned model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "# Train the pruned model\n",
    "train_model(model, train_loader, dev_loader, criterion, optimizer, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "f45d2931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results before pruning:\n",
      "Average test Loss: 0.2305, Test Accuracy: 93.33%, Inference Time for 6000 images: 12.88 seconds\n",
      "Original Model FLOPs: 319.39 MFLOPs, Parameters: 2.59 M\n",
      "Results after pruning:\n",
      "Average test Loss: 4.2113, Test Accuracy: 10.00%, Inference Time for 6000 images: 8.57 seconds\n",
      "Pruned Model FLOPs: 256.15 MFLOPs, Parameters: 1.30 M\n",
      "Results after fine-tuning:\n",
      "Average test Loss: 0.2807, Test Accuracy: 91.53%, Inference Time for 6000 images: 12.36 seconds\n",
      "Fine-tuned Model FLOPs: 256.15 MFLOPs, Parameters: 1.30 M\n"
     ]
    }
   ],
   "source": [
    "print(\"Results before pruning:\")\n",
    "print(f\"Average test Loss: {bp_loss:.4f}, Test Accuracy: {bp_acc:.2f}%, Inference Time for {len(test_dataset)} images: {bp_inf_time:.2f} seconds\")\n",
    "print(f\"Original Model FLOPs: {bp_flops / 1e6:.2f} MFLOPs, Parameters: {bp_params / 1e6:.2f} M\")\n",
    "print(\"Results after pruning:\")\n",
    "print(f\"Average test Loss: {ap_loss:.4f}, Test Accuracy: {ap_acc:.2f}%, Inference Time for {len(test_dataset)} images: {ap_inf:.2f} seconds\")\n",
    "print(f\"Pruned Model FLOPs: {ap_flops / 1e6:.2f} MFLOPs, Parameters: {ap_params / 1e6:.2f} M\")\n",
    "print(\"Results after fine-tuning:\")\n",
    "ft_loss, ft_acc, ft_inf = evaluate_model(model, test_loader, criterion, device)\n",
    "print(f\"Average test Loss: {ft_loss:.4f}, Test Accuracy: {ft_acc:.2f}%, Inference Time for {len(test_dataset)} images: {ft_inf:.2f} seconds\")\n",
    "# calculate FLOPs and parameters after fine-tuning\n",
    "ft_flops, ft_params = tp.utils.count_ops_and_params(model, example_inputs)\n",
    "print(f\"Fine-tuned Model FLOPs: {ft_flops / 1e6:.2f} MFLOPs, Parameters: {ft_params / 1e6:.2f} M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "ed972361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully exported to: ../onnx_models/MobileNetV2_torch_pruning_80.onnx\n"
     ]
    }
   ],
   "source": [
    "onnx_path = '../onnx_models/MobileNetV2_torch_pruning_80.onnx'\n",
    "# Export the model to ONNX\n",
    "torch.onnx.export(\n",
    "    model=model,\n",
    "    args=torch.randn(1, 3, 224, 224).to(device),\n",
    "    f=onnx_path,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    export_params=True,\n",
    "    opset_version=11\n",
    ")\n",
    "print(f\"Model successfully exported to: {onnx_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "72599c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_model_path = '../onnx_models/mobilenet_cifar10.onnx'\n",
    "pruned_30_path = '../onnx_models/MobileNetV2_torch_pruning_30.onnx'\n",
    "pruned_50_path = '../onnx_models/MobileNetV2_torch_pruning_50.onnx'\n",
    "pruned_80_path = '../onnx_models/MobileNetV2_torch_pruning_80.onnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "d05f2870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Model Size: 9.88 MB\n",
      "Pruned Model (30%) Size: 7.57 MB\n",
      "Pruned Model (50%) Size: 6.31 MB\n",
      "Pruned Model (80%) Size: 4.97 MB\n"
     ]
    }
   ],
   "source": [
    "# compare sizes of the models\n",
    "def get_model_size(model_path):\n",
    "    return os.path.getsize(model_path) / (1024 * 1024)  # Size in MB\n",
    "\n",
    "print(f\"Original Model Size: {get_model_size(original_model_path):.2f} MB\")\n",
    "print(f\"Pruned Model (30%) Size: {get_model_size(pruned_30_path):.2f} MB\")\n",
    "print(f\"Pruned Model (50%) Size: {get_model_size(pruned_50_path):.2f} MB\")\n",
    "print(f\"Pruned Model (80%) Size: {get_model_size(pruned_80_path):.2f} MB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
